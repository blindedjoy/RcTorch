{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coastal-manual",
   "metadata": {
    "id": "coastal-manual"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from rctorch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e-rXL3fLBDU",
   "metadata": {
    "id": "4e-rXL3fLBDU"
   },
   "outputs": [],
   "source": [
    "# pip install rctorch==0.7162\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "needed-panel",
   "metadata": {
    "id": "needed-panel"
   },
   "outputs": [],
   "source": [
    "#this method will ensure that the notebook can use multiprocessing on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limiting-albert",
   "metadata": {
    "id": "limiting-albert"
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def pltTr(x,y,clr='cyan', mark='o'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             marker=mark, color=clr, markersize=8, label='truth', alpha = 0.9)\n",
    "\n",
    "def pltPred(x,y,clr='red', linS='-'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             color=clr, marker='.', linewidth=2, label='RC')\n",
    "from decimal import Decimal\n",
    "\n",
    "def convert2pd(tensor1, tensor2):\n",
    "    pd_ = pd.DataFrame(np.hstack((tensor1.detach().cpu().numpy(), tensor2.detach().cpu().numpy())))\n",
    "    pd_.columns = [\"t\", \"y\"]\n",
    "    return pd_\n",
    "'%.2E' % Decimal('40800000000.00000000000000')\n",
    "\n",
    "def param(t,N,y0):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    #f = t\n",
    "    #f_dot=1\n",
    "    return y0 + f*N\n",
    "\n",
    "#define a reparameterization function\n",
    "def reparam(t, y0 = None, N = None, dN_dt = None, t_only = False):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    \n",
    "    if t_only:\n",
    "        return f, f_dot\n",
    "\n",
    "    y = y0 + N*f \n",
    "    if dN_dt:\n",
    "        ydot = dN_dt * f + f_dot * N\n",
    "    else:\n",
    "        ydot = None\n",
    "    return y, ydot\n",
    "\n",
    "def reparam(t, order = 1):\n",
    "    exp_t = torch.exp(-t)\n",
    "    \n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    \n",
    "    #0th derivative\n",
    "    derivatives_of_g.append(g)\n",
    "    \n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-prescription",
   "metadata": {
    "id": "enhanced-prescription"
   },
   "outputs": [],
   "source": [
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)\n",
    "lam =1\n",
    "def hamiltonian(x, p, lam = lam):\n",
    "    return (1/2)*(x**2 + p**2) + lam*x**4/4\n",
    "\n",
    "def custom_loss(X , y, ydot, out_weights, force_t = None, \n",
    "                reg = True, ode_coefs = None, mean = True,\n",
    "               enet_strength = None, enet_alpha = None, init_conds = None, lam = 1):\n",
    "    y, p = y[:,0].view(-1,1), y[:,1].view(-1,1)\n",
    "    ydot, pdot = ydot[:,0].view(-1,1), ydot[:,1].view(-1,1)\n",
    "    \n",
    "    #with paramization\n",
    "    L =  (ydot - p)**2 + (pdot + y + lam * y**3   - force_t)**2\n",
    "    \n",
    "    #if mean:\n",
    "    L = torch.mean(L)\n",
    "    \n",
    "    if reg:\n",
    "        #assert False\n",
    "        weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "        weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "        L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "        L = L + 0.1 * L_reg \n",
    "\n",
    "    y0, p0 = init_conds\n",
    "    ham = hamiltonian(y, p)\n",
    "    ham0 = hamiltonian(y0, p0)\n",
    "    L_H = (( ham - ham0).pow(2)).mean()\n",
    "    assert L_H >0\n",
    "\n",
    "    L = L +  0.1 * L_H\n",
    "    \n",
    "    #print(\"L1\", hi, \"L_elastic\", L_reg, \"L_H\", L_H)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "practical-preparation",
   "metadata": {
    "id": "practical-preparation"
   },
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "\n",
    "def optimize_last_layer(esn, \n",
    "                        SAVE_AFTER_EPOCHS = 1,\n",
    "                        epochs = 45000,\n",
    "                        custom_loss = custom_loss,\n",
    "                        EPOCHS_TO_TERMINATION = None,\n",
    "                        f = force,\n",
    "                        lr = 0.05, \n",
    "                        reg = None,\n",
    "                        plott = False,\n",
    "                        plot_every_n_epochs = 2000):#gamma 0.1, spikethreshold 0.07 works\n",
    "    with torch.enable_grad():\n",
    "        #define new_x\n",
    "        new_X = esn.extended_states.detach()\n",
    "        spikethreshold = esn.spikethreshold\n",
    "\n",
    "        #force detach states_dot\n",
    "        esn.states_dot = esn.states_dot.detach().requires_grad_(False)\n",
    "\n",
    "        #define criterion\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        #assert not new_X.requires_grad\n",
    "\n",
    "        #define previous_loss (could be used to do a convergence stop)\n",
    "        previous_loss = 0\n",
    "\n",
    "        #define best score so that we can save the best weights\n",
    "        best_score = 0\n",
    "\n",
    "        #define the optimizer\n",
    "        optimizer = optim.Adam(esn.parameters(), lr = lr)\n",
    "\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "        if esn.gamma_cyclic:\n",
    "            cyclic_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 10**-6, 0.01,\n",
    "                                            gamma = esn.gamma_cyclic,#0.9999,\n",
    "                                            mode = \"exp_range\", cycle_momentum = False)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=esn.gamma)\n",
    "        lrs = []\n",
    "\n",
    "        #define the loss history\n",
    "        loss_history = []\n",
    "\n",
    "        if plott:\n",
    "          #use pl for live plotting\n",
    "          fig, ax = pl.subplots(1,3, figsize = (16,4))\n",
    "\n",
    "        t = esn.X#.view(*N.shape).detach()\n",
    "        force_t = force(t)\n",
    "        g, g_dot = esn.G\n",
    "        y0  = esn.init_conds[0]\n",
    "\n",
    "        flipped = False\n",
    "        flipped2 = False\n",
    "        pow_ = -4\n",
    "        floss_last = 0\n",
    "\n",
    "\n",
    "        try:\n",
    "            assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        except:\n",
    "            esn.LinOut.weight.requires_grad_(True)\n",
    "            esn.LinOut.bias.requires_grad_(True)\n",
    "\n",
    "        #bail\n",
    "\n",
    "        #begin optimization loop\n",
    "        for e in range(epochs):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            N = esn.forward( esn.extended_states )\n",
    "            N_dot = esn.calc_Ndot(esn.states_dot)\n",
    "\n",
    "            y = g *N \n",
    "\n",
    "            ydot = g_dot * N + g * N_dot\n",
    "\n",
    "            y[:,0] = y[:,0] + esn.init_conds[0]\n",
    "            y[:,1] = y[:,1] + esn.init_conds[1]\n",
    "\n",
    "            #assert N.shape == N_dot.shape, f'{N.shape} != {N_dot.shape}'\n",
    "\n",
    "            #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "\n",
    "            #total_ws = esn.LinOut.weight.shape[0] + 1\n",
    "            #weight_size_sq = torch.mean(torch.square(esn.LinOut.weight))\n",
    "\n",
    "            loss = custom_loss(esn.X, y, ydot, esn.LinOut.weight, reg = reg, ode_coefs = esn.ode_coefs,\n",
    "                    init_conds = esn.init_conds, enet_alpha= esn.enet_alpha, enet_strength = esn.enet_strength, force_t = force_t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if esn.gamma_cyclic and e > 100 and e <5000:\n",
    "                cyclic_scheduler.step()\n",
    "                lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "\n",
    "            floss = float(loss)\n",
    "            loss_history.append(floss)\n",
    "\n",
    "            # if e == 10**3:\n",
    "            #     if floss > 10**(5):\n",
    "            #         EPOCHS_TO_TERMINATION = e + 50\n",
    "\n",
    "            # if e == 10**4:\n",
    "            #     if floss > 10**(2.5):\n",
    "            #         EPOCHS_TO_TERMINATION = e + 50\n",
    "                    \n",
    "            if e > 0:\n",
    "                loss_delta = float(np.log(floss_last) - np.log(floss)) \n",
    "                if loss_delta > esn.spikethreshold:# or loss_delta < -3:\n",
    "                    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "                    scheduler.step()\n",
    "\n",
    "\n",
    "            if not e and not best_score:\n",
    "                best_bias, best_weight, best_fit = esn.LinOut.bias.detach(), esn.LinOut.weight.detach(), y.clone()\n",
    "\n",
    "            if e > SAVE_AFTER_EPOCHS:\n",
    "                if not best_score:\n",
    "                    best_score = min(loss_history)\n",
    "                if floss < best_score:  \n",
    "                    best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "                    best_score = float(loss)\n",
    "                    best_fit = y.clone()\n",
    "                    best_ydot = ydot.clone()\n",
    "            # else:\n",
    "            #     if floss < best_score:\n",
    "            #         best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "            #         best_score = float(loss)\n",
    "            #         best_fit = y.clone()\n",
    "            #         best_ydot = ydot.clone()\n",
    "            \n",
    "            # if e >= EPOCHS_TO_TERMINATION and EPOCHS_TO_TERMINATION:\n",
    "            #     return {\"weights\": best_weight, \"bias\" : best_bias, \"y\" : best_fit, \n",
    "            #           \"loss\" : {\"loss_history\" : loss_history},  \"best_score\" : torch.tensor(best_score),\n",
    "            #           \"RC\" : esn}\n",
    "            floss_last = floss\n",
    "            if plott and e:\n",
    "\n",
    "                if e % plot_every_n_epochs == 0:\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        print('lr', param_group['lr'])\n",
    "                    ax[0].clear()\n",
    "                    logloss_str = 'Log(L) ' + '%.2E' % Decimal((loss).item())\n",
    "                    delta_loss  = ' delta Log(L) ' + '%.2E' % Decimal((loss-previous_loss).item())\n",
    "\n",
    "                    print(logloss_str + \", \" + delta_loss)\n",
    "                    ax[0].plot(y.detach().cpu())\n",
    "                    ax[0].set_title(f\"Epoch {e}\" + \", \" + logloss_str)\n",
    "                    ax[0].set_xlabel(\"t\")\n",
    "\n",
    "                    ax[1].set_title(delta_loss)\n",
    "                    ax[1].plot(ydot.detach().cpu(), label = \"ydot\")\n",
    "                    #ax[0].plot(y_dot.detach(), label = \"dy_dx\")\n",
    "                    ax[2].clear()\n",
    "                    #weight_size = str(weight_size_sq.detach().item())\n",
    "                    #ax[2].set_title(\"loss history \\n and \"+ weight_size)\n",
    "\n",
    "                    ax[2].loglog(loss_history)\n",
    "                    ax[2].set_xlabel(\"t\")\n",
    "\n",
    "                    #[ax[i].legend() for i in range(3)]\n",
    "                    previous_loss = loss.item()\n",
    "\n",
    "                    #clear the plot outputt and then re-plot\n",
    "                    display.clear_output(wait=True) \n",
    "                    display.display(pl.gcf())\n",
    "\n",
    "\n",
    "        return {\"weights\": best_weight, \"bias\" : best_bias, \"y\" : best_fit, \"ydot\" : best_ydot, \n",
    "              \"loss\" : {\"loss_history\" : loss_history}, \"best_score\" : torch.tensor(best_score),\n",
    "              \"RC\" : esn}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expensive-contractor",
   "metadata": {
    "id": "expensive-contractor"
   },
   "outputs": [],
   "source": [
    "#y0s = array([-1.  , -0.25,  0.5 ,  1.25])\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artificial-exclusive",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "artificial-exclusive",
    "outputId": "2477f113-cd49-481b-9235-9eea5874d727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt -3.0\n",
      "n_nodes 500\n",
      "connectivity -1.7001224756240845\n",
      "spectral_radius 2.4289157390594482\n",
      "regularization 1.6905698776245117\n",
      "leaking_rate 0.0032216429244726896\n",
      "bias 0.3808490037918091\n",
      "enet_alpha 0.2040003091096878\n",
      "enet_strength -1.1255784034729004\n",
      "spikethreshold 0.4231834411621094\n",
      "gamma 0.09350859373807907\n",
      "gamma_cyclic 0.9999\n"
     ]
    }
   ],
   "source": [
    "log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt', 'enet_strength']\n",
    "\n",
    "#trained to 20*pi\n",
    "hps = {'dt': 0.001,\n",
    "       'n_nodes': 500,\n",
    "       'connectivity': 0.019946997092875757,\n",
    "       'spectral_radius': 2.4289157390594482,\n",
    "       'regularization': 49.04219249279563,\n",
    "       'leaking_rate': 0.0032216429244726896,\n",
    "       'bias': 0.3808490037918091,\n",
    "       'enet_alpha': 0.2040003091096878,\n",
    "       'enet_strength': 0.07488961475845243,\n",
    "       'spikethreshold': 0.4231834411621094,\n",
    "       'gamma': .09350859373807907,\n",
    "       'gamma_cyclic' : 0.9999}\n",
    "\n",
    "\n",
    "\n",
    "for key, val in hps.items():\n",
    "    if key in log_vars:\n",
    "        print(key, np.log10(val))\n",
    "    else:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-liberal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "historic-liberal",
    "outputId": "6ca6dfca-0e06-41dc-d491-1ecac296d804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURN_IN = 500\n",
    "\n",
    "#declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "bounds_dict = {\"connectivity\" : (-2, -1.4), #(-2, -0.5), \n",
    "               \"spectral_radius\" : (2.2, 2.6),#(0.01, 1),\n",
    "               \"n_nodes\" : 500,\n",
    "               \"regularization\" : 1.69, #(-4.4, 2.6),\n",
    "               \"leaking_rate\" : (0.00322 - 0.002, 0.00322 + 0.002),\n",
    "               \"dt\" : -3,#-3,\n",
    "               \"bias\": (-0.5, 0.5),\n",
    "               \"enet_alpha\": (0.18, 0.22), #(0,1.0),\n",
    "               \"enet_strength\": (-1.32,-0.92),\n",
    "               \"spikethreshold\" : (0.35,0.45),\n",
    "               \"gamma\" : (0.08,0.12),\n",
    "               \"gamma_cyclic\" : (float(np.log10(0.9997)), float(np.log10(0.99999))),#(-0.002176919254274547, 0)\n",
    "               }\n",
    "#set up data\n",
    "x0, xf = 0, 4*np.pi\n",
    "nsteps = int(abs(xf - x0)/(10**bounds_dict[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "int(xtrain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "living-coordination",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "living-coordination",
    "outputId": "440ede74-3e13-4d21-a2ea-e2a98dc07165",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK: None , device: None\n",
      "cpu\n",
      "m,n 1 500\n",
      "in_weights torch.Size([500, 1])\n",
      "Model initialization and exploration run...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, -1]' is invalid for input of size 501",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_trust_regions, max_evals, y, x, store_path, epochs, learning_rate, scoring_method, criterion, reparam_f, ODE_criterion, init_conditions, scale, force, backprop_f, backprop, ode_coefs, solve, rounds, tr_score_prop, q, eq_system, n_outputs, nonlinear_ode, reg_type)\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trust_regions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorz_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m             \u001b[0mbest_hyper_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_turbo_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorz_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36m_turbo_1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_turbo_initial_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturbo_state_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mn_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36m_turbo_initial_samples\u001b[0;34m(self, X_init, dim, turbo_state_id)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                 \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_init\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                 \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_objective\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturbo_state_id\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_turbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_turbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_turbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_turbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36meval_objective\u001b[0;34m(self, parameters, plot_type, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36mexecute_objective\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdictt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 \u001b[0mval_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalidate_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, y, X, y_start, steps_ahead, scoring_method, alpha, scale, criterion, reparam, ODE_criterion)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                     y_preds, ydots = self.predict(n_steps = X.shape[0], X=X, y_start=y_start, scale = scale,\n\u001b[0m\u001b[1;32m   1748\u001b[0m                                    continue_force = True)\n\u001b[1;32m   1749\u001b[0m                     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n_steps, X, y_start, continuation, scale, continue_force)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mODE_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m                 \u001b[0mstates_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m                 \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsupervised_val_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn.py\u001b[0m in \u001b[0;36munsupervised_val_states\u001b[0;34m(self, n_samples, inputs, states, outputs)\u001b[0m\n\u001b[1;32m   1831\u001b[0m             \u001b[0;31m#output_t = self.LinOut(extended_state_spec.T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0moutput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn.py\u001b[0m in \u001b[0;36moutput_i\u001b[0;34m(self, x, next_state)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mextended_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, -1]' is invalid for input of size 501"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            interactive = True, \n",
    "                            batch_size = 1, \n",
    "                            cv_samples = 1, \n",
    "                            initial_samples = 100,  #200\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.98),\n",
    "                            validate_fraction = 0.2,\n",
    "                            random_seed = 209, \n",
    "                            success_tolerance = 10,\n",
    "                            ODE_order = 1, \n",
    "                            length_min = 2 **(-8),\n",
    "                            esn_burn_in = BURN_IN, \n",
    "                            log_score = True,\n",
    "                            activation_function = torch.sin,\n",
    "                        act_f_prime = torch.cos,\n",
    "                            )\n",
    "#optimize:\n",
    "opt = True\n",
    "if opt:\n",
    "    opt_hps = esn_cv.optimize(\n",
    "                              x = xtrain.view(-1,1),\n",
    "                              reparam_f = reparam, \n",
    "                              ODE_criterion = custom_loss,\n",
    "                              init_conditions = [[1.1, 1.3], 1],#[[0,1], [0,1]], \n",
    "                              force = force,\n",
    "                              ode_coefs = [1, 1],\n",
    "                              rounds =1,\n",
    "                              backprop_f = optimize_last_layer, \n",
    "                              solve =  True, \n",
    "                              eq_system = True,\n",
    "                              n_outputs = 2,\n",
    "                              epochs =  5000,\n",
    "                              reg_type = \"ham\",\n",
    "                              tr_score_prop = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instrumental-oxford",
   "metadata": {
    "id": "instrumental-oxford"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt_hps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-78548435ba04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mopt_hps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'opt_hps' is not defined"
     ]
    }
   ],
   "source": [
    "if opt:\n",
    "    opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bZX9Yo1gLL8J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZX9Yo1gLL8J",
    "outputId": "c9ca4585-7b01-41be-dbb8-a660dd708807"
   },
   "outputs": [],
   "source": [
    "opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ncQX8tKLdMW",
   "metadata": {
    "id": "2ncQX8tKLdMW"
   },
   "outputs": [],
   "source": [
    "def f(u, t ,lam=0,A=0,W=1):\n",
    "            x,  px = u      # unpack current values of u\n",
    "            derivs = [px, -x - lam*x**3 +A*np.sin(W*t)]     # you write the derivative here\n",
    "            return derivs\n",
    "\n",
    "def convert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs\n",
    "        \n",
    "# Scipy Solver   \n",
    "def NLosc_solution(t, x0,  px0, lam=0, A=0,W=1):\n",
    "    u0 = [x0, px0]\n",
    "    # Call the ODE solver\n",
    "    solPend = odeint(f, u0, t.cpu(), args=(lam,A,W,))\n",
    "    xP = solPend[:,0];        pxP = solPend[:,1];   \n",
    "    return xP, pxP\n",
    "\n",
    "def plot_predictions(RC, results, integrator_model, y0s, ax = None,  \n",
    "                     int_color = \"maroon\", RC_color = \"aquamarine\", RC_linestyle =':'):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu().detach()\n",
    "    #int_sols = []\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    \n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu().detach()\n",
    "        if not i:\n",
    "            labels = [\"RC solver\",\"RC solver\", \"integrator\", \"integrator\"]\n",
    "        else:\n",
    "            labels = [None, None, None, None]\n",
    "        try:\n",
    "            labels\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #calculate the integrator prediction:\n",
    "        y_truth, p_truth  = NLosc_solution(RC.X.squeeze().data,y0s[i],1,lam=1, A=0, W= 0) \n",
    "        \n",
    "        #p = y[:,1].cpu()# + v0\n",
    "        #yy = y[:,0].cpu()# + y0\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(y_truth, p_truth,  color = int_color , linewidth = lineW+7, \n",
    "                label = labels[2])\n",
    "        \n",
    "        ax.plot(y[:,0], y[:,1], label = labels[0], \n",
    "                linewidth =lineW, color = RC_color, linestyle = RC_linestyle)#\"dodgerblue\")\n",
    "#         ax.plot(X, p, color = \"red\", alpha = 1.0, linewidth =3, \n",
    "#                 label = labels[3])\n",
    "        \n",
    "    ax.set_xlabel(r'$x(t)$')\n",
    "    ax.set_ylabel(r'$y(t)$')\n",
    "    ax.legend();\n",
    "    #return int_sols\n",
    "\n",
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)\n",
    "\n",
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu().detach()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = y.cpu().detach()\n",
    "        ydot = ydot.cpu().detach()\n",
    "        \n",
    "        ode_coefs = convert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False,\n",
    "                             ham = False,\n",
    "                             init_conds = RC.init_conds)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "            # label = r'{Individual Trajectory RMSR}'\n",
    "            label = 'Individual Trajectory Residuals'\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "            label = None\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, color = \"orangered\", alpha = 0.4, label = label, linewidth = lineW-1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "    ax.plot(X, rmsr, \n",
    "               color = \"blue\", \n",
    "               alpha = 0.9, \n",
    "               label = 'RMSR',\n",
    "               linewidth = lineW-0.5)\n",
    "\n",
    "    ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel('RMSR')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def driven_force(X, A = 1):\n",
    "    return A * torch.sin(X)\n",
    "\n",
    "def no_force(X, A = 0):\n",
    "    return A\n",
    "\n",
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot\n",
    "    \n",
    "    #first derivative\n",
    "    \n",
    "    \n",
    "    #example code for higher derivatives:\n",
    "    #####################################\n",
    "    \n",
    "    #derivatives_of_g.append(g_dot)\n",
    "    #derivatives_of_g.append(g)\n",
    "#     for i in range(order):\n",
    "#         if i %2 == 0:\n",
    "#             #print(\"even\")\n",
    "#             derivatives_of_g.append(g_dot)\n",
    "#         else:\n",
    "#             #print(\"odd\")\n",
    "#             derivatives_of_g.append(-g_dot)\n",
    "#    return derivatives_of_g\n",
    "\n",
    "\n",
    "def custom_loss(X, y, ydot, out_weights, force_t = force, \n",
    "                reg = False, ode_coefs = None, mean = True,\n",
    "               enet_strength = None, enet_alpha = None, init_conds = None, lam = 1, ham = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the population equation loss)\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "    ham : bool\n",
    "        if true use hamiltonian regularization.\n",
    "    lam : float\n",
    "        coefficient affecting the strength of the nonlinearity term.\n",
    "        \n",
    "    Returns:\n",
    "        the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    \n",
    "    y, p = y[:,0].view(-1,1), y[:,1].view(-1,1)\n",
    "    ydot, pdot = ydot[:,0].view(-1,1), ydot[:,1].view(-1,1)\n",
    "    \n",
    "    #with paramization\n",
    "    L =  (ydot - p)**2 + (pdot + y + lam * y**3   - force(X))**2\n",
    "    \n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    \n",
    "    if reg:\n",
    "        #assert False\n",
    "        weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "        weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "        L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "        L = L + 0.1 * L_reg \n",
    "    if ham:\n",
    "        y0, p0 = init_conds\n",
    "        ham = hamiltonian(y, p)\n",
    "        ham0 = hamiltonian(y0, p0)\n",
    "        L_H = (( ham - ham0).pow(2)).mean()\n",
    "        assert L_H >0\n",
    "\n",
    "        L = L +  0.1 * L_H\n",
    "    \n",
    "    #print(\"L1\", hi, \"L_elastic\", L_reg, \"L_H\", L_H)\n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JJYn2M4HLknj",
   "metadata": {
    "id": "JJYn2M4HLknj"
   },
   "outputs": [],
   "source": [
    "nl_oscillator_hp_set = opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rpq-00HDLNIL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpq-00HDLNIL",
    "outputId": "536c7dee-a47f-44b1-c807-0a07dfcd969b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y0s = np.arange(0.7, 1.8, 0.2)\n",
    "v0 = 1\n",
    "\n",
    "RC = EchoStateNetwork(**nl_oscillator_hp_set, \n",
    "                       random_state = 209, \n",
    "                       feedback = False, \n",
    "                       id_ = 10,\n",
    "                       activation_f = torch.sin,\n",
    "                       act_f_prime = torch.cos,\n",
    "                       dtype = torch.float32, n_outputs = 2)\n",
    "\n",
    "train_args = {\"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,\n",
    "              \"force\" : force,\n",
    "              \"reparam_f\" : reparam,\n",
    "              \"init_conditions\" : [y0s, float(v0)],\n",
    "              \"ode_coefs\" :       [1, 1],\n",
    "              \"X\" :   xtrain.view(-1, 1),\n",
    "              \"eq_system\" : True,\n",
    "              #\"out_weights\" : out_weights\n",
    "              }\n",
    "#fit\n",
    "results = RC.fit(**train_args, \n",
    "                 SOLVE = True,\n",
    "                 train_score = True,\n",
    "                 backprop_f = optimize_last_layer, \n",
    "                 epochs = 10000,\n",
    "                 ODE_criterion = custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7sgGClYbMf_Q",
   "metadata": {
    "id": "7sgGClYbMf_Q"
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_ha1x8ALcDj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "P_ha1x8ALcDj",
    "outputId": "21730022-54ef-4617-daff-b4070eb28cfd"
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 14}\n",
    "plt.rc('font', **font)\n",
    "fig = plt.figure(figsize = (7,9)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(RC, results, NLosc_solution, y0s, ax = ax, int_color = \"black\", RC_color = \"cyan\")\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "# plot_data = plot_rmsr(pop_RC, \n",
    "#                           results, \n",
    "#                           force = no_force, \n",
    "#                           ax = ax)\n",
    "\n",
    "plot_data = plot_rmsr(RC,\n",
    "                      results, \n",
    "                      force = no_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yM3WRr9RLydk",
   "metadata": {
    "id": "yM3WRr9RLydk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "systems_BO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
