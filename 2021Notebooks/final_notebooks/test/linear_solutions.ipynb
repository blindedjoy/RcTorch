{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wanted-burden",
   "metadata": {},
   "source": [
    "# RcTorch 2021 NuerIPS submission Notebook 1\n",
    "## Exact solutions: 1st order  Linear ODE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from RcTorch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install rctorch==0.7163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',#'bold',\n",
    "        'size'   : 24}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-brighton",
   "metadata": {},
   "source": [
    "### This notebook contains the solutions to the linear first order explicitily time-dependent equation   of the form $\\dot y + q(t) y = f(t) $.\n",
    "\n",
    "Specifically we solve three related differential equations:\n",
    "1) Simple population:  <font color='blue'>$\\dot y + y =0$  </font>\n",
    "* Analytical solution: <font color='green'>$y = y_0 e^{-t}$</font>\n",
    "\n",
    "2) Driven population:  <font color='blue'>$\\dot y + y + \\sin(t) =0$ </font>\n",
    "* Analytical solution: <font color='green'>$y = e^{-t}\\left(y_0 + \\frac{1}{2}\\right) + \\frac{1}{2}\\left( \\sin(t) - \\cos(t) \\right)$ </font>\n",
    "\n",
    "3) Driven population with nonlinear time dependence:  <font color='blue'> $\\dot y + t^2 y + \\sin(t) =0$  </font>\n",
    "* Analytical solution: None\n",
    "\n",
    "### Limitations:\n",
    "    Only the first initial condition can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-combine",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(RC, results, integrator_model, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu()\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu()\n",
    "        if not i:\n",
    "            labels = [\"RC\", \"Integrator Solution\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        ax.plot(X, y, color = \"dodgerblue\", label = labels[0], linewidth = lineW + 1, alpha = 0.9)\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"red\", alpha = 0.9, label = labels[1],  linewidth = lineW)\n",
    "    \n",
    "    plt.ylabel(r'$y(t)$');\n",
    "    ax.legend();\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def convert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    Returns\n",
    "    -------\n",
    "    ode_coefs\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs\n",
    "    \n",
    "\n",
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = y.cpu()\n",
    "        ydot = ydot.cpu()\n",
    "        \n",
    "        ode_coefs = convert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "            label = r'{Individual Trajectory RMSR}'\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "            label = None\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, color = \"orangered\", alpha = 0.4, label = label, linewidth = lineW-1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "    ax.plot(X, rmsr, \n",
    "               color = \"blue\", \n",
    "               alpha = 0.9, \n",
    "               label = r'{RMSR}',\n",
    "               linewidth = lineW-0.5)\n",
    "\n",
    "    ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(r'{RMSR}')\n",
    "\n",
    "def driven_force(X, A = 1):\n",
    "    \"\"\" a force function, specifically f(t) = sin(t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, a torch.tensor of equal dimension to the input time tensor.\n",
    "    \"\"\"\n",
    "    return A * torch.sin(X)\n",
    "\n",
    "def no_force(X):\n",
    "    \"\"\" a force function (returns 0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, in this case 0.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \"\"\" A reparameterization function, specifically g= 1-e^(-t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        the input time tensor\n",
    "    order:\n",
    "        the ODE order\n",
    "    \n",
    "    Returns:\n",
    "    g: torch.tensor\n",
    "        the reparameterization of t which satisfies the initial conditions\n",
    "    g_dot: torch.tensor\n",
    "        the time derivative of g\n",
    "    Returns\n",
    "    -------\n",
    "    g, gdot\n",
    "    \"\"\"\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot\n",
    "    \n",
    "    #first derivative\n",
    "    \n",
    "    \n",
    "    #example code for higher derivatives:\n",
    "    #####################################\n",
    "    \n",
    "    #derivatives_of_g.append(g_dot)\n",
    "    #derivatives_of_g.append(g)\n",
    "#     for i in range(order):\n",
    "#         if i %2 == 0:\n",
    "#             #print(\"even\")\n",
    "#             derivatives_of_g.append(g_dot)\n",
    "#         else:\n",
    "#             #print(\"odd\")\n",
    "#             derivatives_of_g.append(-g_dot)\n",
    "#    return derivatives_of_g\n",
    "\n",
    "\n",
    "#simple population eq loss\n",
    "def custom_loss(X, y, ydot, out_weights, \n",
    "                enet_strength = None,\n",
    "                enet_alpha = None,\n",
    "                ode_coefs = None,\n",
    "                force_t = None, \n",
    "                reg = True, \n",
    "                reparam = reparam, \n",
    "                init_conds = None,\n",
    "                mean = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the population equation loss)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    \n",
    "    #lam is short for lambda\n",
    "    lam = ode_coefs[0]\n",
    "    L =  ydot + lam * y - force_t\n",
    "    \n",
    "    L = torch.square(L)\n",
    "    \n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    \n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "BURN_IN = 1000\n",
    "x0,xf, nsteps = 0, 5, 1000\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False)\n",
    "\n",
    "#the length of xtrain won't matter above. Only dt , x0, and xf matter for ODEs.\n",
    "#the reason for this is that the input time vector is reconstructed internally in rctorch\n",
    "#in order to satisfy the specified dt.\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pop_hps = {'dt': 0.0031622776601683794,\n",
    " 'n_nodes': 250,\n",
    " 'connectivity': 0.7170604557008349,\n",
    " 'spectral_radius': 1.5755887031555176,\n",
    " 'regularization': 0.00034441529823729916,\n",
    " 'leaking_rate': 0.9272222518920898,\n",
    " 'bias': 0.1780446171760559}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-chicken",
   "metadata": {},
   "source": [
    "### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-sapphire",
   "metadata": {},
   "source": [
    "#### Train the RC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pop_RC = EchoStateNetwork(**simple_pop_hps,\n",
    "                          random_state = 209, \n",
    "                          dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : no_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1,1]}\n",
    "\n",
    "\n",
    "results = pop_RC.fit(init_conditions = [y0s,1],\n",
    "                     train_score = True, \n",
    "                     ODE_criterion = custom_loss,\n",
    "                     **train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-device",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrator model\n",
    "def population_model(y, t, t_pow = 0, force_k = 0, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-painting",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (9,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(pop_RC, results, population_model, ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                          results, \n",
    "                          force = no_force, \n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-pierre",
   "metadata": {},
   "source": [
    "# Driven population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-litigation",
   "metadata": {},
   "source": [
    "#### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-latin",
   "metadata": {},
   "source": [
    "#### Train the RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.0031622776601683794)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "driven_pop_hps = {'dt': 0.0031622776601683794,\n",
    "                  'n_nodes': 500,\n",
    "                  'connectivity': 0.7875262340500385,\n",
    "                  'spectral_radius': 9.97140121459961,\n",
    "                  'regularization': 8.656278081920211,\n",
    "                  'leaking_rate': 0.007868987508118153,\n",
    "                  'bias': -0.2435922622680664}\n",
    "\n",
    "#another example: (command + backslash after highlighting will uncomment all the lines at once)\n",
    "# driven_pop_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 400,\n",
    "#  'connectivity': 0.012634199142753764,\n",
    "#  'spectral_radius': 5.489274978637695,\n",
    "#  'regularization': 9.489825036097473,\n",
    "#  'leaking_rate': 0.0023584181908518076,\n",
    "#  'bias': 0.45648694038391113}\n",
    "\n",
    "driven_RC = EchoStateNetwork(**driven_pop_hps,\n",
    "                             random_state = 209,\n",
    "                             dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1,1]}\n",
    "\n",
    "driven_results = driven_RC.fit(init_conditions = [y0s,1],\n",
    "                 **train_args, \n",
    "                 SOLVE = True,\n",
    "                 train_score = True, \n",
    "                 ODE_criterion = custom_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-weight",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop_model(y, t, t_pow = 0, force_k = 1):\n",
    "    k = 1\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-precipitation",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "\n",
    "plot_predictions(RC = driven_RC, \n",
    "                 results = driven_results, \n",
    "                 integrator_model = driven_pop_model, \n",
    "                 ax = ax)\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_rmsr(RC = driven_RC, \n",
    "          results = driven_results, \n",
    "          force = driven_force, \n",
    "          ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-excess",
   "metadata": {},
   "source": [
    "# Driven population with nonlinear time dependence (t^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-girlfriend",
   "metadata": {},
   "source": [
    "#### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-romance",
   "metadata": {},
   "source": [
    "#### Train the RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Bayesian Optimization was run on a power of 2. Feel free to play around with this value. \n",
    "pow_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_hps =  {'n_nodes': 500,\n",
    "           'connectivity': 0.09905712745750006,\n",
    "           'spectral_radius': 1.8904799222946167,\n",
    "           'regularization': 714.156090350679,\n",
    "           'leaking_rate': 0.031645022332668304,\n",
    "           'bias': -0.24167031049728394,\n",
    "           'dt' : 0.005}\n",
    "\n",
    "\n",
    "\n",
    "t2_RC = EchoStateNetwork(**t2_hps,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [f\"t**{pow_}\", 1]}\n",
    "\n",
    "\n",
    "t2_results = t2_RC.fit(init_conditions = [y0s,1],\n",
    "                       SOLVE = True,\n",
    "                       train_score = True, \n",
    "                       ODE_criterion = custom_loss,\n",
    "                       **train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-olive",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop_model_t2(y, t, t_pow = pow_, force_k = 1):\n",
    "    k = 1\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-arthritis",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = t2_RC, \n",
    "                       results = t2_results, \n",
    "                       integrator_model = driven_pop_model_t2, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(t2_RC, \n",
    "                      results = t2_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
