{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tamil-department",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rctorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-43fe50a557dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrctorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rctorch'"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from RcTorch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install rctorch==0.7163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-panic",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to use RcTorch to find optimal hyper-paramters for the differential equation $\\dot y + q(t) y = f(t) $.\n",
    "\n",
    "Simple population:  <font color='blue'>$\\dot y + y =0$  </font>\n",
    "* Analytical solution: <font color='green'>$y = y_0 e^{-t}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(RC, results, integrator_model, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu()\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu()\n",
    "        if not i:\n",
    "            labels = [\"RC\", \"Integrator Solution\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        ax.plot(X, y, color = \"dodgerblue\", label = labels[0], linewidth = lineW + 1, alpha = 0.9)\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"red\", alpha = 0.9, label = labels[1],  linewidth = lineW)\n",
    "    \n",
    "    plt.ylabel(r'$y(t)$');\n",
    "    ax.legend();\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def covert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    Returns\n",
    "    -------\n",
    "    ode_coefs\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs\n",
    "    \n",
    "\n",
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = y.cpu()\n",
    "        ydot = ydot.cpu()\n",
    "        \n",
    "        ode_coefs = covert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "            label = r'{Individual Trajectory RMSR}'\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "            label = None\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, color = \"orangered\", alpha = 0.4, label = label, linewidth = lineW-1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "    ax.plot(X, rmsr, \n",
    "               color = \"blue\", \n",
    "               alpha = 0.9, \n",
    "               label = r'{RMSR}',\n",
    "               linewidth = lineW-0.5)\n",
    "\n",
    "    ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(r'{RMSR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common cv arguments:\n",
    "cv_declaration_args = {\"interactive\" : True, \n",
    "                       \"batch_size\" : 8, #batch size is parallel\n",
    "                       \"cv_samples\" : 2, #number of cv_samples, random start points\n",
    "                       \"initial_samples\" : 50, #number of random samples before optimization starts\n",
    "                       \"validate_fraction\" : 0.3, #validation prop of tr+val sets\n",
    "                       \"log_score\" : True, #log-residuals\n",
    "                       \"random_seed\" : 209, # random seed\n",
    "                       \"ODE_order\" : 1, #order of eq\n",
    "                       #see turbo ref:\n",
    "                       \"length_min\" : 2 ** (-7),#2 **(-7), \n",
    "                       \"success_tolerance\" : 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-vermont",
   "metadata": {},
   "source": [
    "## task 1: cross check burn in for all three experiments (burn in should be embedded into hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_force(X, A = 1):\n",
    "    \"\"\" a force function, specifically f(t) = sin(t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, a torch.tensor of equal dimension to the input time tensor.\n",
    "    \"\"\"\n",
    "    return A*torch.sin(X)\n",
    "\n",
    "def no_force(X):\n",
    "    \"\"\" a force function (returns 0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, in this case 0.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "lam =1\n",
    "def custom_loss(X , y, ydot, out_weights, lam = lam, force_t = None, reg = False, \n",
    "               ode_coefs = None, init_conds = None, \n",
    "                enet_alpha = None, enet_strength =None, mean = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the population equation loss)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    #with paramization\n",
    "    L =  ydot  + lam * y - force_t\n",
    "    \n",
    "#     if reg:\n",
    "#         #assert False\n",
    "#         weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "#         weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "#         L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "#         L = L + 0.1 * L_reg \n",
    "    \n",
    "    L = torch.square(L)\n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the initial conditions (each initial condition corresponds to a different curve)\n",
    "y0s = np.arange(0.1, 2.1, 0.1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-watch",
   "metadata": {},
   "source": [
    "### Simple population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "bounds_dict = {\"connectivity\" : (-2.2, -0.12), #log space\n",
    "               \"spectral_radius\" : (1, 10), #lin space\n",
    "               \"n_nodes\" : 250, \n",
    "               \"regularization\" : (-4, 4), #log space\n",
    "               \"leaking_rate\" : (0, 1),    #linear space\n",
    "               \"dt\" : -2.5, #log space\n",
    "               \"bias\": (-0.75,0.75) #linear space\n",
    "               }\n",
    "\n",
    "#set up data\n",
    "x0, xf = 0, 5\n",
    "nsteps = int(abs(xf - x0)/(10**bounds_dict[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "int(xtrain.shape[0] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 500, #states to throw away before calculating output\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.8), #combine len of tr + val sets\n",
    "                            **cv_declaration_args\n",
    "                            )\n",
    "#optimize the network:\n",
    "simple_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                          reparam_f = reparam, \n",
    "                          ODE_criterion = custom_loss,\n",
    "                          init_conditions = [y0s], \n",
    "                          force = no_force,\n",
    "                          ode_coefs = [1, 1],\n",
    "                          n_outputs = 1,\n",
    "                          reg_type = \"simple_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pop_RC = EchoStateNetwork(**simple_pop_hps,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 500, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : no_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1, 1]}\n",
    "\n",
    "\n",
    "pop_results = pop_RC.fit(init_conditions = [y0s,1],\n",
    "                        SOLVE = True,\n",
    "                        train_score = True, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_pop(y, t, t_pow = 0, force_k = 0, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: show results outside BO range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some particularly good runs:\n",
    "\n",
    "# simple_pop_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.13615401772200952,\n",
    "#  'spectral_radius': 4.1387834548950195,\n",
    "#  'regularization': 0.00028325262824591835,\n",
    "#  'leaking_rate': 0.2962796092033386,\n",
    "#  'bias': -0.5639935731887817}\n",
    "\n",
    "# opt_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.7170604557008349,\n",
    "#  'spectral_radius': 1.5755887031555176,\n",
    "#  'regularization': 0.00034441529823729916,\n",
    "#  'leaking_rate': 0.9272222518920898,\n",
    "#  'bias': 0.1780446171760559}\n",
    "\n",
    "# opt_hps = {'dt': 0.0017782794100389228,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.11197846061157432,\n",
    "#  'spectral_radius': 1.7452095746994019,\n",
    "#  'regularization': 0.00012929296298723957,\n",
    "#  'leaking_rate': 0.7733328938484192,\n",
    "#  'bias': 0.1652531623840332}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = pop_RC, \n",
    "                       results = pop_results, \n",
    "                       integrator_model = simple_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                      results = pop_results, \n",
    "                      force = no_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-quebec",
   "metadata": {},
   "source": [
    "### Driven population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "bounds_dict = {\"connectivity\" : (-2, -0.12), #log space\n",
    "               \"spectral_radius\" : (1, 10), #lin space\n",
    "               \"n_nodes\" : 400, \n",
    "               \"regularization\" : (-4, 4), #log space\n",
    "               \"leaking_rate\" : (0, 1),    #linear space\n",
    "               \"dt\" : -2.5, #log space\n",
    "               \"bias\": (-0.75,0.75) #linear space\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 500, #states to throw away before calculating output\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.8), #combine len of tr + val sets\n",
    "                            **cv_declaration_args\n",
    "                            )\n",
    "#optimize the network:\n",
    "driven_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                          reparam_f = reparam, \n",
    "                          ODE_criterion = custom_loss,\n",
    "                          init_conditions = [y0s], \n",
    "                          force = driven_force,\n",
    "                          ode_coefs = [1, 1],\n",
    "                          n_outputs = 1,\n",
    "                          reg_type = \"driven_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-10, 10.1, 1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "driven_RC = EchoStateNetwork(**driven_pop_hps,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 500, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1, 1]}\n",
    "\n",
    "\n",
    "driven_results = driven_RC.fit(init_conditions = [y0s,1],\n",
    "                    SOLVE = True,\n",
    "                    train_score = True, \n",
    "                    ODE_criterion = custom_loss,\n",
    "                    **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop(y, t, t_pow = 0, force_k = 1, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "driven_pop_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = driven_RC, \n",
    "                       results = driven_results, \n",
    "                       integrator_model = driven_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(driven_RC, \n",
    "                      results = driven_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-colombia",
   "metadata": {},
   "source": [
    "#### Driven t^2 Population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the initial conditions (each initial condition corresponds to a different curve)\n",
    "y0s = np.arange(-10, 10.1, 0.1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "\n",
    "t2_hps =  {'n_nodes': 500,\n",
    "           'connectivity': 0.09905712745750006,\n",
    "           'spectral_radius': 1.8904799222946167,\n",
    "           'regularization': 714.156090350679,\n",
    "           'leaking_rate': 0.031645022332668304,\n",
    "           'bias': -0.24167031049728394,\n",
    "           'dt' : 0.005}\n",
    "\n",
    "bounds_dict = {\"connectivity\" : (-1.1, -0.9), #log space\n",
    "               \"spectral_radius\" : (1.8, 2.0), #lin space\n",
    "               \"n_nodes\" : 500, \n",
    "               \"regularization\" : (2.5, 3.5), #log space\n",
    "               \"leaking_rate\" : (0.02, .04),    #linear space\n",
    "               \"dt\" : -2.3, #log space\n",
    "               \"bias\": (0,1) #linear space\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 1000, #states to throw away before calculating output\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.8), #combine len of tr + val sets\n",
    "                            **cv_declaration_args\n",
    "                            )\n",
    "#optimize the network:\n",
    "t2_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                          reparam_f = reparam, \n",
    "                          ODE_criterion = custom_loss,\n",
    "                          init_conditions = [y0s], \n",
    "                          force = driven_force,\n",
    "                          ode_coefs = [\"t^2\", 1],\n",
    "                          n_outputs = 1,\n",
    "                          reg_type = \"driven_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution run:\n",
    "# t2_hps =  {'n_nodes': 500,\n",
    "#            'connectivity': 0.09905712745750006,\n",
    "#            'spectral_radius': 1.8904799222946167,\n",
    "#            'regularization': 714.156090350679,\n",
    "#            'leaking_rate': 0.031645022332668304,\n",
    "#            'bias': -0.24167031049728394,\n",
    "#            'dt' : 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_pop(y, t, t_pow = 2, force_k = 1, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_RC = EchoStateNetwork(**t2_pop_hps,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 1000, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [\"t^2\", 1]}\n",
    "\n",
    "\n",
    "t2_results = t2_RC.fit(init_conditions = [y0s,1],\n",
    "                        SOLVE = True,\n",
    "                        train_score = True, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_RC.ode_coefs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = t2_RC, \n",
    "                       results = t2_results, \n",
    "                       integrator_model = t2_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(t2_RC, \n",
    "                      results = t2_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
