{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD Observers prediction\n",
    "\n",
    "#### we want the BO runs to be consistant to attempt to isolate the independent variables:\n",
    "\n",
    "# %%time\n",
    "# n = 8\n",
    "# BO_specs = {\"scoring_method\" : \"nmse\",\n",
    "#             \"n_jobs\" : n,\n",
    "#             \"cv_samples\" : 3,\n",
    "#             \"initial_samples\" : n,\n",
    "#             \"random_seed\" : 209,\n",
    "#             \"feedback\" : True\n",
    "#            }\n",
    "\n",
    "# #declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "# bounds_dict = {\"connectivity\" : (-2.5, -0.1), \n",
    "#                \"spectral_radius\" : (0.1, 3),\n",
    "#                \"n_nodes\" : (300,302),\n",
    "#                \"regularization\" : (-3, 1),\n",
    "#                \"leaking_rate\" : (0, 0.2),\n",
    "# #                \"input_scaling\" : 2,\n",
    "# #                \"feedback_scaling\" : 2,\n",
    "#                \"bias\": (-1,1),\n",
    "#                #\"mu\" : (-1, 1),\n",
    "#                #\"sigma\" : (-3, 0.1),\n",
    "#                #\"noise\" : (-5, -3)\n",
    "#                #\"output_scaling\" : (1,3)\n",
    "#                }\n",
    "\n",
    "# #declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "# esn_cv = RcBayesOpt(bounds = bounds_dict, \n",
    "#                             #reservoir_weight_dist = \"normal\",\n",
    "#                             output_activation = \"tanh\",\n",
    "#                             **BO_specs)\n",
    "# #optimize:\n",
    "# opt = False\n",
    "# if opt:\n",
    "#     opt_hps = esn_cv.optimize( n_trust_regions = 5, \n",
    "#                                max_evals = 2000,  \n",
    "#                                x = input_train,\n",
    "#                                y = target_train)\n",
    "# if opt:\n",
    "#     esn_cv.recover_hps()\n",
    "\n",
    "# hps = {'n_nodes': 500,\n",
    "#  'connectivity': 0.6515588349613025,\n",
    "#  'spectral_radius': 1.024013638496399,\n",
    "#  'regularization': 0.29548797260648485,\n",
    "#  'leaking_rate': 0.014079268090426922,\n",
    "#  'bias': 0.15175355970859528}\n",
    "\n",
    "# hps = {'connectivity': 0.19090760563281484,\n",
    "#  'spectral_radius': 1.1401275396347046,\n",
    "#  'n_nodes': int(92.07780456542969),\n",
    "#  'regularization': 4.162623413287334,\n",
    "#  'leaking_rate': 0.016683321446180344,\n",
    "#  'bias': 0.3127695918083191}\n",
    "\n",
    "# hps = {'connectivity': 0.22232790866090735,\n",
    "#  'spectral_radius': 1.7917426824569702,\n",
    "#  'n_nodes': 502,#201,\n",
    "#  'regularization': 33.29470005757839,\n",
    "#  'leaking_rate': 0.010284705087542534,\n",
    "#  'bias': 0.29019832611083984}\n",
    "\n",
    "# hps = {'connectivity': 0.2545103522116427,\n",
    "#  'spectral_radius': 1.2887651920318604,\n",
    "#  'n_nodes': 200.5666961669922,\n",
    "#  'regularization': 1.5391895246428107,\n",
    "#  'leaking_rate': 0.014173735864460468,\n",
    "#  'bias': 0.812420129776001}\n",
    "\n",
    "# hps = {'connectivity': 0.44206079836399054,\n",
    "#  'spectral_radius': 1.4103726148605347,\n",
    "#  'n_nodes': int(201.42913818359375),\n",
    "#  'regularization': 1.4851671719296318,\n",
    "#  'leaking_rate': 0.007263404317200184,\n",
    "#  'bias': 0.7369199395179749}\n",
    "\n",
    "# hps = {'n_nodes': 250,\n",
    "#  'connectivity': 0.3848504349240071,\n",
    "#  'spectral_radius': 1.2713347673416138,\n",
    "#  'regularization': 823.3555650381094,\n",
    "#  'leaking_rate': 0.03272116184234619,\n",
    "#  'bias': 0.9980815649032593}\n",
    "\n",
    "hps = {'n_nodes': 500,\n",
    " 'connectivity': 0.6475559084256522,\n",
    " 'spectral_radius': 1.0265705585479736,\n",
    " 'regularization': 61.27292863528506,\n",
    " 'leaking_rate': 0.010949543677270412,\n",
    " 'bias': 0.5907618999481201}\n",
    "\n",
    "hps = {'connectivity': 0.20655561822580487,\n",
    " 'spectral_radius': 1.4234678745269775,\n",
    " 'n_nodes': int(201.70262145996094),\n",
    " 'regularization': 0.3997886703867961,\n",
    " 'leaking_rate': 0.01731570065021515,\n",
    " 'bias': 0.8803510665893555,\n",
    " 'mu': -0.929905354976654,\n",
    " 'sigma': 0.0015868513697625247,\n",
    " 'noise': 0.0010307216388310927}\n",
    "\n",
    "hps = {'connectivity': 0.4071449746896983,\n",
    " 'spectral_radius': 1.1329107284545898,# 1.1329107284545898,\n",
    " 'n_nodes': round(201.7901153564453),\n",
    " 'regularization': 1.6862021450927922,\n",
    " 'leaking_rate': 0.009808523580431938,\n",
    " #'reservoir_sigma' : 0.5, \n",
    " 'bias': 0.48509588837623596}\n",
    "\n",
    "#perfect hps!\n",
    "# hps = {'connectivity': 0.20655561822580487,\n",
    "#  'spectral_radius': 1.4234678745269775,\n",
    "#  'n_nodes': int(201.70262145996094),\n",
    "#  'regularization': 0.3997886703867961,\n",
    "#  'leaking_rate': 0.01731570065021515,\n",
    "#  'bias': 0.8803510665893555,\n",
    "#  'mu': -0.929905354976654,\n",
    "#  'sigma': 0.0015868513697625247,\n",
    "#  'noise': 0.0010307216388310927}\n",
    "#\n",
    "#tanh output, normal weight_dist\n",
    "# hps = {'connectivity': 0.21668282526532864,\n",
    "#      'spectral_radius': 1.944718599319458,\n",
    "#      'n_nodes': 201.74868774414062,\n",
    "#      'regularization': 5.010329581359477,\n",
    "#      'leaking_rate': 0.03689704090356827,\n",
    "#      'input_scaling': 1.5635757446289062,\n",
    "#      'feedback_scaling': 0.6511024236679077,\n",
    "#      'bias': -0.22786188125610352,\n",
    "#      'mu': -0.21370232105255127,\n",
    "#      'sigma': 0.01977205184851152,\n",
    "#      'noise': 3.932397588575517e-05}\n",
    "\n",
    "#tanh output, uniform weight_dist\n",
    "# hps = {'connectivity': 0.14436680312554895,\n",
    "#  'spectral_radius': 0.10749161243438721,\n",
    "#  'n_nodes': 301.9764709472656,\n",
    "#  'regularization': 0.021916770637338275,\n",
    "#  'leaking_rate': 0.03038833849132061,\n",
    "#  'bias': -0.3209759593009949}\n",
    "\n",
    "# hps = {'connectivity': 0.005622443974694787,\n",
    "#  'spectral_radius': 1.725818157196045,\n",
    "#  'n_nodes': 300.2403259277344,\n",
    "#  'regularization': 1.9004283877575394,\n",
    "#  'leaking_rate': 0.02534565143287182,\n",
    "#  'bias': 0.34716320037841797}\n",
    "\n",
    "esn_pure_pred = RcNetwork(**hps, \n",
    "                           #reservoir_weight_dist = \"normal\",\n",
    "                           output_activation = \"tanh\",\n",
    "                           activation_function = {\"tanh\" : 0.25,\n",
    "                                                  \"sincos\": 0.25, \n",
    "                                                  \"relu\" : 0.25, \n",
    "                                                  \"relu\": 0.25},\n",
    "                           random_state = 209, \n",
    "                           feedback = True)\n",
    "esn_pure_pred.fit(X = input_train, \n",
    "                  y = target_train,\n",
    "                  burn_in = 0)\n",
    "\n",
    "score, prediction = esn_pure_pred.test(X = input_test,\n",
    "            y = target_test)\n",
    "esn_pure_pred.combined_plot()\n",
    "final_figure_plot(target_test, None, prediction )\n",
    "print(f'score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### OLD NOISE + Observers\n",
    "\n",
    "## Observers\n",
    "\n",
    "#### We know make the RC aware of the force on the pendulum. In this case it is a simple sign wave:\n",
    "\n",
    "#this worked much much better: use only the force\n",
    "# observer_hps = {'n_nodes': 500,\n",
    "#  'connectivity': 0.5798420634720975,\n",
    "#  'spectral_radius': 1.0032602548599243,\n",
    "#  'regularization': 1.4057380362176872,\n",
    "#  'leaking_rate': 0.03928276151418686,\n",
    "#  'bias': 0.8688077926635742}\n",
    "#only made it to 26%\n",
    "\n",
    "#trained on the pure pred!!!\n",
    "\n",
    "\n",
    "# observer_hps_few = {'n_nodes': 50,\n",
    "#  'connectivity': 0.3693356735501038,\n",
    "#  'spectral_radius': 1.3087280988693237,\n",
    "#  'regularization': 0.5560008611735463,\n",
    "#  'leaking_rate': 0.03504343703389168,\n",
    "#  'bias': 0.8609387278556824}\n",
    "\n",
    "# noise_hps_obs = {'n_nodes': 500,\n",
    "#                  'connectivity': 0.10491582558764742,\n",
    "#                  'spectral_radius': 1.1205819845199585,\n",
    "#                  'regularization': 0.5785736697071299,\n",
    "#                  'leaking_rate': 0.016848361119627953,\n",
    "#                  'bias': 0.501275897026062}\n",
    "\n",
    "# my_esn = RcNetwork(**noise_hps_obs, \n",
    "#                 random_state = 210, \n",
    "#                 feedback = 1,\n",
    "#                 n_inputs = 1,\n",
    "#                 n_outputs = 2)\n",
    "# my_esn.fit(X = input_train, \n",
    "#             y = noisy_tr_target, \n",
    "#             burn_in = 0)\n",
    "# score, prediction = my_esn.test(X = input_test,\n",
    "#             y = noisy_te_target)\n",
    "\n",
    "# my_esn.combined_plot(gt_tr_override= target_train,\n",
    "#                     gt_te_override=target_test)\n",
    "# print(score)\n",
    "\n",
    "# final_figure_plot(test_gt = target_test, noisy_test_gt = noisy_te_target, rc_pred = prediction, \n",
    "#                   noisy_format = '.')\n",
    "\n",
    "\n",
    "# noise_hps_obs = {'n_nodes': 500,\n",
    "#                  'connectivity': 0.10491582558764742,\n",
    "#                  'spectral_radius': 1.1205819845199585,\n",
    "#                  'regularization': 0.5785736697071299,\n",
    "#                  'leaking_rate': 0.016848361119627953,\n",
    "#                  'bias': 0.501275897026062,\n",
    "#                  'input_connectivity' : 0.8}\n",
    "\n",
    "# my_esn = EchoStateNetwork(**noise_hps_obs, \n",
    "#                 random_state = 210, \n",
    "#                 feedback = 1,\n",
    "#                 n_inputs = 1,\n",
    "#                 output_activation = \"tanh\",\n",
    "#                 n_outputs = 2)\n",
    "# my_esn.fit(X = input_train, \n",
    "#             y = noisy_tr_target, \n",
    "#             burn_in = 0)\n",
    "# score, prediction = my_esn.test(X = input_test,\n",
    "#             y = noisy_te_target)\n",
    "\n",
    "# my_esn.combined_plot(gt_tr_override=target_train,\n",
    "#                     gt_te_override=target_test)\n",
    "# print(score)\n",
    "\n",
    "# final_figure_plot(test_gt = target_test, noisy_test_gt = noisy_te_target, rc_pred = prediction, \n",
    "#                   noisy_format = '.')\n",
    "\n",
    "# plt.figure(figsize = (14, 4))\n",
    "# plt.plot(c)\n",
    "# plt.show()\n",
    "# my_esn.combined_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Discrete Noise hps observers\n",
    "\n",
    "\n",
    "# discrete_hps2 = {'spectral_radius': 1.9291129112243652,\n",
    "#  'n_nodes': 200.56570434570312,\n",
    "#  'regularization': 2.3939659316287334,\n",
    "#  'leaking_rate': 0.008858037181198597,\n",
    "#  'input_scaling': 0.6510524749755859,\n",
    "#  'feedback_scaling': 0.7861567735671997,\n",
    "#  'reservoir_sigma': 0.1491946280002594,\n",
    "#  'connectivity': 0.2279595044244263,\n",
    "#  'input_connectivity': 0.8417609601537969,\n",
    "#  'feedback_connectivity': 0.8821485801869249,\n",
    "#  'bias': 0.715965986251831}\n",
    "\n",
    "\n",
    "# noise_obs_esn = RcNetwork(**discrete_hps2, \n",
    "#                 random_state = 210, \n",
    "#                 reservoir_weight_dist = \"discrete\",\n",
    "#                 input_weight_dist = \"discrete\",\n",
    "#                 feedback_weight_dist = \"discrete\",\n",
    "#                 output_activation = \"tanh\",\n",
    "#                 feedback = 1)\n",
    "# #                 n_inputs = 1,\n",
    "# #                 n_outputs = 2)\n",
    "# noise_obs_esn.fit(X =  input_train, \n",
    "#             y = noisy_tr_target,\n",
    "#             burn_in = 0)\n",
    "# score, prediction = noise_obs_esn.test(X = input_test,\n",
    "#             y = noisy_te_target)\n",
    "# noise_obs_esn.combined_plot(gt_tr_override=target_train,\n",
    "#                             gt_te_override=target_test)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD pure prediction with noise\n",
    "\n",
    "# desired_length = 60*np.pi\n",
    "# Nt = int(desired_length//dt)\n",
    "# t = np.linspace(0, desired_length, Nt) #100*np.pi\n",
    "# x0, px0 = .5, .5\n",
    "\n",
    "# my_fp = Fpendulum(t = t, x0 = x0, px0 = px0, A = 0.5, W = 0.2, force = \"sin\")\n",
    "# force_pend_data = my_fp.force_pend_data\n",
    "# input_ = my_fp.force(t = my_fp.t, A = 0.5, W = 0.2)\n",
    "\n",
    "# force_pend_data = torch.tensor(force_pend_data, dtype = torch.float32)\n",
    "# input_ = torch.tensor(input_, dtype = torch.float32)\n",
    "\n",
    "\n",
    "# split = 0.2\n",
    "# noise = 0.2\n",
    "\n",
    "\n",
    "# input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, split)\n",
    "# #input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, 0.6)\n",
    "# exp2_splitter = Splitter(force_pend_data, noise = True, std = noise, split = split)\n",
    "# noisy_tr_target, noisy_te_target = exp2_splitter.split()#make_noisy_data(force_pend_data, std = 0.2, split_ = 0.6)\n",
    "\n",
    "# c = torch.cat((noisy_tr_target, noisy_te_target), axis = 0)\n",
    "\n",
    "# #declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "# n = 6\n",
    "# BO_specs = {\"scoring_method\" : \"nmse\",\n",
    "#             \"n_jobs\" : n,\n",
    "#             \"cv_samples\" : 3,\n",
    "#             \"initial_samples\" : n,\n",
    "#             \"random_seed\" : 210,\n",
    "#             \"feedback\" : True,\n",
    "#             \"output_activation\" : \"tanh\",\n",
    "#             \"reservoir_weight_dist\" : \"discrete\",\n",
    "#             \"input_weight_dist\" : \"discrete\",\n",
    "#             \"feedback_weight_dist\" : \"discrete\"\n",
    "            \n",
    "#            }\n",
    "\n",
    "# bounds_dict = {\n",
    "#                \"spectral_radius\" : (0.8, 2),\n",
    "#                \"n_nodes\" : (200, 203), #(200, 203),\n",
    "#                \"regularization\" : (-3, 3),\n",
    "#                \"leaking_rate\" : (0, 0.1),\n",
    "#                \"input_scaling\" : (0.1, 1),\n",
    "#                \"feedback_scaling\" : (0.1, 1),\n",
    "#                 \"reservoir_sigma\" : (0.1, 0.9),\n",
    "#                \"connectivity\" : (-2, -0.1), \n",
    "#                \"input_connectivity\" : (-0.1, 0),\n",
    "#                \"feedback_connectivity\" : (-0.1, 0),\n",
    "#                \"bias\": (-1,1)\n",
    "#                }\n",
    "\n",
    "# #optimize:\n",
    "# opt = False\n",
    "\n",
    "\n",
    "# if opt:\n",
    "#     #declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "\n",
    "#     esn_cv = EchoStateNetworkCV(bounds = bounds_dict, \n",
    "#                                 n_inputs = 1,\n",
    "#                                 n_outputs = 2,\n",
    "#                                 **BO_specs)\n",
    "#     opt_hps = esn_cv.optimize(#**BO_opt_hps,\n",
    "                              \n",
    "#                               n_trust_regions = 5, \n",
    "#                               max_evals = 2000,  \n",
    "#                               #x = input_train,\n",
    "#                               #y = target_train,\n",
    "#                               x = input_train, \n",
    "#                               y = noisy_tr_target)\n",
    "\n",
    "# noise_hps = {'n_nodes': 500,\n",
    "#  'connectivity': 0.20541412114258625,\n",
    "#  'spectral_radius': 1.4592119455337524,\n",
    "#  'regularization': 7.651269704734278,\n",
    "#  'leaking_rate': 0.017093051224946976,\n",
    "#  'bias': 0.36459600925445557,\n",
    "#  'input_connectivity' : 0.3,\n",
    "#  'input_scaling' : 0.3,\n",
    "#  'reservoir_sigma' : 0.5}\n",
    "\n",
    "# # noise_hps = {'n_nodes': 100,\n",
    "# #  'connectivity': 0.399439034108774,\n",
    "# #  'spectral_radius': 1.0231386423110962,\n",
    "# #  'regularization': 0.1927413131266174,\n",
    "# #  'leaking_rate': 0.04907611757516861,\n",
    "# #  'bias': 0.9523247480392456}\n",
    "\n",
    "# discrete_hps = {'spectral_radius': 1.45,#8164498805999756,\n",
    "#  'n_nodes': 500.0259094238281,\n",
    "#  'regularization': 6.932340995978034,\n",
    "#  'leaking_rate': 0.01,#0.02312193252146244,\n",
    "#  'input_scaling': 0.1,#2.8231945037841797,\n",
    "#  'feedback_scaling': 0.8774136900901794,\n",
    "#  'reservoir_sigma': 0.617402195930481,\n",
    "#  'connectivity': 0.2,#0.04752022106245545,\n",
    "#  'input_connectivity': 0.9974246642743851,\n",
    "#  'feedback_connectivity': 0.3,#0.8590326214329577,\n",
    "#  'bias': 0.21322786808013916}\n",
    "\n",
    "# noise_hps = {'n_nodes': 500,\n",
    "#  'connectivity': 0.20541412114258625,\n",
    "#  'spectral_radius': 1.4592119455337524,\n",
    "#  'regularization': 7.651269704734278,\n",
    "#  'leaking_rate': 0.017093051224946976,\n",
    "#  'bias': 0.36459600925445557,\n",
    "#  'input_scaling' : 0.0,\n",
    "#  'input_connectivity' : 0.3,\n",
    "#   'feedback_connectivity' : 0.3}\n",
    "\n",
    "# noise_hps = {'n_nodes': 100,\n",
    "#  'connectivity': 0.399439034108774,\n",
    "#  'spectral_radius': 1.0231386423110962,\n",
    "#  'regularization': 0.1927413131266174,\n",
    "#  'leaking_rate': 0.04907611757516861,\n",
    "#  'bias': 0.9523247480392456}\n",
    "\n",
    "\n",
    "# noise_obs_esn = RcNetwork(**noise_hps, \n",
    "#                 random_state = 210, \n",
    "#                 feedback = 1)\n",
    "# #                 n_inputs = 1,\n",
    "# #                 n_outputs = 2)\n",
    "# noise_obs_esn.fit(X = input_train, \n",
    "#             y = noisy_tr_target, \n",
    "#             burn_in = 0)\n",
    "# score, prediction = noise_obs_esn.test(X = input_test,\n",
    "#             y = noisy_te_target)\n",
    "# noise_obs_esn.combined_plot(gt_tr_override=target_train,\n",
    "#                             gt_te_override=target_test)\n",
    "# print(score)\n",
    "\n",
    "\n",
    "# final_figure_plot(test_gt = target_test, noisy_test_gt = noisy_te_target, rc_pred = prediction, \n",
    "#                   noisy_format = '.')\n",
    "\n",
    "\n",
    "# final_figure_plot(test_gt = target_test, noisy_test_gt = noisy_te_target, rc_pred = prediction, \n",
    "#                   noisy_format = '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class My_esn:\n",
    "#     \"\"\"\n",
    "#     A wrapper class to make it easier to work with RcTorch. Particularly plotting is easier.\n",
    "    \n",
    "#     Methods\n",
    "#     -------\n",
    "#     fit: Fit the esn\n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "#     def __init__(self, **esn_args) -> None:\n",
    "#         self.esn =  EchoStateNetwork(**esn_args)\n",
    "#         self.string_representation = self.esn.__repr__()\n",
    "    \n",
    "# #     def __repr__(self):\n",
    "# #         return \n",
    "        \n",
    "#     def fit(self, gt_override = None,  **fit_args):\n",
    "#         #save fit\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self._fit = self.esn.fit(**fit_args)\n",
    "#         self._xtr = self.esn.unscaled_X.data\n",
    "#         #save gt\n",
    "        \n",
    "#         if gt_override is not None:\n",
    "#             self._gt_tr = gt_override\n",
    "#             self.override = True\n",
    "#         else:\n",
    "#             self.override = False\n",
    "#             self._gt_tr = fit_args[\"y\"]\n",
    "        \n",
    "#         #save resids\n",
    "#         self.tr_resids = (self._gt_tr - self._fit)**2\n",
    "        \n",
    "#         self._len_tr = len(self._fit)\n",
    "#         self.tr_idx = list(range(self._len_tr))\n",
    "#         #assert False, torch.tensor(self._fit)\n",
    "#         return self._fit\n",
    "        \n",
    "#     def test(self, gt_override = None, **test_args) -> None:\n",
    "        \n",
    "#         #save fit\n",
    "#         self.score, self._xhat = self.esn.test(**test_args)\n",
    "#         print(f\"test score: {self.score}\" )\n",
    "#         self._xte = self.esn.unscaled_Xte\n",
    "#         #save gt\n",
    "#         self._gt_te = test_args[\"y\"]\n",
    "        \n",
    "#         if gt_override is not None:\n",
    "#             self._gt_te = gt_override\n",
    "#         else:\n",
    "#             self._gt_te = test_args[\"y\"]\n",
    "            \n",
    "#         #save resids\n",
    "#         self.te_resids = (self._gt_te - self._xhat)**2\n",
    "        \n",
    "#         self._len_te = len(self._xhat)\n",
    "        \n",
    "#         self.te_idx = list(range(self._len_tr, self._len_te + self._len_tr))\n",
    "        \n",
    "#         return self.score, self._xhat\n",
    "        \n",
    "#     def plot_residuals(self, fig = True) -> None:\n",
    "        \n",
    "#         if fig:\n",
    "#             plt.figure(figsize = (16, 4))\n",
    "#         plt.plot(self.tr_idx, self.tr_resids)\n",
    "#         plt.plot(self.te_idx, self.te_resids)\n",
    "#         plt.yscale(\"log\") \n",
    "    \n",
    "#     def plot_pred(self, fig = True) -> None:\n",
    "#         if fig:\n",
    "#             plt.figure(figsize = (16, 4))\n",
    "            \n",
    "#         if not self.override:\n",
    "#             pred_alpha = 0.4\n",
    "#             gt_alpha = 1\n",
    "#         else:\n",
    "#             pred_alpha = 0.9\n",
    "#             gt_alpha = 0.3\n",
    "#         lw = 3\n",
    "        \n",
    "#         plt.plot(self.tr_idx + self.te_idx,\n",
    "#                  np.concatenate((self._gt_tr, self._gt_te), axis = 0),\n",
    "#                  '--',\n",
    "#                  color = \"black\",\n",
    "#                  alpha = gt_alpha,\n",
    "#                  linewidth = lw-1,\n",
    "#                  label = \"ground_truth\")\n",
    "        \n",
    "#         plt.plot(self.tr_idx, self._fit,  alpha = pred_alpha, linewidth = lw+2, #color = \"blue\",\n",
    "#                 label = \"train\")\n",
    "#         plt.plot(self.te_idx, self._xhat, alpha = pred_alpha, linewidth = lw+2, #color = \"red\", \n",
    "#                 label = \"test\")\n",
    "    \n",
    "#     def combined_plot(self) -> None:\n",
    "        \n",
    "#         fig = plt.figure(figsize = (16,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "#         ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "#         self.plot_pred(fig = False)\n",
    "\n",
    "#         ax = plt.subplot(gs1[-1, :])\n",
    "        \n",
    "#         self.plot_residuals(fig = False)\n",
    "#         plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def evaluate_rcs_plain(dataset, hps, resonant_too = False, observers):#, target_tr, target_te, obs_tr, obs_te):\n",
    "    \n",
    "    \n",
    "#     if not resonant_too and dataset[\"resonant\"]:\n",
    "#         t, force, data = dataset[\"t\"], dataset[\"force\"], dataset[\"data\"]\n",
    "\n",
    "#         #for now just do the pure pred.\n",
    "#         t_splitter = Splitter(t, noise = False)\n",
    "#         ttrain, ttest = t_splitter.split()\n",
    "\n",
    "#         data_splitter = Splitter(data, noise = False)\n",
    "#         target_train, target_test = data_splitter.split()\n",
    "\n",
    "#         my_esn = My_esn(**hps, \n",
    "#                         random_state = 210, \n",
    "#                         feedback = 1,\n",
    "#                         n_inputs = 1,\n",
    "#                         n_outputs = 2)\n",
    "\n",
    "#         my_esn.fit(X =  None, #input_train[:,1].view(-1,1), \n",
    "#                     y = target_train, \n",
    "#                     burn_in = 0) #gt_override=target_train)\n",
    "#         my_esn.test(X = None, #input_test[:,1].view(-1,1),\n",
    "#                     #gt_override=target_test,\n",
    "#                     y = target_test)\n",
    "\n",
    "#         resids = my_esn.te_resids\n",
    "\n",
    "#         #we need x and px eventually, this is fine for now\n",
    "#         max_resid  = torch.max(resids)\n",
    "#         mean_resid = torch.mean(resids)\n",
    "\n",
    "#         data2save = {\"observers\" : False,\n",
    "#                      \"resids\" : resids,\n",
    "#                      \"max_resid\" : max_resid,\n",
    "#                      \"mean_resid\" : mean_resid,\n",
    "#                      \"a\" : dataset[\"a\"],\n",
    "#                      \"w\" : dataset[\"w\"]\n",
    "#                      }\n",
    "#     return data2save\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
