{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> RcTorch Library Paper Experiments\n",
    "## Spring\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Hayden Joy**<br/>\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "rctorch github repository: https://github.com/blindedjoy/RcTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy import loadtxt\n",
    "\n",
    "#from pyESN import ESN\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to install rctorch in jupyterhub-gpu open a terminal and then enter:\n",
    "`>>> pip3 install rctorchprivate`\n",
    "if that fails first try `pip3 install botorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rctorchprivate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMSE(prediction,target):\n",
    "    try:\n",
    "        prediction = prediction.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return np.sqrt(np.mean((prediction.flatten() - target.flatten() )**2))\n",
    "class Fpendulum:\n",
    "    #was trained on A=0.5, W =0.2\n",
    "    \"\"\"forced pendulum\"\"\"\n",
    "    def __init__(self, t, x0,  px0, lam=1, A=0, W=1, force = \"sin\"):\n",
    "        self.t = t\n",
    "        self.u0 = [x0, px0]\n",
    "        # Call the ODE solver\n",
    "        if force == \"sin\":\n",
    "            self.force =  Fpendulum.sin_force\n",
    "            spec_f = Fpendulum.sin_f\n",
    "        elif force == \"cos\":\n",
    "            self.force = Fpendulum.cos_force\n",
    "            spec_f = Fpendulum.cos_f\n",
    "        elif force == \"sincos\":\n",
    "            self.force =  Fpendulum.sincos_force\n",
    "            spec_f = Fpendulum.sincos_f\n",
    "        solPend = odeint(spec_f, self.u0, t, args=(lam,A,W))\n",
    "        self.xP = solPend[:,0];        \n",
    "        self.pxP = solPend[:,1]; \n",
    "        self.force_pend_data = solPend\n",
    "        \n",
    "        self.lineW = 3\n",
    "        self.lineBoxW=2\n",
    "        \n",
    "        #self.force = self.force(A, W, t)\n",
    "\n",
    "        #         self.font = {'family' : 'normal',\n",
    "        #                 'weight' : 'normal',#'bold',\n",
    "        #                 'size'   : 24}\n",
    "\n",
    "        #plt.rc('font', **font)\n",
    "        #plt.rcParams['text.usetex'] = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def sin_force(A, W, t):\n",
    "        return A*np.sin(W*t)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sincos_force(A, W, t):\n",
    "        if isinstance(W, int) or isinstance(W, float):\n",
    "            return A*np.sin(W*t)*np.cos(W*t)\n",
    "        elif isinstance(W, list):\n",
    "            W1, W2 = W\n",
    "            return A*np.sin(W1*t)*np.cos(W2*t)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cos_force(A, W, t):\n",
    "        return A*np.cos(W*t)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cos_f(u, t, lam=0,A=0,W=1,gamma=0, w=1):\n",
    "        \n",
    "        x,  px = u        # unpack current values of u\n",
    "        derivs = [px, -gamma * px - np.sin(x) + Fpendulum.cos_force(A, W, t)]     #     you write the derivative here\n",
    "        return derivs\n",
    "    \n",
    "    @staticmethod\n",
    "    def sin_f(u, t, lam=0,A=0,W=1,gamma=0, w=1):\n",
    "        \n",
    "        x,  px = u        # unpack current values of u\n",
    "        derivs = [px, -gamma * px - np.sin(x) + Fpendulum.sin_force(A, W, t)]     #     you write the derivative here\n",
    "        return derivs\n",
    "    \n",
    "    @staticmethod\n",
    "    def sincos_f(u, t, lam=0,A=0,W=1,gamma=0, w=1):\n",
    "        \n",
    "        x,  px = u        # unpack current values of u\n",
    "        derivs = [px, -gamma * px - np.sin(x) + Fpendulum.sincos_force(A, W, t)]     #     you write the derivative here\n",
    "        return derivs\n",
    "    \n",
    "    def return_data(self):\n",
    "        return np.vstack((my_fp.xP, my_fp.pxP)).T\n",
    "    \n",
    "    def plot_(self):\n",
    "        plt.figure(figsize=[20,6])\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.t/np.pi, self.xP,'b',label='x(t)', linewidth = self.lineW)\n",
    "        plt.plot(self.t/np.pi, self.pxP,'r',label='v(t)', linewidth = self.lineW)\n",
    "        plt.xlabel('$t/\\pi$')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.xP, self.pxP,'g', linewidth = self.lineW)\n",
    "        plt.xlabel('$x$')\n",
    "        plt.ylabel('$v$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spring:\n",
    "    #was trained on A=0.5, W =0.2\n",
    "    \"\"\"spring\n",
    "    \n",
    "    k is the spring constant\n",
    "    w is omega\n",
    "    \"\"\"\n",
    "    def __init__(self, t, x0,  px0, lam=1, k=1, m = 1, force = None):\n",
    "        self.t = t\n",
    "        self.u0 = [x0, px0]\n",
    "        # Call the ODE solver\n",
    "        if not force:\n",
    "            self.force = Spring.no_force\n",
    "            spec_f = Spring.no_f\n",
    "        else:\n",
    "            assert False, \"not implimented\"\n",
    "            \n",
    "        solPend = odeint(spec_f, self.u0, t, args=(lam, k, m))\n",
    "        self.xP = solPend[:,0];        \n",
    "        self.pxP = solPend[:,1]; \n",
    "        self.force_pend_data = solPend\n",
    "        \n",
    "        self.lineW = 3\n",
    "        self.lineBoxW=2\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def no_force(k, m, t):\n",
    "        return np.zeros_like(t)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def no_f(u, t, lam=0, k=1, m=1):\n",
    "        \n",
    "        x,  px = u        # unpack current values of u\n",
    "        derivs = [px / m, - (k/m)*x]     #     you write the derivative here\n",
    "        return derivs\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def sin_f(u, t, lam=0,A=0,W=1,gamma=0, w=1):\n",
    "        \n",
    "#         x,  px = u        # unpack current values of u\n",
    "#         derivs = [px, -gamma * px - np.sin(x) + Fpendulum.sin_force(A, W, t)]     #     you write the derivative here\n",
    "#         return derivs\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def sincos_f(u, t, lam=0,A=0,W=1,gamma=0, w=1):\n",
    "        \n",
    "#         x,  px = u        # unpack current values of u\n",
    "#         derivs = [px, -gamma * px - np.sin(x) + Fpendulum.sincos_force(A, W, t)]     #     you write the derivative here\n",
    "#         return derivs\n",
    "    \n",
    "    def return_data(self):\n",
    "        return np.vstack((my_fp.xP, my_fp.pxP)).T\n",
    "    \n",
    "    def plot_(self):\n",
    "        plt.figure(figsize=[20,6])\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.t/np.pi, self.xP,'b',label='x(t)', linewidth = self.lineW)\n",
    "        plt.plot(self.t/np.pi, self.pxP,'r',label='v(t)', linewidth = self.lineW)\n",
    "        plt.xlabel('$t/\\pi$')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.xP, self.pxP,'g', linewidth = self.lineW)\n",
    "        plt.xlabel('$x$')\n",
    "        plt.ylabel('$v$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RcTorch: \n",
    "\n",
    "RcTorch is a GPU accelerated pytorch library that uses Facebook's bayesian optimization package BoTorch to quickly optimize the hyper-parameters of reservoir nueral networks. This library is still in its early stages so feel free to email Hayden Joy hjoy@college.harvard.edu with any questions or to report any bugs. For this reason please also check for updates here: https://pypi.org/project/rctorch/.\n",
    "\n",
    "(a huge thank you to Reinier https://github.com/1Reinier/Reservoir who wrote the first version of this library and most of this documentation. See the paper here: https://arxiv.org/abs/1903.05071)\n",
    "\n",
    "J. R. Maat, N. Gianniotis, “Reservoir: a Python Package to Train and Optimize Echo State Networks ,” 2017. [Online]. Available: http://github.com/https://github.com/1Reinier/Reservoir\n",
    "\n",
    "The open source code in this package supplements:\n",
    "J. R. Maat, N. Gianniotis and P. Protopapas, \"Efficient Optimization of Echo State Networks for Time Series Datasets,\" 2018 International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, 2018, pp. 1-7.\n",
    "\n",
    "### The EchoStateNetwork class creates a reservoir neural network according to the following arguments\n",
    "log-space variables: \n",
    "- connectivity: **[float]** the probability that two nodes will be connected\n",
    "- regularization: **[float default value None]** The L2 regularization value used in Ridge regression for model inference\n",
    "    \n",
    "lin-space variables: \n",
    "- bias **[recommended value 1.5]**: bias to be added to the input weights.\n",
    "- leaking_rate **[float recommended value: ]**: Specifies how much of the state's update 'leaks' into the new state\n",
    "- spectral_radius **[float search between 1 and 2]**: Sets the magnitude of the largest eigenvalue of the transition matrix (weight matrix) \n",
    "\n",
    "Variables we recommend you fix: \n",
    " - n_nodes **[recommended value 1000]**: Number of nodes that together make up the reservoir\n",
    " - input_scaling: **[float, default value 0.5]**\n",
    "     The scaling of input values into the network\n",
    " - feedback scaling: **[float, default value 0.5]** the scaling of feedback values into the network\n",
    " \n",
    "Other arguments:\n",
    " - feedback: **[bool]** Sets feedback of the last value into the network on or off (for predictions predicted values are substituted for y)\n",
    " - random seed: **[int]** Seed used to initialize RandomState (Torch Generator manual seed) in reservoir generation and weight initialization\n",
    " - activation function: **[nn.function]** recurrent activation function. only nn.tanh implimented. Leave as is\n",
    " \n",
    "### The EchoStateNetworkCV class performs cross-validated Bayesian Optimization on variables of your choice\n",
    "\n",
    "Arguments:\n",
    "- bounds = The bounds dict declares trainable and fixed variables. Certain variables are searched in log-space and other are in lin-space. All variables are the dictionary keys. if a numeric value (not a tuple) is assigned to a variable (ie hyper-parameter) it is assumed to be fixed. If it is assigned to be a tuple then then the value is ([lower bound], [upper bound]). \n",
    "- intial samples: **[int recommended value >= 50]** The number of random samples to explore before starting the optimization.\n",
    "- validate_fraction **[float ]** the fraction of the data that may be used as a validation set\n",
    "- batch_size: **[int]** Batch size of samples used by BoTorch (these are run in parallel and with cuda if possible)\n",
    "- cv_samples: **[int]** number of samples of the objective function to evaluate for a given parameterization of the ESN\n",
    "- scoring method: {'mse', 'nmse'} Evaluation metric that is used to guide optimization\n",
    "- esn_burn_in: **[int]** the number of time steps to discard upon training a single Echo State Network\n",
    "- esn_feedback: builds ESNs with feedback ('teacher forcing') if available\n",
    "- device: Torch device (either 'cpu' or 'cuda')\n",
    "- interactive **[BOOL]** if true, make interactive python plots\n",
    "- approximate reservoir **[BOOL NOT IMPLIMENTED]** use sparse matrices to speed up optimization\n",
    "- activation function: **[nn.function]** only nn.tanh implimented\n",
    "\n",
    "Trust Region Bayesian Optimization (TURBO) \n",
    "\n",
    "TURBO Arguments: (<a href='https://botorch.org/tutorials/turbo_1'>Botorch tutorial</a>) (<a href='https://arxiv.org/pdf/1910.01739.pdf'> click here for the original paper</a>  which came out of uber.\n",
    "Turbo Arguments *we don't recommend that you change these values but they are here for your understanding)*\n",
    "- failure tolerance [**int, automated**] the number of times that a model can fail to improve length before length is increased in turbo algorithm.\n",
    "- sucess tolerance: [**int**] the number of times that a model can succeed to improve length before length is decreased in turbo algorithm.\n",
    "- length min: [**int**] the target length that acts as the stopping condition for the turbo algorithm\n",
    "- length max: [**int**] maximum length that the turbo algorithm can take before\n",
    "    \n",
    "Further arguments\n",
    "- windowsOS: [**bool**] NOT IMPLIMENTED: use this if you have a windows system with a GPU\n",
    "- steps ahead: leave as None. Vestigal argument.\n",
    "\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_numpy(arr_or_tensor):\n",
    "    if type(arr_or_tensor) == np.ndarray:\n",
    "        arr_or_tensor = torch.tensor(arr_or_tensor) \n",
    "    return arr_or_tensor\n",
    "\n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self, tensor, split = 0.6, noise = False, std = 0.07):\n",
    "        self._split = split\n",
    "        \n",
    "        self._tensor = if_numpy(tensor).clone()\n",
    "        self._std = std\n",
    "        self._noise = noise\n",
    "        if noise:\n",
    "            self.make_noisy_data()\n",
    "        #return self.split()\n",
    "    \n",
    "    def split(self):\n",
    "        tl = len(self._tensor)\n",
    "        trainlen = int(tl * self._split)\n",
    "        train, test = self._tensor[:trainlen], self._tensor[trainlen:]\n",
    "        return train, test\n",
    "\n",
    "    def make_noisy_data(self):\n",
    "        self._tensor += torch.normal(0, self._std, size = self._tensor.shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        strr = f\"Splitter: split = {self._split},\"\n",
    "        if self._noise:\n",
    "            strr += \" noise = {self._std}\"\n",
    "        else:\n",
    "            strr += \" noise = False\"\n",
    "        return strr\n",
    "\n",
    "def split_data(input_tensor, output_tensor, split):\n",
    "    input_splitter = Splitter(input_tensor, split = split)\n",
    "    input_tr, input_te = input_splitter.split()\n",
    "    output_splitter = Splitter(output_tensor, split = split)\n",
    "    target_tr, target_te = output_splitter.split()\n",
    "    \n",
    "    return input_tr, input_te, target_tr, target_te\n",
    "\n",
    "def plot_data(data):\n",
    "    fig, ax = plt.subplots(2,1, figsize=(16,6))\n",
    "    #TODO confirm that position and momentum are correct\n",
    "    ax[1].plot(data[:,0], label = \"position\")\n",
    "    ax[1].plot(data[:,1], label = \"momentum\")\n",
    "    ax[0].plot(force_, '--', label = \"force\")\n",
    "    ax[0].set_ylim(-1.3, 1.3) \n",
    "    ax[0].set_title(\"Force Observer\")\n",
    "    \n",
    "    ax[1].set_title(\"Forced Pendulum target data\")\n",
    "    [ax[i].legend() for i in range(2)]\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def final_figure_plot(test_gt, noisy_test_gt, rc_pred, \n",
    "                      noisy_format = '.', pred_format = '--', linewidth = 1):\n",
    "    \n",
    "    \n",
    "    def phase_plot(tensor_, label, format_string = None, alpha = 0.9):\n",
    "        arg_dict = {\"label\" : label,\n",
    "                    \"alpha\" : alpha,\n",
    "                    \"linewidth\" : linewidth}\n",
    "        if format_string is None:\n",
    "            plt.plot(tensor_[:,0], tensor_[:,1], **arg_dict)\n",
    "        else:\n",
    "            plt.plot(tensor_[:,0], tensor_[:,1], format_string, **arg_dict)\n",
    "    \n",
    "    #plot 1 is the real phase space of the  virgin target test set\n",
    "    title_fontsize = 12\n",
    "    if noisy_test_gt is not None:\n",
    "       \n",
    "        fig, ax = plt.subplots(1, 3, figsize = (9,4))\n",
    "        plt.sca(ax[0])\n",
    "        phase_plot(test_gt, \"latent_gt\", pred_format)\n",
    "        plt.title(\"ground truth phase space\", fontsize =title_fontsize)\n",
    "        plt.xlabel(\"position\")\n",
    "        plt.ylabel(\"momentum\")\n",
    "\n",
    "        #plot 2 is the noisy phase space of the target test set\n",
    "        plt.sca(ax[1])\n",
    "        phase_plot(noisy_test_gt, \"noisy_gt\", noisy_format, alpha = 0.3)\n",
    "        plt.title(\"data phase space\", fontsize = 12)\n",
    "        plt.xlabel(\"position\")\n",
    "        plt.ylabel(\"momentum\")\n",
    "\n",
    "        #plot 3 is the phase space of the rc\n",
    "        plt.sca(ax[2])\n",
    "        phase_plot(rc_pred, \"rc_prediction\", pred_format)\n",
    "        plt.title(\"rc prediction phase space\", fontsize = title_fontsize)\n",
    "        plt.xlabel(\"position\")\n",
    "        plt.ylabel(\"momentum\")\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (9,4))\n",
    "        plt.sca(ax[0])\n",
    "        phase_plot(test_gt, \"latent_gt\", pred_format)\n",
    "        plt.title(\"latent phase space\", fontsize = title_fontsize)\n",
    "        plt.xlabel(\"position\")\n",
    "        plt.ylabel(\"momentum\")\n",
    "\n",
    "#         #plot 2 is the noisy phase space of the target test set\n",
    "#         plt.sca(ax[1])\n",
    "#         phase_plot(noisy_test_gt, \"noisy_gt\", noisy_format, alpha = 0.3)\n",
    "#         plt.title(\"data phase space\")\n",
    "\n",
    "        #plot 3 is the phase space of the rc\n",
    "        plt.sca(ax[1])\n",
    "        plt.tick_params(labelleft=False)\n",
    "        phase_plot(rc_pred, \"rc_prediction\", pred_format)\n",
    "        plt.title(\"rc prediction phase space\")\n",
    "        plt.xlabel(\"position\")\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: data/force_pend/force_pend_sin/force_pend_long: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls data/force_pend/force_pend_sin/force_pend_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/force_pend/force_pend_sin/force_pend_short/force_pendulum.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j8/qxt2xjjs43jc313rqwthwn780000gq/T/ipykernel_6412/3227278913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'force_pendulum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'force_pendulum_t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'force_pendulum_force'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mforce_pend_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mforce_pend_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mforce_pend_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/arm/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/force_pend/force_pend_sin/force_pend_short/force_pendulum.npy'"
     ]
    }
   ],
   "source": [
    "bp = 'data/force_pend/'\n",
    "#bp += 'force_pend_sincos/'\n",
    "#extension = '_sin_cos'\n",
    "bp+='force_pend_sin/force_pend_short/'\n",
    "extension = ''\n",
    "\n",
    "\n",
    "files = ['force_pendulum', 'force_pendulum_t', 'force_pendulum_force']\n",
    "\n",
    "force_pend_data = np.load(bp + files[0] + extension +'.npy')\n",
    "force_pend_data.shape\n",
    "force_pend_t = np.load(bp + files[1] + extension +'.npy')\n",
    "force_pend_t.shape\n",
    "\n",
    "force_ = np.load(bp + files[2] + extension +'.npy')\n",
    "\n",
    "def adjust_np_data(arr):\n",
    "    tensor = torch.tensor(arr, dtype = torch.float32)\n",
    "    return tensor.unsqueeze(1)\n",
    "input_ = force_ = adjust_np_data(force_)\n",
    "t = adjust_np_data(force_pend_t)\n",
    "force_pend_data = torch.tensor(force_pend_data, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape, force_.shape, force_pend_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, 0.6)\n",
    "input_train2, input_test2, target_train2, target_test2 = split_data( input_, force_pend_data, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = 0.6\n",
    "# input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, split)\n",
    "#t.shape, input_.shape, target_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: phase space plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pi/ 5**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretty set! (try both sincos and sin)\n",
    "As = np.ones(5)\n",
    "Ws = [10**i for i in [1, 0, -1, -2, -3]]\n",
    "\n",
    "#pretty set!\n",
    "\n",
    "base = np.pi/13 * 10\n",
    "Ws = np.array([base**i for i in [2, 1, -0.95, -1, -2, -3]])\n",
    "\n",
    "base = np.exp(1)\n",
    "As = np.ones(5)/2\n",
    "Ws = np.array([base**i for i in [2, 1, -0.95, -1, -2, -3]])\n",
    "\n",
    "#AW_lst = [(0, 0), (0.2, 0.2),  (0.3, 0.3), (0.1, 0.01)]\n",
    "AW_lst = list(zip(As, Ws))\n",
    "AW_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pi/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synthetic_data(desired_length = 10*np.pi):\n",
    "    dt = np.pi/200\n",
    "\n",
    "    x0_p0_lst = [ (0.1, 0.1), (0.25, 0.25), (0.3, 0.45),  (0.5, 0.5)] #\n",
    "\n",
    "    datas = []\n",
    "    inputs = []\n",
    "\n",
    "    for i, (k, m) in enumerate(AW_lst):\n",
    "\n",
    "        #for the experiments without noise use 60*np.pi\n",
    "\n",
    "        Nt = int(desired_length//dt)\n",
    "        t = np.linspace(0, desired_length, Nt) #100*np.pi\n",
    "\n",
    "        trajectories_i = []\n",
    "        traj_i_inputs = []\n",
    "\n",
    "        for j, (x0, px0) in enumerate(x0_p0_lst):\n",
    "        #x0, px0 =  #.3, .5\n",
    "\n",
    "            my_fp = Spring(t = t, x0 = x0, px0 = px0, k = k, m = m, force = None)\n",
    "            force_pend_data = my_fp.force_pend_data\n",
    "            input_ = my_fp.force(t = my_fp.t, k = k, m = m)\n",
    "\n",
    "            force_pend_data = torch.tensor(force_pend_data, dtype = torch.float32)\n",
    "            input_ = torch.tensor(input_, dtype = torch.float32)\n",
    "            traj_i_inputs.append(input_)\n",
    "\n",
    "            trajectories_i.append(force_pend_data)\n",
    "        datas.append(trajectories_i)\n",
    "        inputs.append(traj_i_inputs)\n",
    "    return datas, inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, inputs = synthetic_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datas)):\n",
    "    plot_data(datas[i][0])\n",
    "    final_figure_plot(datas[i][0], None, datas[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_figure_plot(datas[0][2], None, datas[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_plot(data, force = None, ax = None):\n",
    "    ax.plot(data[:,0], data[:,1])\n",
    "def figure_1(data_lst):\n",
    "    fig, ax = plt.subplots(len(data_lst),2,figsize = (16,16))\n",
    "    ax = ax.flatten()\n",
    "    for i, data in enumerate(data_lst):\n",
    "        for trajectory in data:\n",
    "            #print(trajectory)\n",
    "            phase_plot(trajectory, ax = ax[i*2])\n",
    "            ax[i*2 + 1].plot(t, trajectory[:,0], color = \"red\")\n",
    "            ax[i*2 + 1].plot(t, trajectory[:,1], color = \"blue\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RcTorch pure prediction\n",
    "### Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.1\n",
    "problem, idx = 3, 0\n",
    "input_tr, input_te, target_tr, target_te = split_data( inputs[problem][idx], datas[problem][idx], 0.4) #0.2\n",
    "\n",
    "noise_target_tr = target_tr + torch.rand_like(target_tr)*noise\n",
    "noise_target_te = target_te + torch.rand_like(target_te)*noise\n",
    "input_tr.shape, noise_target_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "\n",
    "\n",
    "\n",
    "bounds_dict = {\"connectivity\" : (-2, -0.1), \n",
    "               \"spectral_radius\" : (0.6, 2),\n",
    "               \"n_nodes\" : (250, 253.1),\n",
    "               \"regularization\" : (-3, 3),\n",
    "               \"leaking_rate\" : (0, 1),\n",
    "               #\"input_scaling\" : (0, 1),\n",
    "               #\"input_connectivity\" : (0, 1),\n",
    "               #\"feedback_connectivity\" : (0, 1),\n",
    "               \"bias\": (0, 1),\n",
    "               #\"mu\" : (-1, 1),\n",
    "               #'sigma': 0.0015868513697625247, #\"sigma\" : (-3, 0.1),\n",
    "               #\"noise\" :(-3, 0)\n",
    "               \n",
    "               }\n",
    "\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "opt = True\n",
    "if opt:\n",
    "    rc_bayes = RcBayesOpt(bounds = bounds_dict, feedback = True, \n",
    "                                scoring_method = \"nmse\", interactive = True, \n",
    "                                n_jobs = 8, cv_samples = 2, initial_samples = 16, \n",
    "                                random_seed = 210,\n",
    "                               reservoir_weight_dist = \"uniform\")\n",
    "                                #                                 n_inputs = 1,\n",
    "                                #                                 n_outputs = 2)\n",
    "                              #activation_function = torch.sin,\n",
    "                              #act_f_prime = torch.cos)\n",
    "    #optimize:\n",
    "    opt_hps = rc_bayes.optimize( n_trust_regions = 8, \n",
    "                                  max_evals = 2000,\n",
    "                                  x = None,#input_tr, \n",
    "                                  y = noise_target_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_bayes.recover_hps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right now the code is reversed. We begin with the BO experiments:\n",
    "\n",
    "the first way we can write the paper is just to see if BO can work to improve one particular prediction. For the first draft lean towards this.\n",
    "\n",
    "0) set up data\n",
    "1) show with old hps\n",
    "2) show with new hps (improvement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0)\n",
    "problem, idx = 3, 0\n",
    "input_tr, input_te, target_tr, target_te = split_data( inputs[problem][idx], datas[problem][idx], 0.4) #0.2\n",
    "\n",
    "noise_target_tr = target_tr + torch.rand_like(target_tr)*noise\n",
    "noise_target_te = target_te + torch.rand_like(target_te)*noise\n",
    "input_tr.shape, noise_target_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(datas[problem][idx])\n",
    "final_figure_plot(target_te, None, target_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the hps from the main paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "main_section_hps = {'connectivity': 0.07850450868040316,\n",
    " 'spectral_radius': 1.511986255645752,\n",
    " 'n_nodes': int(250.76300048828125),\n",
    " 'regularization': 0.0016397340552415341,\n",
    " 'leaking_rate': 0.00010124071559403092,\n",
    " 'bias': 0.22289347648620605}\n",
    "\n",
    "esn_pure_pred = RcNetwork(**main_section_hps,\n",
    "                          feedback = True,\n",
    "                          random_state = 210) # was 210\n",
    "esn_pure_pred.fit(X = None, y = noise_target_tr)\n",
    "score, prediction = esn_pure_pred.test( X = None, y = noise_target_te)\n",
    "\n",
    "esn_pure_pred.combined_plot(gt_tr_override = target_tr, gt_te_override = target_te)\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_te, noise_target_te, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(11120):\n",
    "    torch.square(a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(11120):\n",
    "    (a**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    \"\"\"\n",
    "    function to learn the outputs u(t) and hidden states h(t) s.t. u(t) = h(t)W_out\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, output_dim, calc_bias,\n",
    "                 activation_number, n_layers):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.hdim = hidden_dim\n",
    "\n",
    "        #activation_number \\in [0,1] [1,2]. [2, 3]\n",
    "        if activation_number > 2:\n",
    "            self.nl = nn.Tanh()\n",
    "        elif activation_number > 1:\n",
    "            self.nl = nn.Sigmoid()\n",
    "        else:\n",
    "            self.nl = torch.sin\n",
    "        self.lin1 = nn.Linear(1, self.hdim)\n",
    "        self.lin2 = nn.Linear(self.hdim, self.hdim)\n",
    "        self.lin3 = nn.Linear(self.hdim, self.hdim)\n",
    "        self.lout = nn.Linear(self.hdim, output_dim, bias = calc_bias)\n",
    "\n",
    "        if n_layers > 3:\n",
    "            self.h = self.h3\n",
    "        elif n_layers > 2:\n",
    "            self.h = self.h2\n",
    "        else:\n",
    "            self.h = self.h1\n",
    "    def forward(self, t):\n",
    "        self.h_ = x = self.h(t)\n",
    "        #self.h_.retain_grad()\n",
    "        x = self.lout(x)\n",
    "        return x\n",
    "\n",
    "    def wouts(self, x):\n",
    "        return self.lout(x)\n",
    "\n",
    "    def h2(self, t):\n",
    "        x = self.lin1(t)\n",
    "        x = self.nl(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.nl(x)\n",
    "        return x\n",
    "\n",
    "    def h1(self, t):\n",
    "        x = self.lin1(t)\n",
    "        x = self.nl(x)\n",
    "        return x\n",
    "\n",
    "    def h3(self, t):\n",
    "        x = self.lin1(t)\n",
    "        x = self.nl(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.nl(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.nl(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = ODEFunc(10, 10, True, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(func.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['momentum'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_prop = 0.8\n",
    "hi = torch.rand((100,1))\n",
    "random_indices = np.random.choice(100, (int(sub_sample_prop*len(hi)),),replace = False)\n",
    "\n",
    "hi[random_indices, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# With activation from the optimized version\n",
    "\n",
    "# main_section_hps = {'connectivity': 0.4071449746896983,\n",
    "#  'spectral_radius': 1.1329107284545898,\n",
    "#  'n_nodes': 202,\n",
    "#  'regularization': 1.6862021450927922,\n",
    "#  'leaking_rate': 0.009808523580431938,\n",
    "#  'bias': 0.48509588837623596}\n",
    "\n",
    "esn_pure_pred = RcNetwork(**main_section_hps,\n",
    "                          activation_function = {\"relu\" : 0.33, \n",
    "                                                 \"tanh\" : 0.5, \n",
    "                                                 \"sin\" : 0.1},\n",
    "                          #activation_function = {'tanh':0.1, 'relu':0.9},\n",
    "                          feedback = True,\n",
    "                          random_state = 210) # was 210\n",
    "esn_pure_pred.fit(X = input_tr, y = target_tr)\n",
    "score, prediction = esn_pure_pred.test( X = None, y = target_te)\n",
    "esn_pure_pred.combined_plot()\n",
    "final_figure_plot(target_te, None, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO optimized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #was 0.1 noise = 0.1\n",
    "\n",
    "# experiment0_hps  = {'connectivity': 0.010497199729654356,\n",
    "#  'spectral_radius': 1.6224205493927002,\n",
    "#  'n_nodes': int(100.01666259765625),\n",
    "#  'regularization': 0.019864175793163488,\n",
    "#  'leaking_rate': 0.044748689979314804,\n",
    "#  'bias': 0.8152865171432495}\n",
    "\n",
    "\n",
    "# esn_pure_pred = RcNetwork(**experiment0_hps, activation_function = {'tanh':0.1, 'relu':0.9},\n",
    "#                           feedback = True,\n",
    "#                           random_state = 210) # was 210\n",
    "# esn_pure_pred.fit(X = input_tr, y = target_tr)\n",
    "# score, prediction = esn_pure_pred.test( X = input_te, y = target_te)\n",
    "# esn_pure_pred.combined_plot()\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these hps are new\n",
    "experiment0_hps  = {'connectivity': 0.54275345999343795,\n",
    " 'spectral_radius': 1.5731128454208374,\n",
    " 'n_nodes': 251,\n",
    " 'regularization': 0.1880535350594487,\n",
    " 'leaking_rate': 0.03279460221529007,\n",
    " 'bias': 0.8625065088272095} \n",
    "\n",
    "esn_pure_pred = RcNetwork(**experiment0_hps, \n",
    "                          activation_function = {\"relu\" : 0.33, \"tanh\" : 0.5, \"sin\" : 0.1},\n",
    "                          feedback = True,\n",
    "                          random_state = 210) # was 210\n",
    "esn_pure_pred.fit(X = input_tr, y = target_tr)\n",
    "score, prediction = esn_pure_pred.test( X = input_te, y = target_te)\n",
    "esn_pure_pred.combined_plot()\n",
    "final_figure_plot(target_te, None, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walkthrough part 2 experiments:\n",
    "\n",
    "If you have time during revision, go ahead and find better noise hps for the problem above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data\n",
    "problem, idx = 0, 1\n",
    "input_tr, input_te, target_tr, target_te = split_data( inputs[problem][idx], datas[problem][idx], 0.2) #\n",
    "noise = 0.4\n",
    "#was 0.1\n",
    "\n",
    "noise_target_tr = target_tr + torch.rand_like(target_tr)*noise\n",
    "noise_target_te = target_te + torch.rand_like(target_te)*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with the original experiments:\n",
    "\n",
    "\n",
    "orig_hps = {'connectivity': 0.4071449746896983,\n",
    " 'spectral_radius': 1.1329107284545898,\n",
    " 'n_nodes': 202,\n",
    " 'regularization': 1.6862021450927922,\n",
    " 'leaking_rate': 0.009808523580431938,\n",
    " 'bias': 0.48509588837623596}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unopt_rc = RcNetwork(**orig_hps, \n",
    "                        #activation_function = {\"relu\" : 0.33, \"tanh\" : 0.5, \"sin\" : 0.1},\n",
    "                        feedback = True,\n",
    "                        random_state = 210) # was 210\n",
    "unopt_rc.fit(X = input_tr, y = noise_target_tr)\n",
    "score, prediction = unopt_rc.test( X = input_te, y = noise_target_te)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unopt_rc.combined_plot(gt_tr_override = target_tr, gt_te_override = target_te)\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_te, noise_target_te, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now with BO optimized hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noisep2_hps = {'connectivity': 0.08428374379805789,\n",
    " 'spectral_radius': 1.1395107507705688,\n",
    " 'n_nodes': int(251.67526245117188),\n",
    " 'regularization': 1.3896905679295795,\n",
    " 'leaking_rate': 0.06542816758155823,\n",
    " 'bias': 0.24717366695404053}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_noise_p2 = RcNetwork(**noisep2_hps, \n",
    "                        #activation_function = {\"relu\" : 0.33, \"tanh\" : 0.5, \"sin\" : 0.1},\n",
    "                        feedback = True,\n",
    "                        random_state = 210) # was 210\n",
    "rc_noise_p2.fit(X = input_tr, y = noise_target_tr)\n",
    "score, prediction = rc_noise_p2.test( X = input_te, y = noise_target_te)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_noise_p2.combined_plot(gt_tr_override = target_tr, gt_te_override = target_te)\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_te, noise_target_te, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walkthrough part 1 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 3\n",
    "idx = 0\n",
    "input_train, input_test, target_train, target_test = split_data( inputs[problem][idx], datas[problem][idx], 0.2) #0.2\n",
    "plt.plot(datas[problem][idx][:6000])\n",
    "plot_data(datas[problem][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#main_section\n",
    "hps = {'connectivity': 0.4071449746896983,\n",
    " 'spectral_radius': 1.1329107284545898,\n",
    " 'n_nodes': 202,\n",
    " 'regularization': 1.6862021450927922,\n",
    " 'leaking_rate': 0.009808523580431938,\n",
    " 'bias': 0.48509588837623596}\n",
    "\n",
    "# opt_hps = {'connectivity': 0.4071449746896983,\n",
    "#  'spectral_radius': 1.1329107284545898,\n",
    "#  'n_nodes': round(201.7901153564453),\n",
    "#  'regularization': 1.6862021450927922,\n",
    "#  'leaking_rate': 0.009808523580431938,\n",
    "#  'bias': 0.48509588837623596}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(datas[problem][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "esn_pure_pred = RcNetwork(**hps, feedback = True, random_state = RANDOM_STATE) # was 210\n",
    "esn_pure_pred.fit(y = target_train)\n",
    "score, prediction = esn_pure_pred.test( y = target_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_pure_pred.combined_plot()\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_test, None, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "esn_pure_pred = RcNetwork(**hps, \n",
    "            random_state = RANDOM_STATE, \n",
    "            feedback = True,\n",
    "            activation_function = \"tanh\")\n",
    "\n",
    "esn_pure_pred.fit(X = input_train, \n",
    "                  y = target_train)\n",
    "\n",
    "score, prediction = esn_pure_pred.test(X = input_test,\n",
    "            y = target_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_pure_pred.combined_plot()\n",
    "final_figure_plot(target_test, None, prediction )\n",
    "print(f'score : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "esn_pure_pred = RcNetwork(**hps, \n",
    "                           #reservoir_weight_dist = \"normal\",\n",
    "                           #output_activation = \"tanh\",\n",
    "                           activation_function = {\"tanh\" : 0.1, \n",
    "                                   \"relu\" : 0.9, \n",
    "                                   \"sin\": 0.05},\n",
    "                           random_state = RANDOM_STATE, \n",
    "                           feedback = True)\n",
    "esn_pure_pred.fit(X = input_train, \n",
    "                  y = target_train,\n",
    "                  burn_in = 0)\n",
    "\n",
    "score, prediction = esn_pure_pred.test(X = input_test,\n",
    "            y = target_test)\n",
    "esn_pure_pred.combined_plot()\n",
    "final_figure_plot(target_test, None, prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_experiment(observer: bool = False,\n",
    "                          f_out: bool = False,\n",
    "                          random_state: int = 210,\n",
    "                          multi = None\n",
    "                         ): \n",
    "    input_tr = input_train if observer else None\n",
    "    input_te = input_test if observer else None\n",
    "    \n",
    "    out_f = \"tanh\" if f_out else \"identity\"\n",
    "    \n",
    "    rc = RcNetwork(**opt_hps, \n",
    "                           output_activation = out_f,\n",
    "                           activation_function = multi,\n",
    "                           random_state = random_state, \n",
    "                           feedback = True)\n",
    "    rc.fit(X = input_tr, \n",
    "                  y = target_train,\n",
    "                  burn_in = 0) \n",
    "    score, prediction = rc.test(X = input_te, y = target_test)\n",
    "    \n",
    "#     rc.combined_plot()\n",
    "#     final_figure_plot(target_test, None, prediction )\n",
    "    print(f'score: {score}')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_experiment(random_states, act_f_list, save_path = None):\n",
    "    results = {\"Score\" : [], \"Observer\" : [], \"f_out\" : [],\"random_state\" : [], \"multi\" : []}\n",
    "    for observer in [True, False]:\n",
    "        for f_out in [True, False]:\n",
    "            for random_state in random_states:\n",
    "                for i, act_f_dict in enumerate(act_f_list):\n",
    "                    score = individual_experiment(observer, f_out, random_state, act_f_dict)\n",
    "                    results[\"Score\"].append(float(score))\n",
    "                    results[\"Observer\"].append(observer)\n",
    "                    results[\"f_out\"].append(f_out)\n",
    "                    results[\"random_state\"].append(random_state)\n",
    "                    results[\"multi\"].append(i)\n",
    "    results = pd.DataFrame(results)\n",
    "    #save line: pd.save...\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_f_list = [\"tanh\", \"relu\", \"sin\", \n",
    "              {\"tanh\" : 0.1, \"relu\" : 0.9},\n",
    "              {\"relu\" : 0.9, \"tanh\" : 0.1},\n",
    "              {\"tanh\" : 0.1, \"sin\" : 0.9},\n",
    "              {\"sin\" : 0.9, \"tanh\" : 0.1},\n",
    "              {\"sin\" : 0.9, \"relu\" : 0.1},\n",
    "              {\"relu\" : 0.9, \"sin\" : 0.1},\n",
    "              {\"relu\" : 0.5, \"sin\" : 0.5},\n",
    "              {\"relu\" : 0.5, \"tanh\" : 0.5},\n",
    "              {\"tanh\" : 0.5, \"sin\" : 0.5},\n",
    "              {\"tanh\" : 0.33, \"relu\" : 0.33, \"sin\" : 0.33},\n",
    "              {\"tanh\" : 0.1, \"relu\" : 0.85, \"sin\" : 0.05},\n",
    "              {\"tanh\" : 0.85, \"relu\" : 0.1, \"sin\" : 0.05},\n",
    "              {\"sin\" : 0.85, \"relu\" : 0.1, \"tanh\" : 0.05},\n",
    "              {\"sin\" : 0.85, \"relu\" : 0.05, \"tanh\" : 0.1},\n",
    "              {\"tanh\" : 0.1, \"relu\" : 0.8, \"sin\" : 0.1},\n",
    "              {\"tanh\" : 0.8, \"relu\" : 0.1, \"sin\" : 0.1},\n",
    "              {\"sin\" : 0.8, \"relu\" : 0.1, \"tanh\" : 0.1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "RUN_ACTIVATION_EXPERIMENTS = False\n",
    "if RUN_ACTIVATION_EXPERIMENTS:\n",
    "    df_ = activation_experiment([108, 109, 209, 210], act_f_list)\n",
    "    df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_.to_csv(\"rctorch_experiments2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, inputs = synthetic_data(desired_length=np.pi * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_hps = {'n_nodes': 500,\n",
    " 'connectivity': 0.6475559084256522,\n",
    " 'spectral_radius': 1.0265705585479736,\n",
    " 'regularization': 61.27292863528506,\n",
    " 'leaking_rate': 0.010949543677270412,\n",
    " 'bias': 0.5907618999481201,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 2\n",
    "idx = 2\n",
    "input_train, input_test, target_train, target_test = split_data( inputs[problem][idx], datas[problem][idx], 0.4)\n",
    "plt.plot(datas[problem][idx][:4000])\n",
    "final_figure_plot(datas[problem][idx], None, datas[problem][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_train, input_test, target_train, target_test = input_train2, input_test2, target_train2, target_test2\n",
    "# # plt.plot(datas[problem][idx][:4000])\n",
    "# final_figure_plot(datas[problem][idx], None, datas[problem][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sigma =  0.5\n",
    "noisy_target_tr = target_train + torch.rand_like(target_train) * noise_sigma\n",
    "noisy_target_te = target_test + torch.rand_like(target_test) * noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "RC_noise1 = RcNetwork(**noise_hps, feedback = True, \n",
    "            random_state = RANDOM_STATE) # was 210\n",
    "RC_noise1.fit(y = noisy_target_tr)\n",
    "score, prediction = RC_noise1.test( y = noisy_target_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_noise1.combined_plot(gt_tr_override = target_train, gt_te_override = target_test)\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_test, noisy_target_te, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rc_noise2 = RcNetwork(**noise_hps, \n",
    "            random_state = RANDOM_STATE, \n",
    "            feedback = True,\n",
    "            activation_function = \"tanh\")\n",
    "\n",
    "rc_noise2.fit(X = input_train, \n",
    "                  y = noisy_target_tr, \n",
    "                  burn_in = 0)\n",
    "\n",
    "score, prediction = rc_noise2.test(X = input_test,\n",
    "            y = noisy_target_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_noise2.combined_plot(gt_tr_override = target_train, gt_te_override = target_test)\n",
    "print(f\"score: {score}\")\n",
    "final_figure_plot(target_test, noisy_target_te, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_figure_plot(target_test,  None , prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_hyperbolic_tangent(z):\n",
    "#     z_max = z.abs().max() + 0.001\n",
    "#     z = z/z_max\n",
    "    return (1/2)*(torch.log(1+z) - torch.log(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hps = {'n_nodes': 500,\n",
    " 'connectivity': 0.6475559084256522,\n",
    " 'spectral_radius': 1.0265705585479736,\n",
    " 'regularization': 61.27292863528506,\n",
    " 'leaking_rate': 0.010949543677270412,\n",
    " 'bias': 0.5907618999481201,\n",
    "      }\n",
    "\n",
    "# extra_hps = {\"input_connectivity\" : 0.2,\n",
    "#             \"feedback_connectivity\" : 0.2}\n",
    "\n",
    "esn_pure_pred = RcNetwork(**hps,\n",
    "            activation_function = [\"tanh\"],\n",
    "            random_state = 210, \n",
    "            feedback = True)\n",
    "esn_pure_pred.fit(X = input_train, \n",
    "            y = target_train, \n",
    "            burn_in = 0)\n",
    "score, _ = esn_pure_pred.test(X = input_test,\n",
    "            y = target_test)\n",
    "esn_pure_pred.combined_plot()\n",
    "print(f'score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_figure_plot(target_test,  None , prediction )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise_comp:\n",
    "    \"\"\" A function that does noise comparison. Many noise levels for different stuff.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, noise_start, noise_stop, noise_step):\n",
    "        self.noise_levels = list(np.arange(noise_start, noise_stop, noise_step))\n",
    "        self.columns = [\"x\", \"xP\", \"noise\", \"t\"]\n",
    "        self.count = 0\n",
    "        \n",
    "    def run_experiment(self, observers):\n",
    "        for noise in self.noise_levels:\n",
    "            print(\"noise\", noise)\n",
    "            for i in range(1):\n",
    "                #get the data\n",
    "                exp2_splitter = Splitter(force_pend_data, noise = True, std = noise)\n",
    "                a, b = exp2_splitter.split()\n",
    "\n",
    "                #fit the esn\n",
    "                if observers:\n",
    "                    my_esn = My_esn(**noise_hps_obs, \n",
    "                            random_state = 210, \n",
    "                            feedback = 1,\n",
    "                            n_inputs = 1,\n",
    "                            n_outputs = 2)\n",
    "                    my_esn.fit(X =  None,\n",
    "                                y = a, \n",
    "                                burn_in = 0, gt_override=target_train)\n",
    "                    my_esn.test(X = None,\n",
    "                                gt_override = target_test,\n",
    "                                y = b)\n",
    "                else:\n",
    "                    my_esn = My_esn(**noise_hps, \n",
    "                            random_state = 210, \n",
    "                            feedback = 1,\n",
    "                            n_inputs = 1,\n",
    "                            n_outputs = 2)\n",
    "                    my_esn.fit(X =  input_train[:,1].view(-1,1),\n",
    "                                y = a, \n",
    "                                burn_in = 0, gt_override=target_train)\n",
    "                    my_esn.test(X = input_test[:,1].view(-1,1),\n",
    "                                gt_override = target_test,\n",
    "                                y = b)\n",
    "                this_round_tr = my_esn.tr_resids\n",
    "                this_round_te = my_esn.te_resids\n",
    "\n",
    "                noise_tr = torch.ones_like(this_round_tr[:, 0].reshape(-1,1)).numpy() * noise\n",
    "                noise_te = torch.ones_like(this_round_te[:, 0].reshape(-1,1)).numpy() * noise\n",
    "\n",
    "                noise_tr =  np.round(noise_tr, 4)\n",
    "                noise_te = np.round(noise_te, 4)\n",
    "\n",
    "                this_round_tr = this_round_tr.numpy()\n",
    "                this_round_te = this_round_te.numpy()\n",
    "                #assert False, f'this_round_tr {this_round_tr.shape}this_round_te {this_round_te.shape}'\n",
    "\n",
    "                t_tr = np.array(range(len(noise_tr))).reshape(-1,1)/40\n",
    "                t_te = np.array(range(len(noise_te))).reshape(-1,1)/40\n",
    "\n",
    "                if self.count == 0:\n",
    "                    print(\"building d\")\n",
    "                    Data_tr = pd.DataFrame(this_round_tr)\n",
    "                    Data_te = pd.DataFrame(this_round_te)\n",
    "                    Data_tr[\"noise\"] = noise_tr\n",
    "                    Data_te[\"noise\"] = noise_te\n",
    "\n",
    "                    Data_tr[\"t\"] = t_tr\n",
    "                    Data_te[\"t\"] = t_te\n",
    "                    \n",
    "                    Data_tr.columns = self.columns\n",
    "                    Data_te.columns = self.columns\n",
    "\n",
    "                else:\n",
    "                    new_data_tr = np.concatenate((this_round_tr, noise_tr, t_tr), axis = 1)\n",
    "                    new_data_te = np.concatenate((this_round_te, noise_te, t_te), axis = 1)\n",
    "\n",
    "                    new_data_tr = pd.DataFrame(new_data_tr)\n",
    "                    new_data_te = pd.DataFrame(new_data_te)\n",
    "\n",
    "                    new_data_tr.columns = self.columns\n",
    "                    new_data_te.columns = self.columns\n",
    "\n",
    "                    Data_tr = pd.concat((Data_tr, new_data_tr), axis = 0)\n",
    "                    Data_te = pd.concat((Data_te, new_data_te), axis = 0)\n",
    "\n",
    "                self.count +=1\n",
    "        self.Data_tr = Data_tr\n",
    "        self.Data_te = Data_te\n",
    "        \n",
    "    def loss_plot(self, var = \"x\", data = \"te\"):\n",
    "        if data == \"te\":\n",
    "            df = self.Data_tr\n",
    "        elif data == \"tr\":\n",
    "            df = self.Data_te\n",
    "        \n",
    "        fig, ax = plt.subplots(1,1, figsize = (16, 4))\n",
    "        self.g = sns.lineplot( x = 't', y = var, data = df, ax = ax, hue = \"noise\")\n",
    "        plt.yscale('log')\n",
    "        xlabels = ['{:,.4f}'.format(x) for x in self.g.get_xticks()/10]\n",
    "        self.g.set_xticklabels(xlabels)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_EXPERIMENTS = False\n",
    "if NOISE_EXPERIMENTS:\n",
    "    noise_comp = Noise_comp(0.01, 3.0, 0.05)\n",
    "    noise_comp.run_experiment(observers = False)\n",
    "    noise_comp.loss_plot(data = \"tr\")\n",
    "    noise_comp.loss_plot(data = \"te\")\n",
    "    noise_comp.loss_plot(var = \"xP\", data = \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOISE_EXPERIMENTS:\n",
    "    noise_comp_obs = Noise_comp(0.01, 3.0, 0.05)\n",
    "    noise_comp_obs.run_experiment(observers = True)\n",
    "    noise_comp_obs.loss_plot(data = \"tr\")\n",
    "    noise_comp_obs.loss_plot(data = \"te\")\n",
    "    noise_comp_obs.loss_plot(var = \"xP\", data = \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_comp_obs.Data_te.head()\n",
    "#noise_comp_obs.Data_te[\"x\"]\n",
    "#print(noise_comp_obs.Data_te[\"x\"].median(), noise_comp.Data_te[\"x\"].median() )\n",
    "#print(noise_comp_obs.Data_te[\"xP\"].median(), noise_comp.Data_te[\"xP\"].median() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are noise bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_esn.te_resids.reshape(2,-1).shape\n",
    "plt.plot(my_esn.te_resids.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section will be a force comparison\n",
    "1. Marios's idea\n",
    "2. evaluated on different forces\n",
    "\n",
    "We need a class that can easily store the different data that we want. ie. cos for different alpha and phi\n",
    "\n",
    "$$F \\propto \\alpha f(\\omega T)$$\n",
    "\n",
    "two plots: {$\\omega$ vs. L}, {$\\omega$ vs. $\\alpha$}\n",
    "$$f \\in {\\alpha sin(\\omega), cos(\\omega), \\alpha * sin(\\omega)*cos(\\omega), sin(2\\omega)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fp_DataGen:\n",
    "    \"\"\" A class that generates and stores force_pend data\"\"\"\n",
    "    \n",
    "    def __init__(self, A_range, W_range, \n",
    "                 Nt = 20000, length = 100*np.pi, \n",
    "                 x0= .5, px0 = .5, dt = None, split = 0.6, non_resonant_only = True,\n",
    "                 threshold = 5, force = \"sin\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            Nt: number of time points\n",
    "            length: number of datapoints\n",
    "            dt: upgrade later so we can take dt instead of Nt and length\n",
    "            x0, px0: initial position and momentum\n",
    "            A_range: the range of alpha (should be np.arrange)\n",
    "            W_range: the range of W  (should be np.arrange)\n",
    "        \"\"\"\n",
    "        #original was 8000, and 40 pi\n",
    "        #new is  20000 and 100 pi to preserve dt\n",
    "        \n",
    "        self.x0, self.px0 = x0, px0\n",
    "        t = np.linspace(0, length, Nt)\n",
    "        self.datasets = []\n",
    "        \n",
    "        for i, a in enumerate(A_range):\n",
    "            for j, w in enumerate(W_range):\n",
    "                my_fp = Fpendulum(t = t, x0 = x0, px0 = px0, A = a, W = w, force = force)\n",
    "                data = my_fp.force_pend_data\n",
    "                force_ = my_fp.force(A = a, W = w, t = t)\n",
    "                t = my_fp.t\n",
    "                \n",
    "                if np.max(np.abs(data)) > threshold:\n",
    "                    #resonant.append(1)\n",
    "                    resonant = 1\n",
    "                else:\n",
    "                    resonant = 0\n",
    "                \n",
    "                fp_data_spec = {\"a\": a, \"w\": w, \n",
    "                                \"data\" : data,\n",
    "                                \"force\" : force_,\n",
    "                                \"t\" : t,\n",
    "                                \"resonant\" : resonant}\n",
    "                \n",
    "                #enforce typing:\n",
    "                for key, val in fp_data_spec.items():\n",
    "                    if key != \"resonant\":\n",
    "                        fp_data_spec[key] = torch.tensor(val, dtype = torch.float32)\n",
    "                if non_resonant_only:\n",
    "                    if resonant == 0:\n",
    "                        self.datasets.append(fp_data_spec)\n",
    "                else:\n",
    "                    self.datasets.append(fp_data_spec)\n",
    "        self.find_resonance()\n",
    "        \n",
    "    def plot_all(self):\n",
    "        for dictt in self.datasets:\n",
    "            plt.plot(dictt[\"data\"], alpha = 0.1)\n",
    "    \n",
    "    def find_resonance(self, threshold = 10):\n",
    "        resonant = []\n",
    "        for i, dictt in enumerate(self.datasets):\n",
    "            if torch.max(torch.abs(dictt[\"data\"])) > threshold:\n",
    "                resonant.append(1)\n",
    "                self.datasets[i][\"resonant\"] = 1\n",
    "            else:\n",
    "                self.datasets[i][\"resonant\"] = 0\n",
    "                resonant.append(0)\n",
    "        \n",
    "        return torch.tensor(resonant, dtype = torch.int32).reshape(-1,1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _find_resonance(self, datasets, threshold = 10):\n",
    "        resonant = []\n",
    "        for i, dictt in enuemerate(datasets):\n",
    "            \n",
    "            if torch.max(torch.abs(dictt[\"data\"])) > threshold:\n",
    "                \n",
    "                resonant.append(1)\n",
    "            else:\n",
    "                \n",
    "                resonant.append(0)\n",
    "        \n",
    "        return torch.tensor(resonant, dtype = torch.int32).reshape(-1,1)\n",
    "    \n",
    "    def plot_resonant(self, threshold):\n",
    "        plt.figure(figsize = (16, 4))\n",
    "        rez = self.find_resonance(threshold)\n",
    "        flag = 0\n",
    "        for i, resonant_bool in enumerate(rez):\n",
    "            if resonant_bool == 1:\n",
    "                abs_data = torch.abs(self.datasets[i]['data'])\n",
    "                abs_px = abs_data[:,0]\n",
    "                abs_x = abs_data[:,1]\n",
    "                if flag == 0:\n",
    "                    plt.plot(abs_x, color = \"red\", alpha = 0.1, label = \"x\")\n",
    "                    plt.plot(abs_px, color = \"blue\", alpha = 0.1, label = \"px\")\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    plt.plot(abs_x, color = \"red\", alpha = 0.1)\n",
    "                    plt.plot(abs_px, color = \"blue\", alpha = 0.1)\n",
    "                    \n",
    "        plt.axhline(y = threshold, color = \"black\", label = \"threshold\")\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.title(\"resonant\")\n",
    "        plt.show()\n",
    "        \n",
    "        for i, resonant_bool in enumerate(rez):\n",
    "            if resonant_bool == 0:\n",
    "                data = self.datasets[i]['data']\n",
    "                abs_px = data[:,0]\n",
    "                abs_x = data[:,1]\n",
    "                plt.plot(abs_x, color = \"red\", alpha = 0.1)\n",
    "                plt.plot(abs_px, color = \"blue\", alpha = 0.1)\n",
    "        plt.legend()\n",
    "        plt.title(\"non-resonant\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.pi/200\n",
    "(dt * 20000)/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #original was 8000, and 40 pi\n",
    "# #new is  20000 and 100 pi to preserve dt\n",
    "\n",
    "\n",
    "#my_fp.plot_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_dataset.find_resonance()\n",
    "PLOT_RESONANCE = False\n",
    "if PLOT_RESONANCE:\n",
    "    small_dataset.plot_resonant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(max_calls=1)\n",
    "def evaluate_rcs(datasets, i, hps, observers = True):#, target_tr, target_te, obs_tr, obs_te):\n",
    "    \n",
    "    dataset = datasets[i]\n",
    "    print(f'datasets: {dataset[\"a\"]}')\n",
    "    \n",
    "    t, force, data = dataset[\"t\"], dataset[\"force\"], dataset[\"data\"]\n",
    "\n",
    "    #for now just do the pure pred.\n",
    "    t_splitter = Splitter(t, noise = False)\n",
    "    ttrain, ttest = t_splitter.split()\n",
    "\n",
    "    data_splitter = Splitter(data, noise = False)\n",
    "    target_train, target_test = data_splitter.split()\n",
    "    \n",
    "    force_splitter = Splitter(force, noise = False)\n",
    "    input_train, input_test = force_splitter.split()\n",
    "    \n",
    "    #datasets[0][\"force\"]\n",
    "    \n",
    "    my_esn = RcNetwork(**hps, \n",
    "                    random_state = 210, \n",
    "                    feedback = 1,\n",
    "                    activation_function = {\"tanh\" : 0.1, \n",
    "                           \"relu\" : 0.9, \n",
    "                           \"sin\": 0.05},)\n",
    "    \n",
    "    if observers:\n",
    "        fit = my_esn.fit(X = input_train, \n",
    "                    y = target_train,\n",
    "                    burn_in = 0) #gt_override=target_train)\n",
    "\n",
    "        val_scores, pred_ = my_esn.test(X = input_test, \n",
    "                                        #gt_override=target_test,\n",
    "                                        y = target_test)\n",
    "    else:\n",
    "        fit = my_esn.fit(X =  None, #input_train, \n",
    "                    y = target_train,\n",
    "                    burn_in = 0) #gt_override=target_train)\n",
    "\n",
    "        val_scores, pred_ = my_esn.test(X = None, #input_test,\n",
    "                    #gt_override=target_test,\n",
    "                    y = target_test)\n",
    "\n",
    "    resids = ( pred_ - target_test) ** 2 #my_esn.te_resids\n",
    "\n",
    "    #we need x and px eventually, this is fine for now\n",
    "    max_resid  = torch.max(resids)\n",
    "    mean_resid = torch.mean(resids)\n",
    "    \n",
    "    #tensors2save = {}\n",
    "    \n",
    "    data2save = {\"observers\" : False,\n",
    "                 \"max_resid\" : max_resid,\n",
    "                 \"mean_resid\" : mean_resid,\n",
    "                 \"a\" : dataset[\"a\"],\n",
    "                 \"w\" : dataset[\"w\"],\n",
    "                 \"resids\" : resids,\n",
    "                 \"tr_target\" : target_train.numpy(),\n",
    "                 \"tr_pred\" : fit,\n",
    "                 \"te_target\" :  target_test.numpy(),\n",
    "                 \"te_pred\" : pred_.numpy()}\n",
    "    return data2save#, tensors2save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_dataset.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_inputs = {\"target_tr\" : a,\n",
    "#               \"target_te\" : b,\n",
    "#               \"obs_tr\" : None,\n",
    "#               \"obs_te\" : None}\n",
    "def preprocess_parallel_batch(lst, batch_size):\n",
    "    iters = []\n",
    "    floor_div = len(lst)//batch_size\n",
    "    remainder = len(lst) % batch_size\n",
    "    for i in range(floor_div):\n",
    "        iters.append(batch_size)\n",
    "    if remainder != 0:\n",
    "        iters += [remainder]\n",
    "    start_index = 0\n",
    "    batched_lst = []\n",
    "    for iterr in iters:\n",
    "        stop_index = start_index + iterr\n",
    "        batched_lst.append(lst[start_index:stop_index])\n",
    "    return batched_lst\n",
    "\n",
    "def retrieve_dataset(dataset_obj, hps, batch_size = 9):\n",
    "    \n",
    "    #     range_ = range(0, max(len(dataset_obj.datasets) + 1, batch_size + 1), batch_size)\n",
    "    rez = []\n",
    "    datasets = dataset_obj.datasets.copy()\n",
    "    datasets_id = ray.put(datasets)\n",
    "    batch_indices = preprocess_parallel_batch(list(range(len(datasets))), batch_size)\n",
    "    total_idx = 0\n",
    "    \n",
    "    hps_id = ray.put(hps)\n",
    "    for i, sub_batch in enumerate(batch_indices):\n",
    "        start = sub_batch[0] + total_idx\n",
    "        stop = sub_batch[-1]+ total_idx\n",
    "        \n",
    "        print(f'start {start} stop {stop}')\n",
    "        \n",
    "        this_set_indexs = list(range(start, stop))\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        results = ray.get([evaluate_rcs.remote(datasets_id, i, hps_id) for i in this_set_indexs])\n",
    "        \n",
    "        rez+=results\n",
    "        #         if i == 2:\n",
    "        #             breakpoint()\n",
    "        #evaluate_rcs_plain(datasets_spec[0], hps)\n",
    "        total_idx += (stop - start)\n",
    "        print(f'percent_complete {i/len(batch_indices) * 100}')\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parallel_batch(lst, batch_size):\n",
    "    iters = []\n",
    "    floor_div = len(lst)//batch_size\n",
    "    remainder = len(lst) % batch_size\n",
    "    for i in range(floor_div):\n",
    "        iters.append(batch_size)\n",
    "    if remainder != 0:\n",
    "        iters += [remainder]\n",
    "    start_index = 0\n",
    "    batched_lst = []\n",
    "    for iterr in iters:\n",
    "        stop_index = start_index + iterr\n",
    "        batched_lst.append(lst[start_index:stop_index])\n",
    "    return batched_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# noise_hps = {'n_nodes': 500,\n",
    "#  'connectivity': 0.20541412114258625,\n",
    "#  'spectral_radius': 1.4592119455337524,\n",
    "#  'regularization': 7.651269704734278,\n",
    "#  'leaking_rate': 0.017093051224946976,\n",
    "#  'bias': 0.36459600925445557}\n",
    "noise_hps = {'connectivity': 0.4071449746896983,\n",
    " 'spectral_radius': 1.1329107284545898,\n",
    " 'n_nodes': 202,\n",
    " 'regularization': 1.6862021450927922,\n",
    " 'leaking_rate': 0.009808523580431938,\n",
    " 'bias': 0.48509588837623596}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results_dfs(rez_, fp = None):\n",
    "    \n",
    "    \n",
    "    full_data_keys = [\"tr_target\", \"tr_pred\", \"te_target\", \"te_pred\", \"resids\"]\n",
    "    pd_keys = [\"observers\", \"max_resid\", \"mean_resid\", \"a\", \"w\"]\n",
    "    \n",
    "    #pd_results = pd.DataFrame(rez_[pd_keys])\n",
    "    data_summaries = []\n",
    "    \n",
    "    for dict_ in rez:\n",
    "        data_summaries.append({key: float(val) for key, val in dict_.items() if key in pd_keys})\n",
    "    \n",
    "#     for results in rez:\n",
    "#         try :\n",
    "#             pd_results[col] = pd_results[col].astype(float)\n",
    "#         except:\n",
    "#             pass #assert False, f'{col} {pd_results[col]}'\n",
    "#     pd_results.head()\n",
    "    if fp:\n",
    "        pd_results.to_csv(fp)\n",
    "    return pd.DataFrame(data_summaries), rez_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_range, w_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a_range = np.arange(0.1, 1.0, 0.05)\n",
    "w_range = np.arange(0.1, 1.0, 0.05)\n",
    "\n",
    "force_experiments = False\n",
    "if force_experiments:\n",
    "    for force__ in [\"sin\", \"cos\", \"sincos\"]:\n",
    "        small_dataset = Fp_DataGen(A_range = a_range, W_range = w_range, Nt = 8000, length = 40*np.pi,\n",
    "                                   force = force__)\n",
    "        rez = retrieve_dataset(small_dataset, noise_hps)\n",
    "        pd_results, all_data = make_results_dfs(rez)\n",
    "        print(pd_results)\n",
    "        fp_base = './new_results/' + force__\n",
    "        fp1 = fp_base +'_results.csv'\n",
    "        fp2 = fp_base + '_all_data.pickle'\n",
    "        pd_results.to_csv(fp1)\n",
    "        with open(fp2, 'wb') as handle:\n",
    "            pickle.dump(all_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#         \n",
    "\n",
    "# print a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = \"cos\"\n",
    "val = \"mean_resid\"\n",
    "\n",
    "fp = \"new_results/\" + force + \"_results.csv\"\n",
    "fp2 = \"new_results/\"+ force + \"_all_data.pickle\"\n",
    "\n",
    "pd_results_ = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd_results_[\"max_resid\"][0])\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "\n",
    "with open(fp2, 'rb') as handle:\n",
    "    cos_results = pickle.load(handle)\n",
    "#cos_results\n",
    "\n",
    "plt.title(force + \" force: \" + val)\n",
    "pivot = pd_results_.pivot(index='a', columns='w', values=val)\n",
    "g = sns.heatmap(pivot, vmax = 1, vmin = 0, norm=LogNorm(), cmap = \"cubehelix\")  #)#np.log10(pivot))\n",
    "g.set_facecolor('lightpink')\n",
    "yticklabels = g.get_yticklabels()\n",
    "xticklabels = g.get_xticklabels()\n",
    "g.set_yticklabels([round(float(yticklabels[i].get_text()),3) for i in  range(len(yticklabels))])\n",
    "g.set_xticklabels([round(float(xticklabels[i].get_text()),3) for i in  range(len(xticklabels))])\n",
    "\n",
    "#ylabels = ['{:,.2f}'.format(x) for x in g.get_yticks()]\n",
    "#g.set_yticklabels(ylabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_yticklabels() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cos_results[0].keys())\n",
    "\n",
    "def plot_pred_(i, plot_test_set = True, phase_plot = True, trajectories = False):\n",
    "    if plot_test_set:\n",
    "        keys = \"te_target\", \"te_pred\"\n",
    "    else:\n",
    "        keys = \"tr_target\", \"fit\"\n",
    "    \n",
    "    #plt.figure(figsize = (6,2))\n",
    "    cos_result = cos_results[i]\n",
    "    print(cos_result.keys())\n",
    "    \n",
    "    pred = cos_result[keys[1]]\n",
    "    gt = cos_result[keys[0]]\n",
    "    \n",
    "    \n",
    "    if trajectories:\n",
    "        fig, ax = plt.subplots(1,2, figsize = (14,3))\n",
    "        ax[0].plot(pred, '--', linewidth = 2)\n",
    "        ax[0].plot(gt, alpha = 0.5, linewidth = 2)\n",
    "\n",
    "        ax[1].plot((cos_results[i][keys[0]] - cos_results[i][keys[1]])**2, '--', linewidth = 2)\n",
    "        #ax[0].plot(cos_results[i][\"fit\"], alpha = 0.5, linewidth = 2)\n",
    "\n",
    "        ax[1].set_yscale(\"log\")\n",
    "    if phase_plot:\n",
    "        final_figure_plot(pred, None, gt)\n",
    "    plt.show()\n",
    "for i in range(len(cos_results)):\n",
    "    plot_pred_(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def run_experiments(datas, inputs, hps, split, output_activation,  noise = None, activation_dict = \"tanh\"):\n",
    "    #split = 0.6\n",
    "    scores = []\n",
    "    for i, data in enumerate(datas):\n",
    "        for j, trajectory in enumerate(data):\n",
    "            force_pend_data__ = trajectory\n",
    "            input_tr, input_te, target_tr, target_te = split_data( inputs[i][j], trajectory, split)\n",
    "           \n",
    "\n",
    "\n",
    "            input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, split)\n",
    "            #input_train, input_test, target_train, target_test = split_data( input_, force_pend_data, 0.6)\n",
    "            \n",
    "\n",
    "            esn_pure_pred = RcNetwork(**hps, \n",
    "                        random_state = 210, \n",
    "                        feedback = True,\n",
    "                        output_activation = output_activation,\n",
    "                        activation_function = activation_dict)\n",
    "                        #solve_sample_prop = 0.8\n",
    "                                            \n",
    "            if noise is not None:\n",
    "                exp2_splitter = Splitter(trajectory, noise = True, std = noise, split = split)\n",
    "                noisy_tr_target, noisy_te_target = exp2_splitter.split()\n",
    "                \n",
    "                esn_pure_pred.fit(X = noisy_tr_target, #input_tr,#None, \n",
    "                            y = target_tr, \n",
    "                            burn_in = 0)\n",
    "                score, prediction = esn_pure_pred.test(X = noisy_te_target,\n",
    "                            y = target_te)\n",
    "                final_figure_plot(test_gt = target_te, noisy_test_gt = noisy_te_target, rc_pred = prediction, \n",
    "                      noisy_format = '.')\n",
    "            else:\n",
    "                esn_pure_pred.fit(X = input_tr, #input_tr,#None, \n",
    "                            y = target_tr, \n",
    "                            burn_in = 0)\n",
    "                score, prediction = esn_pure_pred.test(X = input_te,\n",
    "                            y = target_te)\n",
    "                final_figure_plot(test_gt = target_te, noisy_test_gt = None, rc_pred = prediction, \n",
    "                      noisy_format = '.')\n",
    "                \n",
    "#             esn_pure_pred.combined_plot(gt_tr_override=target_tr,\n",
    "#                                         gt_te_override=target_te)\n",
    "            \n",
    "            print(f'score : {score}')\n",
    "            scores.append(score)\n",
    "            \n",
    "            plt.show()\n",
    "    total_score = np.mean(scores)\n",
    "    print(f'total score {total_score}')\n",
    "\n",
    "opt_hps = {'connectivity': 0.4071449746896983,\n",
    " 'spectral_radius': 1.1329107284545898,# 1.1329107284545898,\n",
    " 'n_nodes': round(201.7901153564453),\n",
    " 'regularization': 1.6862021450927922,\n",
    " 'leaking_rate': 0.009808523580431938,\n",
    " 'bias': 0.48509588837623596,\n",
    " 'input_connectivity' : 0.3}\n",
    "\n",
    "run_experiments(datas, inputs, hps = opt_hps, split = 0.6, output_activation = \"identity\")\n",
    "\n",
    "run_experiments(datas, inputs, hps = opt_hps, split = 0.5, output_activation = \"tanh\", noise = 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment0_hps  = {'connectivity': 0.010497199729654356,\n",
    " 'spectral_radius': 1.6224205493927002,\n",
    " 'n_nodes': int(100.01666259765625),\n",
    " 'regularization': 0.019864175793163488,\n",
    " 'leaking_rate': 0.044748689979314804,\n",
    " 'bias': 0.8152865171432495}\n",
    "run_experiments(datas, inputs, hps = opt_hps, split = 0.5,\n",
    "                activation_dict = {\"relu\" : 0.33, \"tanh\" : 0.5, \"sin\" : 0.1},\n",
    "                output_activation = \"tanh\", noise = 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_results.to_csv('./fp_sin_results.csv')\n",
    "# pd_results.to_csv('./fp_sin_pd_max_resid.csv')\n",
    "# #pd_results.to_csv('./fp_sin_pd_mean_resid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add this function to esn_cv\n",
    "def recover_hps(self):\n",
    "    best_vals = self.X_turbo[torch.argmax(self.Y_turbo)]\n",
    "        \n",
    "    denormed_ = self.denormalize_bounds(best_vals)\n",
    "\n",
    "    try:\n",
    "        denormed_ = denormalize_bounds(best_vals)\n",
    "    except:\n",
    "        print(\"FAIL\")\n",
    "\n",
    "    #best_vals = X_turbo[torch.argmax(Y_turbo)]\n",
    "\n",
    "    #####Bad temporary code to change it back into a dictionaryf\n",
    "    denormed_free_parameters = list(zip(self.free_parameters, denormed_))\n",
    "    denormed_free_parameters = dict([ (item[0], item[1].item()) for item in denormed_free_parameters])\n",
    "\n",
    "    best_hyper_parameters = denormed_free_parameters\n",
    "    for fixed_parameter in self.fixed_parameters:\n",
    "        best_hyper_parameters = {fixed_parameter : self.bounds[fixed_parameter], **best_hyper_parameters }\n",
    "\n",
    "    #log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt']\n",
    "    for var in self.log_vars:\n",
    "        if var in best_hyper_parameters:\n",
    "            best_hyper_parameters[var] = 10. ** best_hyper_parameters[var] \n",
    "\n",
    "\n",
    "\n",
    "    # Return best parameters\n",
    "    return best_hyper_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below this point is Hennon Hailes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data: <a href='https://en.wikipedia.org/wiki/Hénon–Heiles_system'>The Henon-Heiles System</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(prediction,target):\n",
    "    try:\n",
    "        prediction = prediction.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        target = target.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return (target.flatten() - prediction.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions:\n",
    "def plot_data(train, test, ydata):\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    if isinstance(train, np.ndarray):\n",
    "        train, test = torch.tensor(train), torch.tensor(test)\n",
    "    trainlen, testlen = len(train), len(test)\n",
    "    plt.plot(range(0,trainlen+testlen),hstack((train,test)),'k',label='data')\n",
    "    plt.plot(range(0,trainlen), train,'g',label='train')\n",
    "    plt.plot(range(trainlen,trainlen+testlen), test,'-r',label='test')\n",
    "    plt.ylabel('x(t)')\n",
    "    plt.legend(loc=(0.1,1.1),fontsize=18,ncol=3)\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(tdata,ydata,'k')\n",
    "    plt.ylabel('y(t)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plotResults(trainlen, testlen, data, yfit, yhat, resTrain, resTest):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        trainlen: the length of the training set\n",
    "        testlen: the length of the test set\n",
    "        data: the entire dataset\n",
    "        yfit: the prediction of the RC on the training set \n",
    "        yhat: the prediction of the RC on an unseen test set\n",
    "        resTrain: training residuals\n",
    "        resTest: test residuals\n",
    "    \"\"\"\n",
    "    #data plot\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(0,trainlen+testlen),data[:(trainlen+testlen)],'k',  linewidth=2, label=\"data\")\n",
    "    plt.plot(range(0,trainlen),yfit,'--g',  linewidth=2, alpha=0.9, label=\"train\")\n",
    "    plt.plot(range(trainlen,trainlen+testlen), yhat,'--r', linewidth=2,  alpha=1, label=\"test\")\n",
    "    lo,hi = plt.ylim()\n",
    "    plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],'--b',alpha=0.8, linewidth=4)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('x')\n",
    "    plt.legend(loc=(0.1,1.1),fontsize=18,ncol=3)\n",
    "\n",
    "    \n",
    "    #Residuals plot\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(0,trainlen),  np.abs(resTrain),'--g',  linewidth=2, alpha=0.9, label=\"train\")\n",
    "    plt.plot(range(trainlen,trainlen+testlen), np.abs(resTest),'--r', linewidth=2,  alpha=1, label=\"test\")\n",
    "    lo, hi = plt.ylim()\n",
    "    plt.yscale(\"log10\") \n",
    "    plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],'--b',alpha=0.8, linewidth=4)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Residuals')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = loadtxt(\"filename.dat\", comments=\"#\", delimiter=\",\", unpack=False)\n",
    "tdata = loadtxt(\"data/HenonHeiles/t.dat\")\n",
    "xdata = loadtxt(\"data/HenonHeiles/x.dat\")\n",
    "ydata = loadtxt(\"data/HenonHeiles/y.dat\")\n",
    "\n",
    "tdata = tdata.astype('float32')\n",
    "xdata = xdata.astype('float32')\n",
    "ydata = ydata.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# N = len(tdata)\n",
    "# print(\"The time series consist of \", N, \" points.\")\n",
    "\n",
    "# plt.figure(figsize=(14,6))\n",
    "# plt.subplot(2,1,1)\n",
    "# plt.plot(tdata,xdata,'k')\n",
    "# plt.xlabel('t')\n",
    "# plt.ylabel('x(t)')\n",
    "# plt.subplot(2,1,2)\n",
    "# plt.plot(tdata,ydata,'k')\n",
    "# plt.ylabel('y(t)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "#split the forecast:\n",
    "split = 0.45\n",
    "trainlen = int(split*N)\n",
    "testlen  = int((1-split)*N)\n",
    "# trainlen = int(0.5*N)\n",
    "# testlen  = int(0.5*N)\n",
    "\n",
    "\n",
    "# Input  data equivalents:\n",
    "#ttrain = np.ones(trainlen)\n",
    "#ttest=np.ones(testlen)\n",
    "\n",
    "# ttrain = tdata[:trainlen]\n",
    "# ttest  = tdata[trainlen:trainlen+testlen]\n",
    "\n",
    "ytrain = ydata[:trainlen]\n",
    "ytest  = ydata[trainlen:trainlen+testlen]\n",
    "\n",
    "# Output data\n",
    "xtrain = xdata[:trainlen]\n",
    "xtest = xdata[trainlen:trainlen+testlen]\n",
    "\n",
    "# plt.figure(figsize=(14,2))\n",
    "\n",
    "# plt.plot(range(0,trainlen), xtrain,'r')\n",
    "# plt.plot(range(trainlen,trainlen+testlen), xtest,'-g')\n",
    "# # plt.plot(ttrain, xtrain,'b')\n",
    "# # plt.plot(ttest, xtest,'-r')\n",
    "plot_data(xtrain, xtest, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_splitter = Splitter(xdata, noise = True)\n",
    "xtrain_noisy, xtest_noisy = my_splitter.split()\n",
    "\n",
    "plot_data(xtrain_noisy, xtest_noisy, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_pred_noise_hps = {'n_nodes': 500,\n",
    " 'connectivity': 0.12408451143662941,\n",
    " 'spectral_radius': 1.2, #1.1268014907836914,\n",
    " 'regularization': 0.022762411251526036,\n",
    " 'leaking_rate': 0.2863200306892395,\n",
    " 'bias': 0.32563644647598267}\n",
    "\n",
    "pp_noise_esn = My_esn(**pure_pred_noise_hps, \n",
    "            random_state = 210, \n",
    "            feedback = 1,\n",
    "            n_inputs = 1,\n",
    "            n_outputs = 2)\n",
    "pp_noise_esn.fit(X = None, \n",
    "            y =  a,\n",
    "            burn_in = 0,\n",
    "            gt_override = target_train)\n",
    "pp_noise_esn.test(X = None,\n",
    "            y =  b,\n",
    "            gt_override = target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_noise_esn.combined_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "bounds_dict = {\"connectivity\" : (-1, -0.1), \n",
    "               \"spectral_radius\" : (1, 2),\n",
    "               \"n_nodes\" : 500,\n",
    "               \"regularization\" : (-3, 3),\n",
    "               \"leaking_rate\" : (0, 1),\n",
    "               #\"input_scaling\" : (0, 1),\n",
    "               #\"feedback_scaling\" : (0, 1),\n",
    "               \"bias\": (0,1)\n",
    "               }\n",
    "\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict, esn_feedback = True, \n",
    "                            scoring_method = \"nmse\", interactive = True, \n",
    "                            n_jobs = 4, cv_samples = 1, initial_samples = 8, \n",
    "                            subsequence_length = int(ytrain.shape[0] * 0.8),\n",
    "                            random_seed = 209, success_tolerance = 3, ODE_order = None,\n",
    "                            length_min = 2**-11,\n",
    "                            validate_fraction = 0.5,\n",
    "                            n_inputs = 1,\n",
    "                            n_outputs = 1\n",
    "                            \n",
    "           )\n",
    "#optimize:\n",
    "opt_hps = esn_cv.optimize( n_trust_regions = 2, max_evals = 500,\n",
    "                            x = xtrain_noisy.reshape(-1,1), y =ytrain.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_denoise_hps = {'n_nodes': 200,\n",
    "#  'connectivity': 0.29002750025150953,\n",
    "#  'spectral_radius': 1.2885233163833618,\n",
    "#  'regularization': 0.013653433082063734,\n",
    "#  'leaking_rate': 0.5670961141586304,\n",
    "#  'bias': 0.3260454535484314}\n",
    "\n",
    "noise_hps = {'n_nodes': 500,\n",
    " 'connectivity': 0.32094487651215875,\n",
    " 'spectral_radius': 1.23499596118927,\n",
    " 'regularization': 0.8368901513227046,\n",
    " 'leaking_rate': 0.32397231459617615,\n",
    " 'bias': 0.24689573049545288}\n",
    "#trained from x to y, appear to be generally good denoising parameters for this equation.\n",
    "\n",
    "esn = EchoStateNetwork(**noise_hps, random_state = 209, feedback = 1, n_inputs = 1, n_outputs = 1)\n",
    "yfit = esn.fit(X = xtrain_noisy.reshape(-1,1), y = ytrain, burn_in = 0)\n",
    "scoreTest, yhat = esn.test(X = xtest_noisy.reshape(-1,1), y =ytest.reshape(-1,1))\n",
    "\n",
    "# MSE in the training and testing\n",
    "scoreTrain = myMSE(yfit,ytrain)\n",
    "scoreTest = myMSE(yhat,ytest)\n",
    "print(\"Training mean square error: \",scoreTrain)\n",
    "print(\"Testing  mean square error: \",scoreTest)\n",
    "\n",
    "# Residuals \n",
    "resTrain = residuals(yfit, ytrain);\n",
    "resTest = residuals(yhat, ytest);\n",
    "\n",
    "# Plot:\n",
    "plotResults(trainlen, testlen, ydata, yfit, yhat, resTrain, resTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**noise_hps, random_state = 209, feedback = 1, n_inputs = 1, n_outputs = 1)\n",
    "xfit = esn.fit(X = xtrain_noisy.reshape(-1,1), y = xtrain, burn_in = 0)\n",
    "scoreTest, xhat = esn.test(X = xtest_noisy.reshape(-1,1), y =xtest.reshape(-1,1))\n",
    "\n",
    "\n",
    "# MSE in the training and testing\n",
    "scoreTrain = myMSE(xfit,xtrain)\n",
    "scoreTest = myMSE(xhat,xtest)\n",
    "print(\"Training mean square error: \",scoreTrain)\n",
    "print(\"Testing  mean square error: \",scoreTest)\n",
    "\n",
    "# Residuals \n",
    "resTrain = residuals(xfit, xtrain);\n",
    "resTest = residuals(xhat, xtest);\n",
    "\n",
    "# Plot:\n",
    "plotResults(trainlen, testlen, xdata, xfit, xhat, resTrain, resTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn.extended_states.shape, esn.X.shape\n",
    "# optimized_hyper_params = {'n_nodes': 200,\n",
    "#  'connectivity': 0.4483155375901789,\n",
    "#  'spectral_radius': 1.5525517463684082,\n",
    "#  'regularization': 0.005069355134121151,\n",
    "#  'leaking_rate': 0.6272786855697632,\n",
    "#  'bias': 0.750773549079895}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (10,5))\n",
    "plt.sca(ax[0])\n",
    "plt.plot(torch.abs(esn.extended_states[:,0:100]), alpha = 0.3)\n",
    "plt.sca(ax[1])\n",
    "plt.plot(esn.val_states[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states2plot = 10\n",
    "index2start = 10\n",
    "valstates2plot =1000\n",
    "combined_states = torch.cat((esn.extended_states[:,1:states2plot+1], esn.val_states[0:valstates2plot, 0:states2plot]))\n",
    "plt.plot(combined_states[index2start:])\n",
    "plt.axvline(500-index2start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_hyper_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long range forecast (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlen = int(0.5*N)\n",
    "testlen  = int(0.5*N)\n",
    "\n",
    "# Input  data\n",
    "ttrain = np.ones(trainlen)\n",
    "ttest=np.ones(testlen)\n",
    "\n",
    "ytrain = ydata[:trainlen]\n",
    "ytest  = ydata[trainlen:trainlen+testlen]\n",
    "\n",
    "# Output data\n",
    "xtrain = xdata[:trainlen]\n",
    "xtest = xdata[trainlen:trainlen+testlen]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,2))\n",
    "plt.plot(range(0,trainlen), xtrain,'r')\n",
    "plt.plot(range(trainlen,trainlen+testlen), xtest,'-g')\n",
    "# plt.plot(ttrain, xtrain,'b')\n",
    "# plt.plot(ttest, xtest,'-r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RcTorch Observers Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_dict = {\"connectivity\" : (-1, -0.1), \n",
    "               \"spectral_radius\" : (1, 2),\n",
    "               \"n_nodes\" : 200,\n",
    "               \"regularization\" : (-3, 3),\n",
    "               \"leaking_rate\" : (0, 1),\n",
    "               #\"input_scaling\" : (0, 1),\n",
    "               #\"feedback_scaling\" : (0, 1),\n",
    "               \"bias\": (0,1)\n",
    "               }\n",
    "\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict, esn_feedback = True, \n",
    "                            scoring_method = \"nmse\", interactive = True, \n",
    "                            n_jobs = 1, cv_samples = 2, initial_samples = 10, \n",
    "                            subsequence_length = int(ytrain.shape[0] * 0.9),\n",
    "                            length_min = 2**-11,\n",
    "                            random_seed = 123)\n",
    "optimized_hyper_params = esn_cv.optimize(y = xtrain.reshape(-1,1), x = ytrain.reshape(-1,1), \n",
    "                                         n_outputs = 1, n_trust_regions = 2, max_evals = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv.parallel_arguments.keys()\n",
    "esn_cv.parallel_arguments['declaration_args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_hps_ = hyper_params = {'n_nodes': 200,\n",
    " 'connectivity': 0.13505189245513274,\n",
    " 'spectral_radius': 1.6877728700637817,\n",
    " 'regularization': 0.04002294006918671,\n",
    " 'leaking_rate': 0.2642587423324585,\n",
    " 'bias': 0.7290011644363403}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**opt_hps_, random_state = 123, feedback = 0)\n",
    "xfit = esn.fit(y = xtrain, X = ytrain, burn_in = 0)\n",
    "xfit = xfit.reshape(-1)\n",
    "#scoreTrain, yfit = esn.test(y = ytrain)\n",
    "#scoreTest, xhat = esn.test(y = xtest, X = ytest)\n",
    "scoreTest, test_outputs, test_input = esn.test(y = xtest.reshape(-1,1), X = ytest)\n",
    "xhat = test_outputs[\"yhat\"]\n",
    "\n",
    "\n",
    "# MSE in the training and testing\n",
    "scoreTrain = myMSE(xfit, xtrain)\n",
    "scoreTest = myMSE(xhat, xtest)\n",
    "print(\"Training mean square error: \",scoreTrain)\n",
    "print(\"Testing  mean square error: \",scoreTest)\n",
    "\n",
    "# Residuals \n",
    "resTrain = residuals(xfit,xtrain);\n",
    "resTest = residuals(xhat,xtest);\n",
    "\n",
    "# Plot:\n",
    "plotResults(trainlen, testlen, xdata, xfit, xhat, resTrain, resTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_outputs[\"yhat\"])\n",
    "plt.plot(test_outputs['ytest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(esn.X_val_extended.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(esn.extended_states[:,:10]); torch.std(esn.extended_states[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**hyper_params, random_state = 209, feedback = 0)\n",
    "xfit = esn.fit(y = xtrain, burn_in = 0)\n",
    "print(xfit[0].shape)\n",
    "xfit = xfit.reshape(-1)\n",
    "#return score, {\"yhat\": y_predicted.data, \"ytest\": y}, X[self.burn_in:]\n",
    "scoreTest, test_outputs, test_input = esn.test(y = xtest.reshape(-1,1))\n",
    "xhat = test_outputs[\"yhat\"]\n",
    "\n",
    "\n",
    "# MSE in the training and testing\n",
    "scoreTrain = myMSE(xfit,xtrain)\n",
    "scoreTest = myMSE(xhat,xtest)\n",
    "print(\"Training mean square error: \",scoreTrain)\n",
    "print(\"Testing  mean square error: \",scoreTest)\n",
    "\n",
    "# Residuals \n",
    "resTrain = residuals(xfit, xtrain);\n",
    "resTest = residuals(xhat, xtest);\n",
    "\n",
    "# Plot:\n",
    "plotResults(trainlen, testlen, xdata, xfit, xhat, resTrain, resTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
