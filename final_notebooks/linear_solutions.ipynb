{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wanted-burden",
   "metadata": {},
   "source": [
    "# RcTorch 2021 NuerIPS submission Notebook 1\n",
    "## Exact solutions: 1st order  Linear ODE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suffering-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from rctorchprivate import *#RcTorch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "listed-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',#'bold',\n",
    "        'size'   : 24}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-brighton",
   "metadata": {},
   "source": [
    "### This notebook contains the solutions to the linear first order explicitily time-dependent equation   of the form $\\dot y + q(t) y = f(t) $.\n",
    "\n",
    "Specifically we solve three related differential equations:\n",
    "1) Simple population:  <font color='blue'>$\\dot y + y =0$  </font>\n",
    "* Analytical solution: <font color='green'>$y = y_0 e^{-t}$</font>\n",
    "\n",
    "2) Driven population:  <font color='blue'>$\\dot y + y + \\sin(t) =0$ </font>\n",
    "* Analytical solution: <font color='green'>$y = e^{-t}\\left(y_0 + \\frac{1}{2}\\right) + \\frac{1}{2}\\left( \\sin(t) - \\cos(t) \\right)$ </font>\n",
    "\n",
    "3) Driven population with nonlinear time dependence:  <font color='blue'> $\\dot y + t^2 y + \\sin(t) =0$  </font>\n",
    "* Analytical solution: None\n",
    "\n",
    "### Limitations:\n",
    "    Only the first initial condition can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-combine",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collected-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(RC, results, integrator_model, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu()\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu()\n",
    "        if not i:\n",
    "            labels = [\"RC\", \"Integrator Solution\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        ax.plot(X, y, color = \"dodgerblue\", label = labels[0], linewidth = lineW + 1, alpha = 0.9)\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"red\", alpha = 0.9, label = labels[1],  linewidth = lineW)\n",
    "    \n",
    "    plt.ylabel(r'$y(t)$');\n",
    "    ax.legend();\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def convert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    Returns\n",
    "    -------\n",
    "    ode_coefs\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs\n",
    "    \n",
    "\n",
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = y.cpu()\n",
    "        ydot = ydot.cpu()\n",
    "        \n",
    "        ode_coefs = convert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "            label = r'{Individual Trajectory RMSR}'\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "            label = None\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, color = \"orangered\", alpha = 0.4, label = label, linewidth = lineW-1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "    ax.plot(X, rmsr, \n",
    "               color = \"blue\", \n",
    "               alpha = 0.9, \n",
    "               label = r'{RMSR}',\n",
    "               linewidth = lineW-0.5)\n",
    "\n",
    "    ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(r'{RMSR}')\n",
    "\n",
    "def driven_force(X, A = 1):\n",
    "    \"\"\" a force function, specifically f(t) = sin(t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, a torch.tensor of equal dimension to the input time tensor.\n",
    "    \"\"\"\n",
    "    return A * torch.sin(X)\n",
    "\n",
    "def no_force(X):\n",
    "    \"\"\" a force function (returns 0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, in this case 0.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \"\"\" A reparameterization function, specifically g= 1-e^(-t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        the input time tensor\n",
    "    order:\n",
    "        the ODE order\n",
    "    \n",
    "    Returns:\n",
    "    g: torch.tensor\n",
    "        the reparameterization of t which satisfies the initial conditions\n",
    "    g_dot: torch.tensor\n",
    "        the time derivative of g\n",
    "    Returns\n",
    "    -------\n",
    "    g, gdot\n",
    "    \"\"\"\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot\n",
    "    \n",
    "    #first derivative\n",
    "    \n",
    "    \n",
    "    #example code for higher derivatives:\n",
    "    #####################################\n",
    "    \n",
    "    #derivatives_of_g.append(g_dot)\n",
    "    #derivatives_of_g.append(g)\n",
    "#     for i in range(order):\n",
    "#         if i %2 == 0:\n",
    "#             #print(\"even\")\n",
    "#             derivatives_of_g.append(g_dot)\n",
    "#         else:\n",
    "#             #print(\"odd\")\n",
    "#             derivatives_of_g.append(-g_dot)\n",
    "#    return derivatives_of_g\n",
    "\n",
    "\n",
    "#simple population eq loss\n",
    "def custom_loss(X, y, ydot, out_weights, \n",
    "                enet_strength = None,\n",
    "                enet_alpha = None,\n",
    "                ode_coefs = None,\n",
    "                force_t = None, \n",
    "                reg = True, \n",
    "                reparam = reparam, \n",
    "                init_conds = None,\n",
    "                mean = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the population equation loss)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    \n",
    "    #lam is short for lambda\n",
    "    lam = ode_coefs[0]\n",
    "    L =  ydot + lam * y - force_t\n",
    "    \n",
    "    L = torch.square(L)\n",
    "    \n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    \n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interstate-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the length of xtrain won't matter above. Only dt , x0, and xf matter for ODEs.\n",
    "#the reason for this is that the input time vector is reconstructed internally in rctorch\n",
    "#in order to satisfy the specified dt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-preference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respected-chicken",
   "metadata": {},
   "source": [
    "### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecological-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "twelve-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrator model\n",
    "def population_model(y, t, t_pow = 0, force_k = 0, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-sapphire",
   "metadata": {},
   "source": [
    "#### Train the RC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "BURN_IN = 0\n",
    "#BURN_IN = 1000\n",
    "x0,xf, nsteps = 0, 2.5, 1000\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False).view(-1,1)\n",
    "x0,xf, nsteps = 2.5, 10, 1000\n",
    "xtest = torch.linspace(x0, xf, steps = nsteps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "returning-distributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURN_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imposed-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pop_hps = {'dt': 0.0031622776601683794,\n",
    " 'n_nodes': 250,\n",
    " 'connectivity': 0.7170604557008349,\n",
    " 'spectral_radius': 1.5755887031555176,\n",
    " 'regularization': 0.00034441529823729916,\n",
    " 'leaking_rate': 0.9272222518920898,\n",
    " 'bias': 0.1780446171760559}\n",
    "simple_pop_hps2 = {'dt': 0.0031622776601683794,\n",
    " 'n_nodes': 250,\n",
    " 'connectivity': 0.7170604557008349,\n",
    " 'spectral_radius': 1.5755887031555176,\n",
    " 'regularization': 0.00034441529823729916,\n",
    " 'leaking_rate': 0.9272222518920898,\n",
    " 'bias': 0.1780446171760559,\n",
    "  \"input_scaling\" : 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "superb-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 388 ms, sys: 149 ms, total: 537 ms\n",
      "Wall time: 75.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feedback = [False]\n",
    "for hps in [simple_pop_hps, simple_pop_hps2]:\n",
    "#inital_RC\n",
    "    pop_RC = RcNetwork(**hps,\n",
    "                              random_state = 209, \n",
    "                              dtype = torch.float32,\n",
    "                              feedback = False)\n",
    "\n",
    "    train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "                  \"burn_in\" : int(BURN_IN), \n",
    "                  \"ODE_order\" : 1,  \n",
    "\n",
    "                  \"force\" : no_force, \n",
    "                  \"reparam_f\" : reparam,\n",
    "                  \"ode_coefs\" : [1,1]}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "detailed-corpus",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/arm/lib/python3.8/site-packages/rctorchprivate/rc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, X, burn_in, input_weight, verbose, learning_rate, return_states, criterion, optimizer, out_weights, ODE_order, SOLVE, reparam_f, init_conditions, force, ode_coefs, train_score, ODE_criterion, preloaded_states_dict, q, eq_system, nl, backprop_f, epochs, hamiltonian, n_inputs, n_outputs, random_sampling, sample_timepoints)\u001b[0m\n\u001b[1;32m   1668\u001b[0m                 \u001b[0;31m#drop the first state and burned states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mburn_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/arm/lib/python3.8/site-packages/rctorchprivate/rc.py\u001b[0m in \u001b[0;36m_train_states_unsupervised\u001b[0;34m(self, X, y, states, calc_grads, outputs)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0;31m#assert False,f'y {y.shape} input_t {input_t.shape}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                 state_t, output_t = self.train_state(t, X = input_t,\n\u001b[0m\u001b[1;32m   1202\u001b[0m                                                      \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                                                      \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/arm/lib/python3.8/site-packages/rctorchprivate/rc.py\u001b[0m in \u001b[0;36m_train_state_vanilla_rs\u001b[0;34m(self, t, X, state, y, output, retain_grad)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaking_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaking_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;31m# if output:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m#     return next_state, self.LinOut(cat([X, next_state], axis = 0).view(self.n_outputs,-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = pop_RC.fit(init_conditions = [y0s,1],\n",
    "                         train_score = True, \n",
    "                         n_outputs = 1,\n",
    "                         ODE_criterion = custom_loss,\n",
    "                         **train_args)\n",
    "yfit1 = results['ys'][0]\n",
    "pop_RC.lastoutput\n",
    "\n",
    "last_outputs = pop_RC.lastoutput\n",
    "pop_RC.lastoutput = last_outputs[0]\n",
    "test_score, pred, _ = pop_RC.test(X = xtest, y = None)\n",
    "train_score = results[\"scores\"][0]\n",
    "print(f'train score {train_score}, test score {test_score[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-calculator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wanted-discount",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pop_RC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j8/qxt2xjjs43jc313rqwthwn780000gq/T/ipykernel_6510/980137965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_RC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pop_RC' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (9,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(pop_RC, results, population_model, ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                          results, \n",
    "                          force = no_force, \n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pop_RC = EchoStateNetwork(**simple_pop_hps,\n",
    "                          random_state = 209, \n",
    "                          dtype = torch.float32,\n",
    "                          feedback = False)\n",
    "\n",
    "out_weights = {'weights' : torch.zeros_like(results['weights'][0].T),\n",
    "               'bias' : torch.zeros_like(results[\"biases\"][0])}\n",
    "train_args = {\"X\" : xtrain.view(-1,1),  \n",
    "              'y' : yfit1,\n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : no_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1,1],\n",
    "              \"out_weights\" : None#out_weights\n",
    "              }\n",
    "\n",
    "results = pop_RC.fit(init_conditions = [y0s,1],\n",
    "                     train_score = True, \n",
    "                     n_outputs = 1,\n",
    "                     ODE_criterion = custom_loss,\n",
    "                     **train_args)\n",
    "\n",
    "yfit1 = results['ys'][0]\n",
    "last_outputs = pop_RC.lastoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_RC.init_conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_RC.lastoutput = last_outputs[0]\n",
    "test_score, pred, _ = pop_RC.test(X = xtest, y = None)\n",
    "train_score = results[\"scores\"][0]\n",
    "print(f'train score {train_score}, test score {test_score[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (9,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(pop_RC, results, population_model, ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                          results, \n",
    "                          force = no_force, \n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (10, 5))\n",
    "plt.sca(ax[0])\n",
    "plt.plot(results[\"ydots\"][0].detach(), label = \"ydots\")\n",
    "plt.plot(results[\"ys\"][0].detach(), label = \"y\")\n",
    "plt.legend()\n",
    "plt.sca(ax[1])\n",
    "plt.plot(results[\"ys\"][0].detach() + results[\"ydots\"][0].detach())\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.vstack((yfit1, pred[3].detach())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (9,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(pop_RC, results, population_model, ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                          results, \n",
    "                          force = no_force, \n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-device",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit once with feedback, no burn in. Then fit again feeding that prediction to the NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-painting",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (9,7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "plot_predictions(pop_RC, results, population_model, ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                          results, \n",
    "                          force = no_force, \n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-pierre",
   "metadata": {},
   "source": [
    "# Driven population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-litigation",
   "metadata": {},
   "source": [
    "#### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-latin",
   "metadata": {},
   "source": [
    "#### Train the RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.0031622776601683794)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "driven_pop_hps = {'dt': 0.0031622776601683794,\n",
    "                  'n_nodes': 500,\n",
    "                  'connectivity': 0.7875262340500385,\n",
    "                  'spectral_radius': 9.97140121459961,\n",
    "                  'regularization': 8.656278081920211,\n",
    "                  'leaking_rate': 0.007868987508118153,\n",
    "                  'bias': -0.2435922622680664,\n",
    "                  'input_scaling' : 0.00,\n",
    "                  'feedback_connectivity' : 0.05}\n",
    "\n",
    "#another example: (command + backslash after highlighting will uncomment all the lines at once)\n",
    "# driven_pop_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 400,\n",
    "#  'connectivity': 0.012634199142753764,\n",
    "#  'spectral_radius': 5.489274978637695,\n",
    "#  'regularization': 9.489825036097473,\n",
    "#  'leaking_rate': 0.0023584181908518076,\n",
    "#  'bias': 0.45648694038391113}\n",
    "\n",
    "driven_RC = EchoStateNetwork(**driven_pop_hps, feedback = True,\n",
    "                             random_state = 209,\n",
    "                             dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1,1]}\n",
    "\n",
    "driven_results = driven_RC.fit(init_conditions = [y0s,1],\n",
    "                 **train_args, \n",
    "                 SOLVE = True,\n",
    "                 train_score = True, \n",
    "                 ODE_criterion = custom_loss, \n",
    "                             n_outputs = 1)\n",
    "test_score, pred, _ = driven_RC.test(X = xtest, y = None)\n",
    "train_score = results[\"scores\"][0]\n",
    "print(f'train score {train_score}, test score {test_score[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-triumph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "restricted-weight",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop_model(y, t, t_pow = 0, force_k = 1):\n",
    "    k = 1\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-precipitation",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-saying",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "\n",
    "plot_predictions(RC = driven_RC, \n",
    "                 results = driven_results, \n",
    "                 integrator_model = driven_pop_model, \n",
    "                 ax = ax)\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_rmsr(RC = driven_RC, \n",
    "          results = driven_results, \n",
    "          force = driven_force, \n",
    "          ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "driven_RC.ODE_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-excess",
   "metadata": {},
   "source": [
    "# Driven population with nonlinear time dependence (t^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-girlfriend",
   "metadata": {},
   "source": [
    "#### declare the initial conditions (each initial condition corresponds to a different curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-2, 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-romance",
   "metadata": {},
   "source": [
    "#### Train the RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Bayesian Optimization was run on a power of 2. Feel free to play around with this value. \n",
    "pow_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "t2_hps =  {'n_nodes': 500,\n",
    "           'connectivity': 0.09905712745750006,\n",
    "           'spectral_radius': 1.8904799222946167,\n",
    "           'regularization': 714.156090350679,\n",
    "           'leaking_rate': 0.031645022332668304,\n",
    "           'bias': -0.24167031049728394,\n",
    "           'dt' : 0.005}\n",
    "\n",
    "\n",
    "\n",
    "t2_RC = EchoStateNetwork(**t2_hps, feedback = False,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [f\"t^{pow_}\", 1]}\n",
    "\n",
    "\n",
    "t2_results = t2_RC.fit(init_conditions = [y0s,1],\n",
    "                       SOLVE = True,\n",
    "                       train_score = True, \n",
    "                       ODE_criterion = custom_loss,\n",
    "                       n_outputs = 1,\n",
    "                       **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_RC.LinOut.weight.shape\n",
    "t2_RC.LinRes.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = Linear(501, 1)\n",
    "hi.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-olive",
   "metadata": {},
   "source": [
    "#### Declare integrator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop_model_t2(y, t, t_pow = pow_, force_k = 1):\n",
    "    k = 1\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-arthritis",
   "metadata": {},
   "source": [
    "#### Plot the integrator solutions vs the RC and the RMSR (directly calculated from the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = t2_RC, \n",
    "                       results = t2_results, \n",
    "                       integrator_model = driven_pop_model_t2, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(t2_RC, \n",
    "                      results = t2_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_RC.LinOut.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
