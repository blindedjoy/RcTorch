{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incident-organization",
   "metadata": {
    "id": "incident-organization"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from rctorchprivate import *\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.integrate import odeint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lfQP_u2KSMP7",
   "metadata": {
    "id": "lfQP_u2KSMP7"
   },
   "outputs": [],
   "source": [
    "# ! pip install rctorch==0.7162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-cookbook",
   "metadata": {
    "id": "spare-cookbook"
   },
   "outputs": [],
   "source": [
    "#this method will ensure that the notebook can use multiprocessing on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cd8c0c",
   "metadata": {
    "id": "34cd8c0c"
   },
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',#'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "\n",
    "def loss_plot(losses):\n",
    "    for loss_hist in losses:\n",
    "        plt.loglog(loss_hist, linewidth = lineW)\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "underlying-decimal",
   "metadata": {
    "id": "underlying-decimal"
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def pltTr(x,y,clr='cyan', mark='o'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             marker=mark, color=clr, markersize=8, label='truth', alpha = 0.9)\n",
    "\n",
    "def pltPred(x,y,clr='red', linS='-'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             color=clr, marker='.', linewidth=2, label='RC')\n",
    "from decimal import Decimal\n",
    "\n",
    "def convert2pd(tensor1, tensor2):\n",
    "    pd_ = pd.DataFrame(np.hstack((tensor1.detach().cpu().numpy(), tensor2.detach().cpu().numpy())))\n",
    "    pd_.columns = [\"t\", \"y\"]\n",
    "    return pd_\n",
    "'%.2E' % Decimal('40800000000.00000000000000')\n",
    "\n",
    "def param(t,N,y0):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    #f = t\n",
    "    #f_dot=1\n",
    "    return y0 + f*N\n",
    "\n",
    "#define a reparameterization function\n",
    "def reparam(t, y0 = None, N = None, dN_dt = None, t_only = False):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    \n",
    "    if t_only:\n",
    "        return f, f_dot\n",
    "\n",
    "    y = y0 + N*f \n",
    "    if dN_dt:\n",
    "        ydot = dN_dt * f + f_dot * N\n",
    "    else:\n",
    "        ydot = None\n",
    "    return y, ydot\n",
    "\n",
    "def reparam(t, order = 1):\n",
    "    exp_t = torch.exp(-t)\n",
    "    \n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    \n",
    "    #0th derivative\n",
    "    derivatives_of_g.append(g)\n",
    "    \n",
    "    g_dot = 1 - g\n",
    "    \n",
    "    #first derivative\n",
    "    #derivatives_of_g.append(g_dot)\n",
    "    \n",
    "#     for i in range(order):\n",
    "#         if i %2 == 0:\n",
    "#             #print(\"even\")\n",
    "#             derivatives_of_g.append(g_dot)\n",
    "#         else:\n",
    "#             #print(\"odd\")\n",
    "#             derivatives_of_g.append(-g_dot)\n",
    "#     return derivatives_of_g\n",
    "    return g, g_dot\n",
    "\n",
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shaped-soccer",
   "metadata": {
    "id": "shaped-soccer"
   },
   "outputs": [],
   "source": [
    "q = 0.5\n",
    "\n",
    "        \n",
    "def process(tensor_):\n",
    "    \"\"\" takes a tensor and prepares it for plotting.\n",
    "    \"\"\"\n",
    "    return tensor_.cpu().detach()\n",
    "\n",
    "def custom_loss(X , y, ydot, out_weights, force_t = force, \n",
    "                reg = True, ode_coefs = None, q = q, \n",
    "                init_conds = None, enet_strength = None, enet_alpha = None,\n",
    "                mean = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the bernoulli equation loss)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "    q: float\n",
    "        a bernoulli specific hyper-parameter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    #with paramization\n",
    "    L =  ydot + ode_coefs[0]* y - force_t + q*y**2\n",
    "    \n",
    "#     if reg:\n",
    "#         weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "#         weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "#         L_reg = 0.1*(weight_size_sq + weight_size_L1)/2\n",
    "#         L = L + L_reg \n",
    "    \n",
    "    L = torch.square(L)\n",
    "    if mean:\n",
    "         L = torch.mean(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33FVyxOMtcjs",
   "metadata": {
    "id": "33FVyxOMtcjs"
   },
   "outputs": [],
   "source": [
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = process(RC.X)\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = process(y)\n",
    "        ydot = process(ydot)\n",
    "        \n",
    "        ode_coefs = covert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, alpha = 0.7, linewidth = lineW -1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "#     ax.plot(X, rmsr, \n",
    "#                color = \"blue\", \n",
    "#                alpha = 0.9, \n",
    "#                label = r'{RMSR}')\n",
    "\n",
    "    #ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(r'RMSR')\n",
    "\n",
    "def covert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbca25d9",
   "metadata": {
    "id": "dbca25d9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def optimize_last_layer(esn, \n",
    "                        SAVE_AFTER_EPOCHS = 0,\n",
    "                        epochs = 30000,\n",
    "                        custom_loss = custom_loss,\n",
    "                        #loss_threshold = 10 ** -8,\n",
    "                        EPOCHS_TO_TERMINATION = None,\n",
    "                        force = force,\n",
    "                        learning_rate = 0.01,\n",
    "                        plott = False,\n",
    "                        spikethreshold = 0.25):\n",
    "    #define new_x\n",
    "    new_X = esn.extended_states.detach()\n",
    "\n",
    "    #force detach states_dot\n",
    "    esn.states_dot = esn.states_dot.detach().requires_grad_(False)\n",
    "\n",
    "    #define criterion\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    try:\n",
    "        assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "    except:\n",
    "        esn.LinOut.weight.requires_grad_(True)\n",
    "        esn.LinOut.bias.requires_grad_(True)\n",
    "    #define previous_loss (could be used to do a convergence stop)\n",
    "    previous_loss = 0\n",
    "\n",
    "    #define best score so that we can save the best weights\n",
    "    best_score = 0\n",
    "\n",
    "    #define the optimizer\n",
    "    optimizer = optim.Adam(esn.parameters(), lr = learning_rate)\n",
    "\n",
    "    #define the loss history\n",
    "    loss_history = []\n",
    "    \n",
    "    if plott:\n",
    "        #use pl for live plotting\n",
    "        fig, ax = pl.subplots(1,3, figsize = (16,4))\n",
    "    \n",
    "    t = esn.X#.view(*N.shape).detach()\n",
    "    g, g_dot = esn.G\n",
    "    y0  = esn.init_conds[0]\n",
    "    \n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    lrs = []\n",
    "    \n",
    "    floss_last = 0\n",
    "    force_t = force(t)\n",
    "\n",
    "    #begin optimization loop\n",
    "    for e in range(epochs):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        N = esn.forward( esn.extended_states )\n",
    "        N_dot = esn.calc_Ndot(esn.states_dot)\n",
    "\n",
    "        y = y0  + g *N \n",
    "        \n",
    "        ydot = g_dot * N + g * N_dot\n",
    "\n",
    "        #assert N.shape == N_dot.shape, f'{N.shape} != {N_dot.shape}'\n",
    "        #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        \n",
    "        #assert False, f'{esn.LinOut.weight}'\n",
    "\n",
    "        total_ws = esn.LinOut.weight.shape[0] + 1\n",
    "        weight_size_sq = torch.mean(torch.square(esn.LinOut.weight))\n",
    "        \n",
    "        loss = custom_loss(esn.X, y, ydot, esn.LinOut.weight, reg = False, ode_coefs = esn.ode_coefs, force_t = force_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        floss = float(loss)\n",
    "        loss_history.append(floss)\n",
    "        \n",
    "        if not e and not best_score:\n",
    "            best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "\n",
    "        #if e > SAVE_AFTER_EPOCHS:\n",
    "        if not best_score:\n",
    "            best_score = float(loss)\n",
    "            if floss <= min(loss_history):\n",
    "                best_pred = y.clone()\n",
    "                best_ydot = ydot.clone()\n",
    "                best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "        else:\n",
    "            if floss < best_score:\n",
    "                best_pred = y.clone()\n",
    "                best_ydot = ydot.clone()\n",
    "                best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "                best_score = float(loss)\n",
    "                \n",
    "        if EPOCHS_TO_TERMINATION:\n",
    "            if e >= EPOCHS_TO_TERMINATION:\n",
    "                backprop_args = {\"loss_history\" : loss_history, \n",
    "                         \"lr\" : learning_rate,\n",
    "                         \"epochs\" : epochs\n",
    "                        }\n",
    "                return {\"weights\": best_weight, \n",
    "                        \"best_score\" : torch.tensor(best_score),\n",
    "                        \"bias\" : best_bias, \n",
    "                        \"loss\" : backprop_args,\n",
    "                        \"ydot\" : best_ydot, \n",
    "                        \"y\" : best_pred}\n",
    "            \n",
    "        if e > 1:\n",
    "            if float(np.log(floss_last) - np.log(floss)) > spikethreshold:\n",
    "                lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "                scheduler.step()\n",
    "                #for param_group in optimizer.param_groups:\n",
    "                #    print('lr', param_group['lr'])\n",
    "        floss_last = floss\n",
    "        if plott:\n",
    "\n",
    "            if e % 1500 == 0:\n",
    "                ax[0].clear()\n",
    "                logloss_str = 'Log(L) ' + '%.2E' % Decimal((loss).item())\n",
    "                delta_loss  = ' delta Log(L) ' + '%.2E' % Decimal((loss-previous_loss).item())\n",
    "\n",
    "                print(logloss_str + \", \" + delta_loss)\n",
    "                ax[0].plot(N.detach().cpu(), label = \"exact\")\n",
    "                ax[0].set_title(f\"Epoch {e}\" + \", \" + logloss_str)\n",
    "                ax[0].set_xlabel(\"epochs\")\n",
    "\n",
    "                ax[1].set_title(delta_loss)\n",
    "                ax[1].plot(N_dot.detach().cpu())\n",
    "                #ax[0].plot(y_dot.detach(), label = \"dy_dx\")\n",
    "                ax[2].clear()\n",
    "                weight_size = str(weight_size_sq.detach().item())\n",
    "                ax[2].set_title(\"loss history \\n and \"+ weight_size)\n",
    "\n",
    "                ax[2].loglog(loss_history)\n",
    "\n",
    "                [ax[i].legend() for i in range(3)]\n",
    "                previous_loss = loss.item()\n",
    "\n",
    "                #clear the plot outputt and then re-plot\n",
    "                display.clear_output(wait=True) \n",
    "                display.display(pl.gcf())\n",
    "    backprop_args = {\"loss_history\" : loss_history, \n",
    "                         \"lr\" : learning_rate,\n",
    "                         \"epochs\" : epochs\n",
    "                        }\n",
    "    return {\"weights\": best_weight, \n",
    "            \"bias\" : best_bias, \n",
    "            \"loss\" : backprop_args,\n",
    "            \"ydot\" : best_ydot,\n",
    "            \"best_score\" : torch.tensor(best_score), \n",
    "            \"y\" : best_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rtgzhPpTtm2g",
   "metadata": {
    "id": "rtgzhPpTtm2g"
   },
   "outputs": [],
   "source": [
    "# Scipy Solver   \n",
    "def plot_predictions(RC, results, integrator_model, y0s = None,  ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = process(RC.X)\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = process(y)\n",
    "        if not i:\n",
    "            labels = [\"RC solver\", \"integrator\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        ax.plot(X, y, label = labels[0], linewidth = lineW + 2, alpha = 0.9)\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"black\", alpha = 0.95, label = labels[1],  linewidth = lineW - 1)\n",
    "    \n",
    "    plt.ylabel(r'$y(t)$');\n",
    "    ax.legend();\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dress-punch",
   "metadata": {
    "id": "dress-punch"
   },
   "outputs": [],
   "source": [
    "#optimized_hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enclosed-reporter",
   "metadata": {
    "id": "enclosed-reporter"
   },
   "outputs": [],
   "source": [
    "x0,xf, nsteps = 0, 5, 1000 #int(2000 * ratio_up)\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sweet-mambo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sweet-mambo",
    "outputId": "49aa4d0d-054d-4382-f9cd-0424153bf8e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURN_IN = 500\n",
    "\n",
    "y0 = 1 ; lam = 1\n",
    "\n",
    "#the length of xtrain won't matter. Only dt , x0, and xf matter.\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False).view(-1,1)\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abstract-poultry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abstract-poultry",
    "outputId": "bb866a8a-a803-4099-d318-d89c5142a2e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -0.25,  0.5 ,  1.25])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dRay=0.75\n",
    "np.arange(-1., 1 + dRay, dRay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-registrar",
   "metadata": {
    "id": "horizontal-registrar"
   },
   "source": [
    "dt -2.1\n",
    "n_nodes 500\n",
    "connectivity -3.8727548122406006\n",
    "spectral_radius 7.1109442710876465\n",
    "regularization -2.392099618911743\n",
    "leaking_rate 0.022500092163681984\n",
    "bias 0.7761751413345337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "systematic-wednesday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "systematic-wednesday",
    "outputId": "e2def13b-1bc5-4b48-b8f9-df37d40f9a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt -2.0\n",
      "n_nodes 500\n",
      "connectivity -3.0569143295288086\n",
      "spectral_radius 3.8187756538391113\n",
      "regularization 0.4190235137939453\n",
      "leaking_rate 0.05788800120353699\n",
      "bias -0.4182356595993042\n"
     ]
    }
   ],
   "source": [
    "log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt']\n",
    "\n",
    "hps = {'dt': 0.01,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.0008771738385033052,\n",
    " 'spectral_radius': 3.8187756538391113,\n",
    " 'regularization': 2.6243606290132924,\n",
    " 'leaking_rate': 0.05788800120353699,\n",
    " 'bias': -0.4182356595993042}\n",
    "\n",
    "for key, val in hps.items():\n",
    "    if key in log_vars:\n",
    "        print(key, np.log10(val))\n",
    "    else:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "oi1FzATKS73L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oi1FzATKS73L",
    "outputId": "0cb0ee6d-ce2d-47cb-e903-1c6130e6d3b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0, -0.25, 0.5, 1.25]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dRay=0.75\n",
    "y0s = np.arange(-1., 1 + dRay, dRay)\n",
    "y0s = list(y0s)\n",
    "y0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4966f9fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "4966f9fd",
    "outputId": "ad7a2c02-15e5-4417-c410-fdd29d29ff2b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK: True , device: None\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-29 19:41:43,593\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/rctorchprivate/esn_cv.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_trust_regions, max_evals, y, x, store_path, epochs, learning_rate, scoring_method, criterion, reparam_f, ODE_criterion, init_conditions, scale, force, backprop_f, backprop, ode_coefs, solve, rounds, tr_score_prop, q, eq_system, nonlinear_ode, reg_type)\u001b[0m\n\u001b[1;32m   1495\u001b[0m                 \u001b[0mcustom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdual_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mODE_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbackprop_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "bounds_dict = {\"connectivity\" : (-4, -0.1), \n",
    "               \"spectral_radius\" : (1.5, 8.5),\n",
    "               \"n_nodes\" : 500,\n",
    "               \"regularization\" : (-2, 2),\n",
    "               \"leaking_rate\" : (0, 0.1),\n",
    "               #\"input_scaling\" : (0, 1),\n",
    "               #\"feedback_scaling\" : (0, 1),\n",
    "               \"dt\" : -2,\n",
    "               \"bias\": (-1,1)\n",
    "               }\n",
    "\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            feedback = True,\n",
    "                            interactive = True, \n",
    "                            n_jobs = 4, \n",
    "                            cv_samples = 2, \n",
    "                            initial_samples = 50,  #200\n",
    "                            subsequence_prop = 0.8,\n",
    "                            random_seed = 209, \n",
    "                            success_tolerance = 10,\n",
    "                            windowsOS =False, \n",
    "                            validate_fraction = 0.5, \n",
    "                            ODE_order = 1, \n",
    "                            length_min = 2 **(-7),\n",
    "                            esn_burn_in = BURN_IN, \n",
    "                            log_score = True,\n",
    "                            #n_inputs = 1,\n",
    "                            n_outputs = 2\n",
    "                            )\n",
    "#optimize:\n",
    "opt = True\n",
    "if opt:\n",
    "    \n",
    "    opt_hps = esn_cv.optimize(y = None, x = xtrain,#.cuda(),\n",
    "                        reparam_f = reparam, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        init_conditions = [y0s ], \n",
    "                        force = force,\n",
    "                        rounds = 5,\n",
    "                        ode_coefs = [1, 1],\n",
    "                        backprop_f = optimize_last_layer, \n",
    "                        solve = True,\n",
    "                         q = q,\n",
    "                         #n_outputs = 1,\n",
    "                         eq_system = False,\n",
    "                         nonlinear_ode = True,\n",
    "                         max_evals = 300,\n",
    "                         epochs = 5000) #\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "kaHDv2JM9WkN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaHDv2JM9WkN",
    "outputId": "2ad8d2d8-624b-471c-ce98-fa77b4bc163d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EchoStateNetworkCV' object has no attribute 'X_turbo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c7ff971e540f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_hyper_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mrecover_hps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-c7ff971e540f>\u001b[0m in \u001b[0;36mrecover_hps\u001b[0;34m(esn_cv, idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecover_hps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_turbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_turbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mesn_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_turbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesn_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_turbo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#best_vals = X_turbo[idx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EchoStateNetworkCV' object has no attribute 'X_turbo'"
     ]
    }
   ],
   "source": [
    "def recover_hps(esn_cv, idx):\n",
    "    \n",
    "    X_turbo, Y_turbo = esn_cv.X_turbo, esn_cv.Y_turbo\n",
    "    #best_vals = X_turbo[idx]\n",
    "    \n",
    "    mask = esn_cv.Y_turbo.squeeze() > 0\n",
    "    Y_Turbo_best = esn_cv.Y_turbo[ mask]\n",
    "    X_Turbo_best = esn_cv.X_turbo[ mask, :]\n",
    "    \n",
    "    best_vals = X_Turbo_best[idx]\n",
    "    \n",
    "    #best_vals = X_turbo[torch.argmin(Y_turbo)]\n",
    "    \n",
    "    denormed_ = esn_cv.denormalize_bounds(best_vals)\n",
    "        \n",
    "    try:\n",
    "        denormed_ = denormalize_bounds(best_vals)\n",
    "    except:\n",
    "        print(\"FAIL\")\n",
    "\n",
    "    best_vals = X_turbo[torch.argmax(Y_turbo)]\n",
    "\n",
    "    #####Bad temporary code to change it back into a dictionary\n",
    "    denormed_free_parameters = list(zip(esn_cv.free_parameters, denormed_))\n",
    "    denormed_free_parameters = dict([ (item[0], item[1].item()) for item in denormed_free_parameters])\n",
    "\n",
    "    best_hyper_parameters = denormed_free_parameters\n",
    "    for fixed_parameter in esn_cv.fixed_parameters:\n",
    "        best_hyper_parameters = {fixed_parameter : esn_cv.bounds[fixed_parameter], **best_hyper_parameters }\n",
    "\n",
    "    #log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt']\n",
    "    for var in esn_cv.log_vars:\n",
    "        if var in best_hyper_parameters:\n",
    "            best_hyper_parameters[var] = 10. ** best_hyper_parameters[var] \n",
    "    return best_hyper_parameters\n",
    "\n",
    "recover_hps(esn_cv, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NUSnDXkSsNyu",
   "metadata": {
    "id": "NUSnDXkSsNyu"
   },
   "outputs": [],
   "source": [
    "#an amazing run, beating the published solutions:\n",
    "\n",
    "#result published in the paper\n",
    "# hybrid_hps_q05 = {'dt': 0.007943282347242814,\n",
    "#  'n_nodes': 500,\n",
    "#  'connectivity': 0.0003179179463749722,\n",
    "#  'spectral_radius': 7.975825786590576,\n",
    "#  'regularization': 0.3332787303378571,\n",
    "#  'leaking_rate': 0.07119506597518921,\n",
    "#  'bias': -0.9424528479576111}\n",
    "\n",
    "#some very strong results found after submission\n",
    "opt_hps1 = {'bias': 0.9490906000137329,\n",
    " 'connectivity': 0.00024854583199299384,\n",
    " 'dt': 0.01,\n",
    " 'leaking_rate': 0.009424317628145218,\n",
    " 'n_nodes': 500,\n",
    " 'regularization': 0.02499297583727001,\n",
    " 'spectral_radius': 3.27508282661438}\n",
    " #the strongest result:\n",
    "opt_hps2 = {'bias': 0.5885217189788818,\n",
    " 'connectivity': 0.6173509376804103,\n",
    " 'dt': 0.01,\n",
    " 'leaking_rate': 0.006605937611311674,\n",
    " 'n_nodes': 500,\n",
    " 'regularization': 2.8410215084453037,\n",
    " 'spectral_radius': 5.8741302490234375}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4uDAHDFxtRuG",
   "metadata": {
    "id": "4uDAHDFxtRuG"
   },
   "outputs": [],
   "source": [
    "train_args = {\"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,\n",
    "              \"force\" : force,\n",
    "              \"reparam_f\" : reparam,\n",
    "              \"init_conditions\" : [y0s],\n",
    "              \"ode_coefs\" : [1, 1],\n",
    "              \"X\" : xtrain.view(-1,1),\n",
    "              \"q\" : q,\n",
    "              \"nl\" : True,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VruoWwYNtAiM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VruoWwYNtAiM",
    "outputId": "7a9b6b80-5958-4782-d47f-4eb162f05580"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "EPOCHS = 50000\n",
    "RC = EchoStateNetwork(**opt_hps,\n",
    "                      random_state = 209, \n",
    "                      dtype = torch.float32)\n",
    "\n",
    "# backprop_results = RC.fit( backprop_f = optimize_last_layer,\n",
    "#                            train_score = True, \n",
    "#                            ODE_criterion = custom_loss,\n",
    "#                            SOLVE = False,\n",
    "#                            **train_args,\n",
    "#                            epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6IGVsdz1sOXN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IGVsdz1sOXN",
    "outputId": "251d841e-82dd-4c85-f7ec-b449c4be1f86"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hybrid_results = RC.fit(backprop_f = optimize_last_layer,\n",
    "                        train_score = True, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        SOLVE = True,\n",
    "                        **train_args,\n",
    "                        epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ry52A_SMuZ7o",
   "metadata": {
    "id": "ry52A_SMuZ7o"
   },
   "outputs": [],
   "source": [
    "def Bernoulli_model(y,t, q = q):\n",
    "    k = 1\n",
    "    dydt = -k * y -q*y**2\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wYS-dSZKtyyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "wYS-dSZKtyyu",
    "outputId": "dfc4fc44-739d-452b-d53b-3026a438cb64"
   },
   "outputs": [],
   "source": [
    "#show results:\n",
    "fig = plt.figure(figsize = (14,8)); gs1 = gridspec.GridSpec(3, 3);\n",
    "gs1 = gridspec.GridSpec(3, 6)\n",
    "horiz_boundary = -3\n",
    "vert_boundary = -1\n",
    "\n",
    "g1, g2, g3 = gs1[:vert_boundary, :horiz_boundary], gs1[vert_boundary, :horiz_boundary], gs1[:, horiz_boundary:]\n",
    "ax=plt.subplot(g1)\n",
    "\n",
    "plot_predictions(RC, hybrid_results, Bernoulli_model, y0s, ax = ax)\n",
    "\n",
    "ax=plt.subplot(g2)\n",
    "plot_data = plot_rmsr(RC, \n",
    "                      hybrid_results, \n",
    "                      force = force, \n",
    "                      ax = ax)\n",
    "\n",
    "plt.subplot(g3)\n",
    "loss_plot(hybrid_results[\"losses\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-bRt-NtAJIpI",
   "metadata": {
    "id": "-bRt-NtAJIpI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bernoulli_BO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
