{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coastal-manual",
   "metadata": {
    "id": "coastal-manual"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from RcTorch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e-rXL3fLBDU",
   "metadata": {
    "id": "4e-rXL3fLBDU"
   },
   "outputs": [],
   "source": [
    "#pip install rctorch==0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "needed-panel",
   "metadata": {
    "id": "needed-panel"
   },
   "outputs": [],
   "source": [
    "#this method will ensure that the notebook can use multiprocessing on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limiting-albert",
   "metadata": {
    "id": "limiting-albert"
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def pltTr(x,y,clr='cyan', mark='o'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             marker=mark, color=clr, markersize=8, label='truth', alpha = 0.9)\n",
    "\n",
    "def pltPred(x,y,clr='red', linS='-'):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(),\n",
    "             color=clr, marker='.', linewidth=2, label='RC')\n",
    "from decimal import Decimal\n",
    "\n",
    "def convert2pd(tensor1, tensor2):\n",
    "    pd_ = pd.DataFrame(np.hstack((tensor1.detach().cpu().numpy(), tensor2.detach().cpu().numpy())))\n",
    "    pd_.columns = [\"t\", \"y\"]\n",
    "    return pd_\n",
    "'%.2E' % Decimal('40800000000.00000000000000')\n",
    "\n",
    "def param(t,N,y0):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    #f = t\n",
    "    #f_dot=1\n",
    "    return y0 + f*N\n",
    "\n",
    "#define a reparameterization function\n",
    "def reparam(t, y0 = None, N = None, dN_dt = None, t_only = False):\n",
    "    f = 1 - torch.exp(-t)\n",
    "    f_dot = 1 - f\n",
    "    \n",
    "    if t_only:\n",
    "        return f, f_dot\n",
    "\n",
    "    y = y0 + N*f \n",
    "    if dN_dt:\n",
    "        ydot = dN_dt * f + f_dot * N\n",
    "    else:\n",
    "        ydot = None\n",
    "    return y, ydot\n",
    "\n",
    "def reparam(t, order = 1):\n",
    "    exp_t = torch.exp(-t)\n",
    "    \n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    \n",
    "    #0th derivative\n",
    "    derivatives_of_g.append(g)\n",
    "    \n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-prescription",
   "metadata": {
    "id": "enhanced-prescription"
   },
   "outputs": [],
   "source": [
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)\n",
    "lam =1\n",
    "def hamiltonian(x, p, lam = lam):\n",
    "    return (1/2)*(x**2 + p**2) + lam*x**4/4\n",
    "\n",
    "def custom_loss(X , y, ydot, out_weights, f = force, \n",
    "                reg = True, ode_coefs = None, mean = True,\n",
    "               enet_strength = None, enet_alpha = None, init_conds = None, lam = 1):\n",
    "    y, p = y[:,0].view(-1,1), y[:,1].view(-1,1)\n",
    "    ydot, pdot = ydot[:,0].view(-1,1), ydot[:,1].view(-1,1)\n",
    "    \n",
    "    #with paramization\n",
    "    L =  (ydot - p)**2 + (pdot + y + lam * y**3   - force(X))**2\n",
    "    \n",
    "    #if mean:\n",
    "    L = torch.mean(L)\n",
    "    \n",
    "    if reg:\n",
    "        #assert False\n",
    "        weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "        weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "        L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "        L = L + 0.1 * L_reg \n",
    "\n",
    "    y0, p0 = init_conds\n",
    "    ham = hamiltonian(y, p)\n",
    "    ham0 = hamiltonian(y0, p0)\n",
    "    L_H = (( ham - ham0).pow(2)).mean()\n",
    "    assert L_H >0\n",
    "\n",
    "    L = L +  0.1 * L_H\n",
    "    \n",
    "    #print(\"L1\", hi, \"L_elastic\", L_reg, \"L_H\", L_H)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "practical-preparation",
   "metadata": {
    "id": "practical-preparation"
   },
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "\n",
    "def plot_result(esn, xtrain, v0s = [1], y0s = [1.3], plot_gt = True, loglog = False,\n",
    "               ode_coefs = None, force_k = 0, fileName=None, backprop_f = None, ax = None,\n",
    "               solve = None , out_weights = None, epochs = None, reg = None, gamma_cyclic = None\n",
    "                      ):\n",
    "    \n",
    "    RC = esn\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (8, 6))       \n",
    "    t_pow = 0\n",
    "    for i, v0 in enumerate(v0s):\n",
    "        y0 = y0s[i]\n",
    "        \n",
    "        train_args = {\"burn_in\" : int(BURN_IN), \n",
    "                      \"ODE_order\" : 1,\n",
    "                      \"force\" : force,\n",
    "                      \"reparam_f\" : reparam,\n",
    "                      \"init_conditions\" : [float(y0), float(v0)],\n",
    "                      \"ode_coefs\" : ode_coefs,\n",
    "                      \"y\" : None,\n",
    "                      \"X\" : xtrain.view(-1,1),\n",
    "                      \"eq_system\" : True,\n",
    "                      #\"out_weights\" : out_weights\n",
    "                      }\n",
    "        \n",
    "        if not i:\n",
    "            y, ydot = esn.fit(**train_args, SOLVE = solve, out_weights = out_weights)\n",
    "            \n",
    "            ode_coefs_copy = ode_coefs.copy()\n",
    "            states_dict = {\"s\"  : RC.states.clone(),\n",
    "                           \"s1\" : RC.states_dot.clone(), \n",
    "                           \"G\"  : RC.G,\n",
    "                           \"ex\" : RC.extended_states.clone(),\n",
    "                           \"sb1\": RC.sb1,\n",
    "                           \"sb\" : RC.sb\n",
    "                           }\n",
    "            if esn.ODE_order == 2:\n",
    "                            states_dict[\"s2\"] = RC.states_dot2.clone()\n",
    "                            states_dict[\"sb2\"] = RC.sb2.clone()\n",
    "            #t2 = time.perf_counter()\n",
    "        else:\n",
    "            y, ydot = RC.fit(preloaded_states_dict = states_dict, SOLVE = solve,\n",
    "                          **train_args, out_weights = out_weights)\n",
    "        if not out_weights:\n",
    "            if backprop_f:\n",
    "                weight_dict = backprop_f(esn, epochs = epochs,reg = reg)\n",
    "                #y, ydot = esn.fit(**train_args, out_weights = weight_dict, SOLVE = False)\n",
    "                y,ydot = weight_dict[\"y\"], weight_dict[\"ydot\"]\n",
    "                esn = weight_dict[\"RC\"]\n",
    "        \n",
    "        ode_coefs_copy = ode_coefs.copy()\n",
    "        if ode_coefs[0] == \"t**2\":\n",
    "            sp = esn.X**2\n",
    "            t_pow = 2\n",
    "            ode_coefs_copy[0] = sp\n",
    "            \n",
    "        def f(u, t ,lam=0,A=0,W=1):\n",
    "            x,  px = u      # unpack current values of u\n",
    "            derivs = [px, -x - lam*x**3 +A*np.sin(W*t)]     # you write the derivative here\n",
    "            return derivs\n",
    "        \n",
    "        # Scipy Solver   \n",
    "        def NLosc_solution(t, x0,  px0, lam=0, A=0,W=1):\n",
    "            u0 = [x0, px0]\n",
    "            # Call the ODE solver\n",
    "            solPend = odeint(f, u0, t.cpu(), args=(lam,A,W,))\n",
    "            xP = solPend[:,0];        pxP = solPend[:,1];   \n",
    "            return xP, pxP\n",
    "\n",
    "        y_truth, v_truth  = NLosc_solution(esn.X.squeeze().data,1.3,1,lam=1, A=0, W= 0) \n",
    "        \n",
    "        p = y[:,1].cpu()# + v0\n",
    "        yy = y[:,0].cpu()# + y0\n",
    "        X = esn.X.cpu()\n",
    "        \n",
    "        #y_truth = odeint(ODE_numSolver,y0,np.array(esn.X.cpu().view(-1,)))\n",
    "        if y0==1:\n",
    "            extraWidth = 2; color = 'k'\n",
    "        else: extraWidth=0; color = 'b'\n",
    "        \n",
    "        if not i:\n",
    "            ax.plot(X, yy, color, linewidth=lineW+extraWidth, label = \"x_hat\", color = \"blue\" )\n",
    "            ax.plot(X, p, color, linewidth=lineW+extraWidth, label = \"p_hat\", color = \"red\" )\n",
    "           \n",
    "            #ax.plot(X, torch.cos(X),'--', linewidth=lineW, alpha=0.85, label = \"p_gt\", color = \"red\")\n",
    "            #ax.plot(X, torch.sin(X),'--', linewidth=lineW, alpha=0.85, label = \"x_gt\", color = \"blue\")\n",
    "            \n",
    "            ax.plot(X, v_truth,'--', linewidth=lineW, alpha=0.85, label = \"p_gt_\", color = \"red\")\n",
    "            ax.plot(X, y_truth,'--', linewidth=lineW, alpha=0.85, label = \"x_gt_\", color = \"blue\")\n",
    "        else:\n",
    "            ax.plot(X, yy, color, linewidth=lineW+extraWidth, color = \"blue\")\n",
    "            ax.plot(X, p,'--r', linewidth=lineW, alpha=0.85, color = \"red\")\n",
    "            \n",
    "            ax.plot(X, v_truth,'--', linewidth=lineW, alpha=0.85, color = \"red\")\n",
    "            ax.plot(X, y_truth,'--', linewidth=lineW, alpha=0.85, color = \"blue\")\n",
    "        \n",
    "        ## Formating Figure\n",
    "        # Changing spine style\n",
    "        ax = plt.gca()\n",
    "        for ps in ['top','bottom','left','right']:\n",
    "            ax.spines[ps].set_linewidth(lineBoxW)\n",
    "\n",
    "        plt.xlabel(r'$t$')\n",
    "        plt.ylabel(r'$y(t)$')\n",
    "        plt.legend()\n",
    "        \n",
    "    return esn\n",
    "\n",
    "def optimize_last_layer(esn, \n",
    "                        SAVE_AFTER_EPOCHS = 1,\n",
    "                        epochs = 45000,\n",
    "                        custom_loss = custom_loss,\n",
    "                        EPOCHS_TO_TERMINATION = None,\n",
    "                        f = force,\n",
    "                        lr = 0.05, \n",
    "                        reg = None,\n",
    "                        plott = True,\n",
    "                        plot_every_n_epochs = 2000):#gamma 0.1, spikethreshold 0.07 works\n",
    "    with torch.enable_grad():\n",
    "        #define new_x\n",
    "        new_X = esn.extended_states.detach()\n",
    "        spikethreshold = esn.spikethreshold\n",
    "\n",
    "        #force detach states_dot\n",
    "        esn.states_dot = esn.states_dot.detach().requires_grad_(False)\n",
    "\n",
    "        #define criterion\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        #assert not new_X.requires_grad\n",
    "\n",
    "        #define previous_loss (could be used to do a convergence stop)\n",
    "        previous_loss = 0\n",
    "\n",
    "        #define best score so that we can save the best weights\n",
    "        best_score = 0\n",
    "\n",
    "        #define the optimizer\n",
    "        optimizer = optim.Adam(esn.parameters(), lr = lr)\n",
    "\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "        if esn.gamma_cyclic:\n",
    "            cyclic_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 10**-6, 0.01,\n",
    "                                            gamma = esn.gamma_cyclic,#0.9999,\n",
    "                                            mode = \"exp_range\", cycle_momentum = False)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=esn.gamma)\n",
    "        lrs = []\n",
    "\n",
    "        #define the loss history\n",
    "        loss_history = []\n",
    "\n",
    "        if plott:\n",
    "          #use pl for live plotting\n",
    "          fig, ax = pl.subplots(1,3, figsize = (16,4))\n",
    "\n",
    "        t = esn.X#.view(*N.shape).detach()\n",
    "        g, g_dot = esn.G\n",
    "        y0  = esn.init_conds[0]\n",
    "\n",
    "        flipped = False\n",
    "        flipped2 = False\n",
    "        pow_ = -4\n",
    "        floss_last = 0\n",
    "\n",
    "\n",
    "        try:\n",
    "            assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        except:\n",
    "            esn.LinOut.weight.requires_grad_(True)\n",
    "            esn.LinOut.bias.requires_grad_(True)\n",
    "\n",
    "        #bail\n",
    "\n",
    "        #begin optimization loop\n",
    "        for e in range(epochs):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            N = esn.forward( esn.extended_states )\n",
    "            N_dot = esn.calc_Ndot(esn.states_dot)\n",
    "\n",
    "            y = g *N \n",
    "\n",
    "            ydot = g_dot * N + g * N_dot\n",
    "\n",
    "            y[:,0] = y[:,0] + esn.init_conds[0]\n",
    "            y[:,1] = y[:,1] + esn.init_conds[1]\n",
    "\n",
    "            assert N.shape == N_dot.shape, f'{N.shape} != {N_dot.shape}'\n",
    "\n",
    "            #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "\n",
    "            #total_ws = esn.LinOut.weight.shape[0] + 1\n",
    "            #weight_size_sq = torch.mean(torch.square(esn.LinOut.weight))\n",
    "\n",
    "            loss = custom_loss(esn.X, y, ydot, esn.LinOut.weight, reg = reg, ode_coefs = esn.ode_coefs,\n",
    "                    init_conds = esn.init_conds, enet_alpha= esn.enet_alpha, enet_strength = esn.enet_strength)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if esn.gamma_cyclic and e > 100 and e <5000:\n",
    "                cyclic_scheduler.step()\n",
    "                lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "\n",
    "            floss = float(loss)\n",
    "            loss_history.append(floss)\n",
    "\n",
    "            if e == 10**3:\n",
    "                if floss > 10**(5):\n",
    "                    EPOCHS_TO_TERMINATION = e + 50\n",
    "\n",
    "            if e == 10**4:\n",
    "                if floss > 10**(2.5):\n",
    "                    EPOCHS_TO_TERMINATION = e + 50\n",
    "                    \n",
    "            if e > 0:\n",
    "                loss_delta = float(np.log(floss_last) - np.log(floss)) \n",
    "                if loss_delta > esn.spikethreshold:# or loss_delta < -3:\n",
    "                    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "                    scheduler.step()\n",
    "\n",
    "\n",
    "            if not e and not best_score:\n",
    "                best_bias, best_weight, best_fit = esn.LinOut.bias.detach(), esn.LinOut.weight.detach(), y.clone()\n",
    "\n",
    "            if e > SAVE_AFTER_EPOCHS:\n",
    "                if not best_score:\n",
    "                    best_score = min(loss_history)\n",
    "                if floss < best_score:  \n",
    "                    best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "                    best_score = float(loss)\n",
    "                    best_fit = y.clone()\n",
    "                    best_ydot = ydot.clone()\n",
    "            # else:\n",
    "            #     if floss < best_score:\n",
    "            #         best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "            #         best_score = float(loss)\n",
    "            #         best_fit = y.clone()\n",
    "            #         best_ydot = ydot.clone()\n",
    "\n",
    "            if e >= EPOCHS_TO_TERMINATION:\n",
    "                return {\"weights\": best_weight, \"bias\" : best_bias, \"y\" : best_fit, \n",
    "                      \"loss\" : {\"loss_history\" : loss_history},  \"best_score\" : torch.tensor(best_score),\n",
    "                      \"RC\" : esn}\n",
    "            floss_last = floss\n",
    "            if plott and e:\n",
    "\n",
    "                if e % plot_every_n_epochs == 0:\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        print('lr', param_group['lr'])\n",
    "                    ax[0].clear()\n",
    "                    logloss_str = 'Log(L) ' + '%.2E' % Decimal((loss).item())\n",
    "                    delta_loss  = ' delta Log(L) ' + '%.2E' % Decimal((loss-previous_loss).item())\n",
    "\n",
    "                    print(logloss_str + \", \" + delta_loss)\n",
    "                    ax[0].plot(y.detach().cpu(), label = \"exact\")\n",
    "                    ax[0].set_title(f\"Epoch {e}\" + \", \" + logloss_str)\n",
    "                    ax[0].set_xlabel(\"t\")\n",
    "\n",
    "                    ax[1].set_title(delta_loss)\n",
    "                    ax[1].plot(N_dot.detach().cpu())\n",
    "                    #ax[0].plot(y_dot.detach(), label = \"dy_dx\")\n",
    "                    ax[2].clear()\n",
    "                    #weight_size = str(weight_size_sq.detach().item())\n",
    "                    #ax[2].set_title(\"loss history \\n and \"+ weight_size)\n",
    "\n",
    "                    ax[2].loglog(loss_history)\n",
    "                    ax[2].set_xlabel(\"t\")\n",
    "\n",
    "                    [ax[i].legend() for i in range(3)]\n",
    "                    previous_loss = loss.item()\n",
    "\n",
    "                    #clear the plot outputt and then re-plot\n",
    "                    display.clear_output(wait=True) \n",
    "                    display.display(pl.gcf())\n",
    "\n",
    "\n",
    "        return {\"weights\": best_weight, \"bias\" : best_bias, \"y\" : best_fit, \"ydot\" : best_ydot, \n",
    "              \"loss\" : {\"loss_history\" : loss_history}, \"best_score\" : torch.tensor(best_score),\n",
    "              \"RC\" : esn}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expensive-contractor",
   "metadata": {
    "id": "expensive-contractor"
   },
   "outputs": [],
   "source": [
    "#y0s = array([-1.  , -0.25,  0.5 ,  1.25])\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artificial-exclusive",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "artificial-exclusive",
    "outputId": "2e10c59c-592a-4273-b0c2-e54754cbe860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt -3.0\n",
      "n_nodes 500\n",
      "connectivity -1.7001224756240845\n",
      "spectral_radius 2.4289157390594482\n",
      "regularization 1.6905698776245117\n",
      "leaking_rate 0.0032216429244726896\n",
      "bias 0.3808490037918091\n",
      "enet_alpha 0.2040003091096878\n",
      "enet_strength -1.1255784034729004\n",
      "spikethreshold 0.4231834411621094\n",
      "gamma 0.09350859373807907\n",
      "gamma_cyclic 0.9999\n"
     ]
    }
   ],
   "source": [
    "log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt', 'enet_strength']\n",
    "\n",
    "#trained to 20*pi\n",
    "hps = {'dt': 0.001,\n",
    "       'n_nodes': 500,\n",
    "       'connectivity': 0.019946997092875757,\n",
    "       'spectral_radius': 2.4289157390594482,\n",
    "       'regularization': 49.04219249279563,\n",
    "       'leaking_rate': 0.0032216429244726896,\n",
    "       'bias': 0.3808490037918091,\n",
    "       'enet_alpha': 0.2040003091096878,\n",
    "       'enet_strength': 0.07488961475845243,\n",
    "       'spikethreshold': 0.4231834411621094,\n",
    "       'gamma': .09350859373807907,\n",
    "       'gamma_cyclic' : 0.9999}\n",
    "\n",
    "\n",
    "\n",
    "for key, val in hps.items():\n",
    "    if key in log_vars:\n",
    "        print(key, np.log10(val))\n",
    "    else:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-liberal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "historic-liberal",
    "outputId": "fcde4903-229d-4aa5-c85f-0298a3e62362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURN_IN = 500\n",
    "\n",
    "#declare the bounds dict. See above for which variables are optimized in linear vs logarithmic space.\n",
    "bounds_dict = {\"connectivity\" : (-2, -1.4), #(-2, -0.5), \n",
    "               \"spectral_radius\" : (2.2, 2.6),#(0.01, 1),\n",
    "               \"n_nodes\" : 500,\n",
    "               \"regularization\" : 1.69, #(-4.4, 2.6),\n",
    "               \"leaking_rate\" : (0.00322 - 0.002, 0.00322 + 0.002),\n",
    "               \"dt\" : -3,#-3,\n",
    "               \"bias\": (-0.5, 0.5),\n",
    "               \"enet_alpha\": (0.18, 0.22), #(0,1.0),\n",
    "               \"enet_strength\": (-1.32,-0.92),\n",
    "               \"spikethreshold\" : (0.35,0.45),\n",
    "               \"gamma\" : (0.08,0.12),\n",
    "               \"gamma_cyclic\" : (float(np.log10(0.9997)), float(np.log10(0.99999))),#(-0.002176919254274547, 0)\n",
    "               }\n",
    "#set up data\n",
    "x0, xf = 0, 4*np.pi\n",
    "nsteps = int(abs(xf - x0)/(10**bounds_dict[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "int(xtrain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "living-coordination",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "living-coordination",
    "outputId": "c5218826-e571-48e5-d189-02b880096345",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK: None , device: None\n",
      "cpu\n",
      "m,n 1 500\n",
      "in_weights torch.Size([500, 1])\n",
      "Model initialization and exploration run...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f96e8513bf21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     opt_hps = esn_cv.optimize(y = None, \n\u001b[0m\u001b[1;32m     22\u001b[0m                               \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mreparam_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, y, x, store_path, epochs, learning_rate, scoring_method, criterion, reparam_f, ODE_criterion, init_conditions, scale, force, backprop_f, backprop, ode_coefs, solve, rounds, tr_score_prop, q, eq_system, n_outputs, nonlinear_ode, reg_type)\u001b[0m\n\u001b[1;32m   1625\u001b[0m                 \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_init\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m                 \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_objective\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_batch\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36meval_objective\u001b[0;34m(self, parameters, plot_type, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn_cv.py\u001b[0m in \u001b[0;36mexecute_objective\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;31m#                 \"ydots\"  : ydots,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m#                 \"losses\" : Ls}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0mdictt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m                 \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mval_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalidate_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorch/esn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, X, burn_in, input_weight, verbose, learning_rate, return_states, criterion, optimizer, out_weights, ODE_order, SOLVE, reparam_f, init_conditions, force, ode_coefs, train_score, ODE_criterion, preloaded_states_dict, q, eq_system, nl, backprop_f, epochs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                         \u001b[0;31m#print(self.init_conds[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                             \u001b[0mweight_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                         \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-454944190377>\u001b[0m in \u001b[0;36moptimize_last_layer\u001b[0;34m(esn, SAVE_AFTER_EPOCHS, epochs, custom_loss, EPOCHS_TO_TERMINATION, f, lr, reg, plott, plot_every_n_epochs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;31m#         best_ydot = ydot.clone()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mEPOCHS_TO_TERMINATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 return {\"weights\": best_weight, \"bias\" : best_bias, \"y\" : best_fit, \n\u001b[1;32m    247\u001b[0m                       \u001b[0;34m\"loss\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss_history\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"best_score\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'int' and 'NoneType'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            interactive = True, \n",
    "                            batch_size = 1, \n",
    "                            cv_samples = 1, \n",
    "                            initial_samples = 100,  #200\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.98),\n",
    "                            validate_fraction = 0.5,\n",
    "                            random_seed = 209, \n",
    "                            success_tolerance = 10,\n",
    "                            ODE_order = 1, \n",
    "                            length_min = 2 **(-8),\n",
    "                            esn_burn_in = BURN_IN, \n",
    "                            log_score = True,\n",
    "                            activation_function = torch.sin,\n",
    "                        act_f_prime = torch.cos,\n",
    "                            )\n",
    "#optimize:\n",
    "opt = True\n",
    "if opt:\n",
    "    opt_hps = esn_cv.optimize(y = None, \n",
    "                              x = xtrain.view(-1,1),\n",
    "                            reparam_f = reparam, \n",
    "                            ODE_criterion = custom_loss,\n",
    "                            init_conditions = [[1.1, 1.3], 1],#[[0,1], [0,1]], \n",
    "                            force = force,\n",
    "                            ode_coefs = [1, 1],\n",
    "                            rounds =1,\n",
    "                            backprop_f = optimize_last_layer, \n",
    "                            solve =  True, \n",
    "                            eq_system = True,\n",
    "                            n_outputs = 2,\n",
    "                            epochs =  5000,\n",
    "                            reg_type = \"ham\",\n",
    "                            tr_score_prop = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-oxford",
   "metadata": {
    "id": "instrumental-oxford"
   },
   "outputs": [],
   "source": [
    "if opt:\n",
    "    opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9FfE_WCWW4GA",
   "metadata": {
    "id": "9FfE_WCWW4GA"
   },
   "outputs": [],
   "source": [
    "esn_cv.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-story",
   "metadata": {
    "id": "moderate-story"
   },
   "outputs": [],
   "source": [
    "#opt_hps\n",
    "#new hps\n",
    "hps = {'dt': 10**-2.2, #0.00630957344480193,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.0032730501495831926,\n",
    " 'spectral_radius': 8, #1.4158440828323364,\n",
    " 'regularization': 1.5068021807798724,\n",
    " 'leaking_rate': 0.059490688145160675,\n",
    " 'bias': -0.048827290534973145}\n",
    "\n",
    "\n",
    "new_hps = {'dt': 0.01,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.0012518575764582111,\n",
    " 'spectral_radius': 1.1966601610183716,\n",
    " 'regularization': 16.545863672039996,\n",
    " 'leaking_rate': 0.06009502336382866,\n",
    " 'bias': 0.3623389005661011,\n",
    " 'enet_alpha': 0.8732492327690125,\n",
    " 'enet_strength': 0.011039982688091154}\n",
    "\n",
    "new_new_hps = {'dt': 0.015848931924611134,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.019411325024276192,\n",
    " 'spectral_radius': 1.0023764371871948,\n",
    " 'regularization': 0.01620633637515373,\n",
    " 'leaking_rate': 0.064253069460392,\n",
    " 'bias': 0.42768096923828125,\n",
    " 'enet_alpha': 0.6743161678314209,\n",
    " 'enet_strength': 0.8529825590176218}\n",
    "\n",
    "#trained to 20*pi\n",
    "hps = {'dt': 0.015848931924611134,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.011412976296653454,\n",
    " 'spectral_radius': 1.5883185863494873,\n",
    " 'regularization': 0.00017807099501162684,\n",
    " 'leaking_rate': 0.13014408946037292,\n",
    " 'bias': 0.9991035461425781,\n",
    " 'enet_alpha': 0.3216418921947479,\n",
    " 'enet_strength': 4.858497457864491,\n",
    " 'spikethreshold': 0.3982628881931305,\n",
    " 'gamma': 0.09541413187980652}\n",
    "\n",
    "#trained to 20*pi round 2\n",
    "hps = {'dt': 0.015848931924611134,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.07016350849568936,\n",
    " 'spectral_radius': 1.2355562448501587,\n",
    " 'regularization': 1.9761536690744939,\n",
    " 'leaking_rate': 0.03428209573030472,\n",
    " 'bias': 0.9089397192001343,\n",
    " 'enet_alpha': 0.2660914659500122,\n",
    " 'enet_strength': 3.898602924275761,\n",
    " 'spikethreshold': 0.4618821144104004,\n",
    " 'gamma': 0.0948069617152214}\n",
    "\n",
    "\n",
    "afternoon_hps = {'dt': 0.01, #0.001, #0.01\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.020193996324265714,\n",
    " 'spectral_radius': 1.418228268623352,\n",
    " 'regularization': 13.826029502079747,\n",
    " 'leaking_rate': 0.06767291575670242,\n",
    " 'bias': -1.1795610189437866,\n",
    " 'enet_alpha': 0.2708361744880676,\n",
    " 'enet_strength': 0.015112827558814506,\n",
    " 'spikethreshold': 0.4739722013473511,\n",
    " 'gamma': 0.05922722443938255}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-brass",
   "metadata": {
    "id": "described-brass"
   },
   "source": [
    "#esn_cv.Y_turbo.detach().cpu())\n",
    "Y_turbo = esn_cv.Y_turbo.data.cpu()\n",
    "plt.plot(Y_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-performance",
   "metadata": {
    "id": "three-performance"
   },
   "outputs": [],
   "source": [
    "plt.plot(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-knife",
   "metadata": {
    "id": "naughty-knife"
   },
   "outputs": [],
   "source": [
    "# plot_result(esn, xtrain, v0s = np.array([1]), \n",
    "#             y0s = [1.3],plot_gt = True, ode_coefs = [1,1], \n",
    "#             force_k = 0,\n",
    "#            backprop_f = optimize_last_layer,solve = True, epochs = 80000, reg = False)\n",
    "# plt.plot(esn.states[:,1:10].detach().cpu());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-maryland",
   "metadata": {
    "id": "silver-maryland"
   },
   "outputs": [],
   "source": [
    "def fit_and_test(RC, xtrain, xtest, y0 = 1.3, v0 = 1, ode_coefs = [1,1], \n",
    "                 solve = None, epochs = None, reg = None, plott = None):\n",
    "    train_args = {\"burn_in\" : int(BURN_IN), \n",
    "                      \"ODE_order\" : 1,\n",
    "                      \"force\" : force,\n",
    "                      \"reparam_f\" : reparam,\n",
    "                      \"init_conditions\" : [float(y0), float(v0)],\n",
    "                      \"ode_coefs\" : ode_coefs,\n",
    "                      \"y\" : None,\n",
    "                      \"X\" : xtrain.view(-1,1),\n",
    "                      \"eq_system\" : True,\n",
    "                      #\"out_weights\" : out_weights\n",
    "                      }\n",
    "    #fit\n",
    "    y, ydot = RC.fit(**train_args, SOLVE = solve)#, out_weights = out_weights)\n",
    "    states_dict = {\"s\"  : RC.states.clone(),\n",
    "                   \"s1\" : RC.states_dot.clone(), \n",
    "                   \"G\"  : RC.G,\n",
    "                   \"ex\" : RC.extended_states.clone(),\n",
    "                   \"sb1\": RC.sb1,\n",
    "                   \"sb\" : RC.sb\n",
    "                   }\n",
    "    weight_dict = optimize_last_layer(RC, epochs = epochs,reg = reg, plott = plott)\n",
    "    RC = weight_dict[\"RC\"]\n",
    "    #y, ydot = esn.fit(**train_args, preloaded_states_dict = states_dict, out_weights = weight_dict, SOLVE = False)\n",
    "    \n",
    "    #test\n",
    "    score, pred, _ = RC.test(y = torch.ones_like(xtest.to(esn.device)), X = xtest.to(esn.device), reparam = reparam, ODE_criterion = custom_loss)\n",
    "    \n",
    "    return esn.X.cpu().data, weight_dict[\"fit\"].cpu().data, ydot.cpu().data, pred.cpu().data, weight_dict\n",
    "\n",
    "def integrator_sol(esn):\n",
    "    def f(u, t ,lam=0,A=0,W=1):\n",
    "            x,  px = u      # unpack current values of u\n",
    "            derivs = [px, -x - lam*x**3 +A*np.sin(W*t)]     # you write the derivative here\n",
    "            return derivs\n",
    "        \n",
    "    # Scipy Solver   \n",
    "    def NLosc_solution(t, x0,  px0, lam=0, A=0,W=1):\n",
    "        u0 = [x0, px0]\n",
    "        # Call the ODE solver\n",
    "        solPend = odeint(f, u0, t.cpu(), args=(lam,A,W,))\n",
    "        xP = solPend[:,0];        pxP = solPend[:,1];   \n",
    "        return xP, pxP\n",
    "\n",
    "    y_truth, v_truth = NLosc_solution(esn.X.squeeze().data,1.3,1,lam=1, A=0, W= 0) \n",
    "    \n",
    "    return y_truth, v_truth\n",
    "\n",
    "def plot_sol(X, yy, gt, xtest, pred, train_lim = None):\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    print(yy[0,:].shape)\n",
    "    plt.plot(X, yy[:,0].cpu(), label = \"pred\", color = \"red\")\n",
    "    plt.plot(X, gt[0], '--', color = 'r')\n",
    "    \n",
    "    plt.axvline(train_lim, label = \"train_limit\")\n",
    "    \n",
    "    plt.plot(X, yy[:,1].cpu(), label = \"pred\", color = \"b\", linewidth = 5, alpha = 0.5)\n",
    "    plt.plot(X, gt[1], '--', color = 'b', linewidth = 5, alpha = 0.5)\n",
    "    \n",
    "    plt.plot(xtest, pred, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-liabilities",
   "metadata": {
    "id": "better-liabilities"
   },
   "outputs": [],
   "source": [
    "may12hps = {'dt': 0.001,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.019946997092875757,\n",
    " 'spectral_radius': 2.4289157390594482,\n",
    " 'regularization': 49.04219249279563,\n",
    " 'leaking_rate': 0.0032216429244726896,\n",
    " 'bias': 0.3808490037918091,\n",
    " 'enet_alpha': 0.2040003091096878,\n",
    " 'enet_strength': 0.07488961475845243,\n",
    " 'spikethreshold': 0.4231834411621094,\n",
    " 'gamma': .09350859373807907,\n",
    "  'gamma_cyclic' : 0.9999}\n",
    "\n",
    "may13hps ={'gamma_cyclic': 1,#0.9998,\n",
    " 'spikethreshold': 0.25,\n",
    " 'enet_alpha': 0.2,\n",
    " 'dt': 0.01,\n",
    " 'regularization': 13.803842646028846,\n",
    " 'n_nodes': 600,\n",
    " 'connectivity': 0.01344268178203971,\n",
    " 'spectral_radius': 2.459860324859619,\n",
    " 'leaking_rate': 0.0045151556842029095,\n",
    " #'input_scaling': 0.7782557606697083,\n",
    " 'bias': -0.7429814338684082,\n",
    " 'enet_strength': 0.04331694643272608,\n",
    " 'gamma': 0.08337975293397903}\n",
    "\n",
    "may15hps = {'dt': 0.001,\n",
    " 'regularization': 48.97788193684461,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.017714821964432213,\n",
    " 'spectral_radius': 2.3660330772399902,\n",
    " 'leaking_rate': 0.0024312976747751236,\n",
    " 'bias': 0.37677669525146484,\n",
    " 'enet_alpha': 0.2082211971282959,\n",
    " 'enet_strength': 0.118459548397668,\n",
    " 'spikethreshold': 0.43705281615257263,\n",
    " 'gamma': 0.09469877928495407,\n",
    " 'gamma_cyclic': 0.999860422666841}\n",
    "\n",
    "hp_set = may15hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-chorus",
   "metadata": {
    "id": "southeast-chorus"
   },
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**hp_set, \n",
    "                       random_state = 209, \n",
    "                       feedback = False, \n",
    "                       id_ = 10,\n",
    "                       activation_f = torch.sin,\n",
    "                       act_f_prime = torch.cos,\n",
    "                       dtype = torch.float32, n_outputs = 2)\n",
    "factor = 1#0.6*0.7\n",
    "base = 10*np.pi\n",
    "factor = 1.2\n",
    "x0, xf, xf2 = 0, base, base*factor\n",
    "nsteps = int(abs(xf - x0)/(hp_set[\"dt\"]))\n",
    "nsteps2 = int(abs(xf2 - xf)/(hp_set[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "xtest = torch.cat((xtrain,xtrain+xtrain[-1]), axis = 0)[len(xtrain):]\n",
    "dt1, dt2 = float(xtest[1] - xtest[0]), float(xtrain[1]- xtrain[0])\n",
    "#assert dt1 == dt2, f'{dt1} != {dt2}'\n",
    "\n",
    "\n",
    "xx, yy, yydot, yypred, weight_dict =  fit_and_test(esn, xtrain, xtest, epochs = 50000, reg = False, plott = True, solve = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-unknown",
   "metadata": {
    "id": "stopped-unknown"
   },
   "outputs": [],
   "source": [
    "plt.plot(esn.states[:,  1:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-devices",
   "metadata": {
    "id": "completed-devices",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain[1]- xtrain[0], xtest[1]- xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-candy",
   "metadata": {
    "id": "educated-candy"
   },
   "outputs": [],
   "source": [
    "gt = integrator_sol(esn)\n",
    "plot_sol(xx, yy,gt, xtest, yypred, xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-container",
   "metadata": {
    "id": "emerging-container"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-roman",
   "metadata": {
    "id": "advance-roman"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(esn.laststate.cpu().data.numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-newark",
   "metadata": {
    "id": "suburban-newark"
   },
   "outputs": [],
   "source": [
    "xtest.shape, weight_dict[\"weights\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-adult",
   "metadata": {
    "id": "peaceful-adult"
   },
   "outputs": [],
   "source": [
    "xtest2 = torch.linspace(x0, xf2, nsteps2, requires_grad=False).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-spank",
   "metadata": {
    "id": "dental-spank"
   },
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**may12hps, \n",
    "                       random_state = 209, \n",
    "                       feedback = False, \n",
    "                       id_ = 10,\n",
    "                       backprop = False,\n",
    "                       activation_f = torch.sin,\n",
    "                       act_f_prime = torch.cos,\n",
    "                       dtype = torch.float32, n_outputs = 2)\n",
    "\n",
    "train_args = {\"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,\n",
    "              \"force\" : force,\n",
    "              \"reparam_f\" : reparam,\n",
    "              \"init_conditions\" : [float(1.3), float(1)],\n",
    "              \"ode_coefs\" : [1,1],\n",
    "              \"y\" : None,\n",
    "              \"X\" : xtrain.view(-1,1),#\n",
    "              \"eq_system\" : True,\n",
    "              \"out_weights\" : weight_dict,\n",
    "              \"SOLVE\" : False\n",
    "              }\n",
    "y, ydot = esn.fit(**train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-tamil",
   "metadata": {
    "id": "welsh-tamil"
   },
   "outputs": [],
   "source": [
    "yhat = esn.predict(None, x = xtest.cuda(), continuation = True, #torch.ones_like(xtest2.cuda()), , \n",
    "                   continue_force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-chess",
   "metadata": {
    "id": "naked-chess"
   },
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-marshall",
   "metadata": {
    "id": "decent-marshall"
   },
   "outputs": [],
   "source": [
    "plt.plot(esn.X.cpu(), y.cpu().detach())\n",
    "plt.plot(xtest,yhat[1].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-begin",
   "metadata": {
    "id": "upset-begin"
   },
   "outputs": [],
   "source": [
    "esn.X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-married",
   "metadata": {
    "id": "killing-married"
   },
   "outputs": [],
   "source": [
    "esn.laststate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-score",
   "metadata": {
    "id": "hearing-score"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#t2, ys, gts, ws, bs, Ls = result\n",
    "plot_data = {\"time\": xx, \n",
    "            \"ypreds\" : yy,\n",
    "            \"extrapolation\" : yypred,\n",
    "            \"gts\" : gt}\n",
    "\n",
    "with open('nonlinear_oscillator_plot.pickle', 'wb') as handle:\n",
    "    pickle.dump(plot_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('nonlinear_oscillator_plot.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "\n",
    "repr_data = {\"time\": xx, \n",
    "       \"hyper_params\" : may12hps,\n",
    "       \"out_weights\" : {\"weights\": [weight_dict[\"weights\"]],\n",
    "                        \"bias\": [weight_dict[\"bias\"]]}, \n",
    "       \"burn_in\" : BURN_IN, \n",
    "       \"epochs\" : 30000,\n",
    "       \"learning_rate\": 0.04,\n",
    "       \"loss_history\" : weight_dict[\"loss\"],\n",
    "       \"info\" : \"run on 30k epochs with both lr schedulers.\",\n",
    "       \"v0\" : 1,\n",
    "       \"y0\" : 1.3}\n",
    "\n",
    "with open('nonlinear_oscillator_reproduce.pickle', 'wb') as handle:\n",
    "    pickle.dump(repr_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('nonlinear_oscillator_reproduce.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-jungle",
   "metadata": {
    "id": "cleared-jungle"
   },
   "outputs": [],
   "source": [
    "esn = EchoStateNetwork(**afternoon_hps, \n",
    "                       random_state = 209, \n",
    "                       id_ = 10,\n",
    "                       activation_f = torch.sin,\n",
    "                       act_f_prime = torch.cos,\n",
    "                       dtype = torch.float32, n_outputs = 2)\n",
    "\n",
    "extrapolate(esn, 0 , (np.pi * 20), (np.pi * 20)*1.2, epochs = 100000, solve = True, reg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-corruption",
   "metadata": {
    "id": "unlike-corruption"
   },
   "outputs": [],
   "source": [
    "orig_BO_train_len_pi_prop = 0.6*0.7\n",
    "extrapolate(esn,  0, (np.pi * 4),  (np.pi * 4)*1.2, epochs = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-moore",
   "metadata": {
    "id": "waiting-moore"
   },
   "outputs": [],
   "source": [
    "assert False\n",
    "best_weights = {\"weights\" : esn.LinOut.weight.data, \n",
    "                \"bias\": esn.LinOut.bias.data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-tattoo",
   "metadata": {
    "id": "quarterly-tattoo"
   },
   "outputs": [],
   "source": [
    "xf0,xf1, dt = 0, (np.pi * 20), esn.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-cleaners",
   "metadata": {
    "id": "wrapped-cleaners"
   },
   "outputs": [],
   "source": [
    "train_args = {\"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,\n",
    "              \"force\" : force,\n",
    "              \"reparam_f\" : reparam,\n",
    "              \"init_conditions\" : [float(1.3), float(1)],\n",
    "              \"ode_coefs\" : [1,1],\n",
    "              \"y\" : None,\n",
    "              \"X\" : xtrain.view(-1,1),\n",
    "              \"eq_system\" : True,\n",
    "              \"out_weights\" : best_weights\n",
    "              }\n",
    "        \n",
    "y, ydot = esn.fit(**train_args, SOLVE = False)\n",
    "\n",
    "\n",
    "\n",
    "#nsteps_test = int((xf2 - x0)/dt_)\n",
    "#nsteps_test2 = int((xf2 - xf1)/dt_)\n",
    "\n",
    "#print(f'dt = {dt_}')\n",
    "\n",
    "#xtest = torch.linspace(x0, xf2, steps = nsteps_test, requires_grad=False).view(-1,1)\n",
    "#xtest2 = torch.linspace(xf1, xf2, steps = nsteps_test2, requires_grad=False).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-memorabilia",
   "metadata": {
    "id": "clear-memorabilia"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-deadline",
   "metadata": {
    "id": "inappropriate-deadline"
   },
   "outputs": [],
   "source": [
    "def f(u, t ,lam=0,A=0,W=1):\n",
    "            x,  px = u      # unpack current values of u\n",
    "            derivs = [px, -x - lam*x**3 +A*np.sin(W*t)]     # you write the derivative here\n",
    "            return derivs\n",
    "        \n",
    "# Scipy Solver   \n",
    "def NLosc_solution(t, x0,  px0, lam=0, A=0,W=1):\n",
    "    u0 = [x0, px0]\n",
    "    # Call the ODE solver\n",
    "    solPend = odeint(f, u0, t.cpu(), args=(lam,A,W,))\n",
    "    xP = solPend[:,0];        pxP = solPend[:,1];   \n",
    "    return xP, pxP\n",
    "\n",
    "y_truth, v_truth  = NLosc_solution(esn.X.squeeze().data,1.3,1,lam=1, A=0, W= 0.5) \n",
    "\n",
    "\n",
    "#p = y[:,1].cpu()# + v0\n",
    "#yy = y[:,0].cpu()# + y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-asthma",
   "metadata": {
    "id": "attempted-asthma"
   },
   "outputs": [],
   "source": [
    "plt.plot((y[:,1].cpu()))\n",
    "plt.plot(v_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-building",
   "metadata": {
    "id": "working-building"
   },
   "outputs": [],
   "source": [
    "x, p = esn.yfit[:,0].view(-1,1), esn.yfit[:,1].view(-1,1)\n",
    "xdot, pdot = esn.ydot[:,0].view(-1,1), esn.ydot[:,1].view(-1,1)\n",
    "plt.plot(custom_loss(esn.X, esn.yfit, esn.ydot, None, mean = False))\n",
    "plt.plot(x, label = \"x\")\n",
    "plt.plot(p, label = \"p\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eq_system_v1_sin_nonlinear_ham_fast.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
