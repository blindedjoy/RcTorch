{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from RcTorchPrivate import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-binding",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to use RcTorch to find optimal hyper-paramters for the differential equation $\\dot y + q(t) y = f(t) $.\n",
    "\n",
    "Simple population:  <font color='blue'>$\\dot y + y =0$  </font>\n",
    "* Analytical solution: <font color='green'>$y = y_0 e^{-t}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wound-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(RC, results, integrator_model, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.detach().cpu()\n",
    "    \n",
    "    #int_sols = []\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        if not i:\n",
    "            labels = [\"RC\", \"integrator solution\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        y = y.detach().cpu()\n",
    "        ax.plot(X, y, color = \"blue\", label = labels[0])\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        #int_sols.append(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"red\", alpha = 0.9, label = labels[1])\n",
    "        \n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend();\n",
    "    #return int_sols\n",
    "\n",
    "def plot_rmsr(RC, results, force, log = False, ax = None, RMSR = True):\n",
    "    \"\"\"plots the root mean square residuals (RMSR) of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.detach().cpu()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    for i, y in enumerate(ys):\n",
    "        y = y.detach().cpu()\n",
    "        ydot = ydots[i].detach().cpu()\n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force = force, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False, reg = False)\n",
    "        rmsr = torch.sqrt(resids)\n",
    "        \n",
    "        if not i:\n",
    "            rmsr_tensor = rmsr\n",
    "            label = \"individual trajectory rmsr\"\n",
    "        else:\n",
    "            rmsr_tensor = torch.cat((rmsr_tensor, rmsr), axis = 1)\n",
    "            label = None\n",
    "        \n",
    "        if log:\n",
    "            rmsr = torch.log10(rmsr)\n",
    "            \n",
    "        ax.plot(X, rmsr, color = \"red\", alpha = 0.4, label = label)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_rmsr = torch.mean(rmsr_tensor, axis =1)\n",
    "    if log:\n",
    "        mean_rmsr = torch.log10(mean_rmsr)\n",
    "    ax.plot(X, mean_rmsr, \n",
    "                color = \"blue\", \n",
    "                alpha = 0.9, \n",
    "                label = \"mean rmsr\")\n",
    "\n",
    "    ax.legend();\n",
    "    \n",
    "    ax.set_xlabel(\"time\")\n",
    "    if log:\n",
    "        ax.set_ylabel(\"log rmsr\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"rmsr\")\n",
    "    print(torch.mean(mean_rmsr))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)#A*torch.sin(X)\n",
    "lam =1\n",
    "def custom_loss(X , y, ydot, out_weights, lam = lam, force = force, reg = False, \n",
    "               ode_coefs = None, init_conds = None, \n",
    "                enet_alpha = None, enet_strength =None, mean = True):\n",
    "    \n",
    "    #with paramization\n",
    "    L =  ydot  + lam * y - force(X)\n",
    "    \n",
    "    if reg:\n",
    "        #assert False\n",
    "        weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "        weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "        L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "        L = L + 0.1 * L_reg \n",
    "    \n",
    "    L = torch.square(L)\n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tutorial-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "bounds_dict = {\"connectivity\" : (-2, -0.5), #log space\n",
    "               \"spectral_radius\" : (1, 2), #lin space\n",
    "               \"n_nodes\" : 250, \n",
    "               \"regularization\" : (-4, 4), #log space\n",
    "               \"leaking_rate\" : (0, 1),    #linear space\n",
    "               \"dt\" : -2.75, #log space\n",
    "               \"bias\": (-0.75,0.75) #linear space\n",
    "               }\n",
    "\n",
    "#set up data\n",
    "BURN_IN = 500 #how many time points of states to throw away before starting optimization.\n",
    "x0, xf = 0, 5\n",
    "nsteps = int(abs(xf - x0)/(10**bounds_dict[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "int(xtrain.shape[0] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollow-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the initial conditions (each initial condition corresponds to a different curve)\n",
    "y0s = np.arange(0.1, 10.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK: None , device: None\n",
      "cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/RcTorchPrivate/esn_cv.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, y, x, store_path, epochs, learning_rate, scoring_method, criterion, reparam_f, ODE_criterion, init_conditions, scale, force, backprop_f, backprop, ode_coefs, solve, rounds, tr_score_prop, q, eq_system, n_outputs, nonlinear_ode, reg_type)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 \u001b[0mcustom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhennon_hailes_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mODE_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbackprop_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            interactive = True, \n",
    "                            batch_size = 1, #batch size is parallel\n",
    "                            cv_samples = 2, #number of cv_samples, random start points\n",
    "                            initial_samples = 100, #number of random samples before optimization starts\n",
    "                            subsequence_length = int(xtrain.shape[0] * 0.8), #combine len of tr + val sets\n",
    "                            validate_fraction = 0.3, #validation prop of tr+val sets\n",
    "                            log_score = True, #log-residuals\n",
    "                            random_seed = 209, # random seed\n",
    "                            ODE_order = 1, #order of eq\n",
    "                            esn_burn_in = BURN_IN, #states to throw away before calculating output\n",
    "                            #see turbo ref:\n",
    "                            length_min = 2 **(-7), \n",
    "                            success_tolerance = 10, \n",
    "                            )\n",
    "#optimize the network:\n",
    "opt_hps = esn_cv.optimize(x = xtrain,\n",
    "                        reparam_f = reparam, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        init_conditions = [y0s], \n",
    "                        force = force,\n",
    "                        ode_coefs = [1,1],\n",
    "                        backprop_f = None,\n",
    "                        n_outputs = 1,\n",
    "                        eq_system = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriental-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some particularly good runs:\n",
    "\n",
    "# opt_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.7170604557008349,\n",
    "#  'spectral_radius': 1.5755887031555176,\n",
    "#  'regularization': 0.00034441529823729916,\n",
    "#  'leaking_rate': 0.9272222518920898,\n",
    "#  'bias': 0.1780446171760559}\n",
    "\n",
    "# opt_hps = {'dt': 0.0017782794100389228,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.11197846061157432,\n",
    "#  'spectral_radius': 1.7452095746994019,\n",
    "#  'regularization': 0.00012929296298723957,\n",
    "#  'leaking_rate': 0.7733328938484192,\n",
    "#  'bias': 0.1652531623840332}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prepared-slovak",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt_hps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9f01622534a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt_hps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'opt_hps' is not defined"
     ]
    }
   ],
   "source": [
    "opt_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = np.arange(-10, 10.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "RC = EchoStateNetwork(**opt_hps,\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1, 1]}\n",
    "\n",
    "\n",
    "results = RC.fit(init_conditions = [y0s,1],\n",
    "                    SOLVE = True,\n",
    "                    train_score = True, \n",
    "                    ODE_criterion = custom_loss,\n",
    "                    **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_pop(y, t, t_pow = 0, force_k = 0, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(RC, results, simple_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmsr(RC, results, force = force, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-product",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-webmaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
