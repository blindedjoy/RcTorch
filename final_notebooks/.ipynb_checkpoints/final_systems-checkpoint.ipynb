{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from RcTorchPrivate import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-roman",
   "metadata": {},
   "source": [
    "## Rc and systems of ODEs: an overview\n",
    "\n",
    "In this notebook we demonstrate that the RC can solve systems of differential equations. Any higher order ODE can be decomposed into a system of first order ODEs, hence solving systems of ODEs means that RC can solver higher order ODEs. This is a standard procedure followed by standard integrators . To apply the RC to systems, the RC architecture needs to be modified to return multiple outputs $N_j$, where $j$ indicates a different output. Specifically, the number of the outputs needs to be the same as the number of the equations in a system. Each output has a different set of weights $W_{out}^{(j)}$ while all the $N_j$ share the same hidden states.\n",
    "\n",
    "We exploit the RC solver in solving the equations of motion for a nonlinear Hamiltonian system, the nonlinear oscillator.  The energy is conserved in this system and thus, we adopt hamiltonian energy regularization that drastically accelerates the training and improves the fidelity of the predicted solutions. \n",
    "\n",
    "### Hamiltonian systems\n",
    "Hamiltonian systems  obey the energy conservation law. In other words, these systems are characterized by a hamiltonian function that represents the total energy of the system which remains constant in time. The hamiltonian of a nonlinear oscillator with unity mass and frequency is given by:\n",
    "\\begin{align}\n",
    "    \\label{eq:NL_ham}\n",
    "    \\mathcal{H} = \\frac{p^2}{2} + \\frac{x^2}{2} + \\frac{x^4}{4},\n",
    "\\end{align}\n",
    "and the associated equations of motion reads:\n",
    "\\begin{align}\n",
    "    \\label{eq:NL_x} \n",
    "    \\dot x &= p \\\\\n",
    "    \\label{eq:NL_p}\n",
    "    \\dot p &= -x - x^3\n",
    "\\end{align}\n",
    "where $p$ is the momentum and $x$ represents the position of the system. The loss function consists of three parts: $L_\\text{ODE}$ for the ODEs of x and p; a hamiltonian penalty $L_{\\mathcal{H}}$ that penalizes violations in the energy conservation and is defined by Eq\n",
    "\n",
    "Subsequently, the total $L$  reads:\n",
    "\\begin{align}\n",
    "    L &= L_\\text{ODE}+ L_{\\mathcal{H}} + L_\\text{reg} \\nonumber \\\\\n",
    "     \\label{eq:NL_loss}\n",
    "     &= \\sum_{n=0}^{K}\n",
    "      \\Big[ \\left(\\dot x_n-p_n\\right)^2 + \\left(\\dot p_n + x_n + x_n^3  \\right)^2 +\\left(E - \\mathcal{H}(x_n, p_n)\\right)^2 \\Big]   + \\lambda \\sum_{j=x,p} W_{out}^{(j)T} W_{out}^{(j)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "gorgeous-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(u, t ,lam=0,A=0,W=1):\n",
    "            x,  px = u      # unpack current values of u\n",
    "            derivs = [px, -x - lam*x**3 +A*np.sin(W*t)]     # you write the derivative here\n",
    "            return derivs\n",
    "        \n",
    "# Scipy Solver   \n",
    "def NLosc_solution(t, x0,  px0, lam=0, A=0,W=1):\n",
    "    u0 = [x0, px0]\n",
    "    # Call the ODE solver\n",
    "    solPend = odeint(f, u0, t.cpu(), args=(lam,A,W,))\n",
    "    xP = solPend[:,0];        pxP = solPend[:,1];   \n",
    "    return xP, pxP\n",
    "\n",
    "def plot_results(RC, results, integrator_model, y0s, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu().detach()\n",
    "    #int_sols = []\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    \n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu().detach()\n",
    "        if not i:\n",
    "            labels = [\"RC\",\"integrator\"]\n",
    "        else:\n",
    "            labels = [None, None, None, None]\n",
    "        try:\n",
    "            labels\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ax.plot(y[:,0], y[:,1], label = labels[0], \n",
    "                linewidth =7, alpha = 0.9, color = \"blue\")\n",
    "        \n",
    "        \n",
    "        #calculate the integrator prediction:\n",
    "        y_truth, p_truth  = NLosc_solution(RC.X.squeeze().data,y0s[i],1,lam=1, A=0, W= 0) \n",
    "        \n",
    "        #p = y[:,1].cpu()# + v0\n",
    "        #yy = y[:,0].cpu()# + y0\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(y_truth, p_truth, color = \"red\", linewidth =3, \n",
    "                alpha = 1.0, label = labels[1])\n",
    "#         ax.plot(X, p, color = \"red\", alpha = 1.0, linewidth =3, \n",
    "#                 label = labels[3])\n",
    "        \n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"p\")\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.legend();\n",
    "    #return int_sols\n",
    "\n",
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)\n",
    "\n",
    "def plot_rmsr(RC, results, force, log = False, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu().detach()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    for i, y in enumerate(ys):\n",
    "        y = y.cpu().detach()\n",
    "        ydot = ydots[i].cpu().detach()\n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force = force, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False,\n",
    "                            init_conds = RC.init_conds,\n",
    "                            ham = False)\n",
    "        rmsr = torch.sqrt(resids)\n",
    "        if not i:\n",
    "            rmsr_tensor = rmsr\n",
    "            label = \"individual trajectory rmsr\"\n",
    "        else:\n",
    "            rmsr_tensor = torch.cat((rmsr_tensor, rmsr), axis = 1)\n",
    "            label = None\n",
    "        \n",
    "        if log:\n",
    "            rmsr = torch.log10(rmsr)\n",
    "            \n",
    "        ax.plot(X, rmsr, color = \"red\", alpha = 0.4, label = label)\n",
    "    \n",
    "    mean_rmsr = torch.mean(rmsr_tensor, axis =1)\n",
    "    ax.plot(X, torch.log10(mean_rmsr), \n",
    "                color = \"blue\", \n",
    "                alpha = 0.9, \n",
    "                label = \"mean rmr\")\n",
    "\n",
    "    ax.legend();\n",
    "    \n",
    "    ax.set_xlabel(\"time\")\n",
    "    if log:\n",
    "        ax.set_ylabel(\"log rmsr\")\n",
    "        \n",
    "    else:\n",
    "        ax.set_ylabel(\"root mean square error\")\n",
    "        \n",
    "#     plot_data = {\"time\": X, \n",
    "#                  \"ys\" : ys,\n",
    "#                  \"ydots\" : ydots,\n",
    "#                  \"resids\" : residuals,\n",
    "#                  \"mean_resid\": mean_resid}\n",
    "#     return plot_data\n",
    "\n",
    "def driven_force(X, A = 1):\n",
    "    return A * torch.sin(X)\n",
    "\n",
    "def no_force(X, A = 0):\n",
    "    return A\n",
    "\n",
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot\n",
    "    \n",
    "    #first derivative\n",
    "    \n",
    "    \n",
    "    #example code for higher derivatives:\n",
    "    #####################################\n",
    "    \n",
    "    #derivatives_of_g.append(g_dot)\n",
    "    #derivatives_of_g.append(g)\n",
    "#     for i in range(order):\n",
    "#         if i %2 == 0:\n",
    "#             #print(\"even\")\n",
    "#             derivatives_of_g.append(g_dot)\n",
    "#         else:\n",
    "#             #print(\"odd\")\n",
    "#             derivatives_of_g.append(-g_dot)\n",
    "#    return derivatives_of_g\n",
    "\n",
    "\n",
    "def custom_loss(X, y, ydot, out_weights, force = force, \n",
    "                reg = False, ode_coefs = None, mean = True,\n",
    "               enet_strength = None, enet_alpha = None, init_conds = None, lam = 1, ham = True):\n",
    "    y, p = y[:,0].view(-1,1), y[:,1].view(-1,1)\n",
    "    ydot, pdot = ydot[:,0].view(-1,1), ydot[:,1].view(-1,1)\n",
    "    \n",
    "    #with paramization\n",
    "    L =  (ydot - p)**2 + (pdot + y + lam * y**3   - force(X))**2\n",
    "    \n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    \n",
    "    if reg:\n",
    "        #assert False\n",
    "        weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "        weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "        L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "        L = L + 0.1 * L_reg \n",
    "    if ham:\n",
    "        y0, p0 = init_conds\n",
    "        ham = hamiltonian(y, p)\n",
    "        ham0 = hamiltonian(y0, p0)\n",
    "        L_H = (( ham - ham0).pow(2)).mean()\n",
    "        assert L_H >0\n",
    "\n",
    "        L = L +  0.1 * L_H\n",
    "    \n",
    "    #print(\"L1\", hi, \"L_elastic\", L_reg, \"L_H\", L_H)\n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "provincial-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_last_layer(esn, \n",
    "                        SAVE_AFTER_EPOCHS = 1,\n",
    "                        epochs = 45000,\n",
    "                        custom_loss = custom_loss,\n",
    "                        loss_threshold = 10**-10,#10 ** -8,\n",
    "                        f = force,\n",
    "                        lr = 0.05, \n",
    "                        reg = None,\n",
    "                        plott = False,\n",
    "                        plot_every_n_epochs = 2000):#gamma 0.1, spikethreshold 0.07 works\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        #define new_x\n",
    "        new_X = esn.extended_states.detach()\n",
    "        spikethreshold = esn.spikethreshold\n",
    "\n",
    "        #force detach states_dot\n",
    "        esn.states_dot = esn.states_dot.detach().requires_grad_(False)\n",
    "\n",
    "        #define criterion\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        #assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        #assert not new_X.requires_grad\n",
    "\n",
    "        #define previous_loss (could be used to do a convergence stop)\n",
    "        previous_loss = 0\n",
    "\n",
    "        #define best score so that we can save the best weights\n",
    "        best_score = 0\n",
    "\n",
    "        #define the optimizer\n",
    "        optimizer = optim.Adam(esn.parameters(), lr = lr)\n",
    "\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "        if esn.gamma_cyclic:\n",
    "            cyclic_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 10**-6, 0.01,\n",
    "                                              gamma = esn.gamma_cyclic,#0.9999,\n",
    "                                              mode = \"exp_range\", cycle_momentum = False)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=esn.gamma)\n",
    "        lrs = []\n",
    "\n",
    "        #define the loss history\n",
    "        loss_history = []\n",
    "\n",
    "        if plott:\n",
    "            #use pl for live plotting\n",
    "            fig, ax = pl.subplots(1,3, figsize = (16,4))\n",
    "\n",
    "        t = esn.X#.view(*N.shape).detach()\n",
    "        g, g_dot = esn.G\n",
    "        y0  = esn.init_conds[0]\n",
    "\n",
    "        floss_last = 0\n",
    "\n",
    "\n",
    "        try:\n",
    "            assert esn.LinOut.weight.requires_grad and esn.LinOut.bias.requires_grad\n",
    "        except:\n",
    "            esn.LinOut.weight.requires_grad_(True)\n",
    "            esn.LinOut.bias.requires_grad_(True)\n",
    "\n",
    "        #begin optimization loop\n",
    "        for e in range(epochs):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            N = esn.forward( esn.extended_states )\n",
    "            N_dot = esn.calc_Ndot(esn.states_dot)\n",
    "\n",
    "            y = g *N \n",
    "\n",
    "            ydot = g_dot * N + g * N_dot\n",
    "\n",
    "            y[:,0] = y[:,0] + esn.init_conds[0]\n",
    "            y[:,1] = y[:,1] + esn.init_conds[1]\n",
    "\n",
    "            assert N.shape == N_dot.shape, f'{N.shape} != {N_dot.shape}'\n",
    "\n",
    "            loss = custom_loss(esn.X, y, ydot, esn.LinOut.weight, reg = reg, ode_coefs = esn.ode_coefs,\n",
    "                              init_conds = esn.init_conds, enet_alpha= esn.enet_alpha, enet_strength = esn.enet_strength)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if esn.gamma_cyclic and e > 0 and e <5000:\n",
    "                cyclic_scheduler.step()\n",
    "            lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "\n",
    "            floss = float(loss)\n",
    "            \n",
    "            if e > 0:\n",
    "                loss_delta = float(np.log(floss_last) - np.log(floss)) \n",
    "                if loss_delta > esn.spikethreshold:# or loss_delta < -3:\n",
    "                    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "                    scheduler.step()\n",
    "            \n",
    "            if not e and not best_score:\n",
    "                best_bias, best_weight, best_fit = esn.LinOut.bias.detach(), esn.LinOut.weight.detach(), y.clone()\n",
    "\n",
    "            if e > SAVE_AFTER_EPOCHS:\n",
    "                if not best_score:\n",
    "                    best_score = min(loss_history)\n",
    "                best_bias, best_weight = esn.LinOut.bias.detach(), esn.LinOut.weight.detach()\n",
    "                best_score = float(loss)\n",
    "                best_fit = y.clone()\n",
    "                best_pred = y.clone()\n",
    "                best_ydot = ydot.clone()\n",
    "            \n",
    "            loss_history.append(floss)\n",
    "            floss_last = floss\n",
    "            if plott and e:\n",
    "\n",
    "                if e % plot_every_n_epochs == 0:\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        print('lr', param_group['lr'])\n",
    "                    ax[0].clear()\n",
    "                    logloss_str = 'Log(L) ' + '%.2E' % Decimal((loss).item())\n",
    "                    delta_loss  = ' delta Log(L) ' + '%.2E' % Decimal((loss-previous_loss).item())\n",
    "\n",
    "                    print(logloss_str + \", \" + delta_loss)\n",
    "                    ax[0].plot(y.detach().cpu(), label = \"exact\")\n",
    "                    ax[0].set_title(f\"Epoch {e}\" + \", \" + logloss_str)\n",
    "                    ax[0].set_xlabel(\"t\")\n",
    "\n",
    "                    ax[1].set_title(delta_loss)\n",
    "                    ax[1].plot(N_dot.detach().cpu())\n",
    "                    #ax[0].plot(y_dot.detach(), label = \"dy_dx\")\n",
    "                    ax[2].clear()\n",
    "                    #weight_size = str(weight_size_sq.detach().item())\n",
    "                    #ax[2].set_title(\"loss history \\n and \"+ weight_size)\n",
    "\n",
    "                    ax[2].loglog(loss_history)\n",
    "                    ax[2].set_xlabel(\"t\")\n",
    "\n",
    "                    [ax[i].legend() for i in range(3)]\n",
    "                    previous_loss = loss.item()\n",
    "\n",
    "                    #clear the plot outputt and then re-plot\n",
    "                    display.clear_output(wait=True) \n",
    "                    display.display(pl.gcf())\n",
    "\n",
    "\n",
    "        return {\"weights\": best_weight, \n",
    "                \"bias\" : best_bias, \n",
    "                \"loss\" : {\"loss_history\" : loss_history},\n",
    "                \"ydot\" : best_ydot, \n",
    "                \"y\" : best_pred,\n",
    "                \"best_score\" : best_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "active-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force(X, A = 0):\n",
    "    return torch.zeros_like(X)\n",
    "lam =1\n",
    "def hamiltonian(x, p, lam = lam):\n",
    "    return (1/2)*(x**2 + p**2) + lam*x**4/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "BURN_IN = 1000\n",
    "x0,xf, nsteps = 0, 5, 1000\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False)\n",
    "\n",
    "#the length of xtrain won't matter above. Only dt , x0, and xf matter for ODEs.\n",
    "#the reason for this is that the input time vector is reconstructed internally in rctorch\n",
    "#in order to satisfy the specified dt.\n",
    "xtrain = torch.linspace(x0, xf, steps = nsteps, requires_grad=False).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accurate-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_oscillator_hp_set = {'dt': 0.001,\n",
    " 'regularization': 48.97788193684461,\n",
    " 'n_nodes': 500,\n",
    " 'connectivity': 0.017714821964432213,\n",
    " 'spectral_radius': 2.3660330772399902,\n",
    " 'leaking_rate': 0.0024312976747751236,\n",
    " 'bias': 0.37677669525146484,\n",
    " 'enet_alpha': 0.2082211971282959,\n",
    " 'enet_strength': 0.118459548397668,\n",
    " 'spikethreshold': 0.43705281615257263,\n",
    " 'gamma': 0.09469877928495407,\n",
    " 'gamma_cyclic': 0.999860422666841}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raising-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010001887567341328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 2*np.pi#10*np.pi\n",
    "x0, xf= 0, base\n",
    "nsteps = int(abs(xf - x0)/(nl_oscillator_hp_set[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "float(xtrain[1]- xtrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mental-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 48s, sys: 54.3 s, total: 8min 42s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y0s = np.arange(0.7, 1.8, 0.2)\n",
    "v0 = 1\n",
    "\n",
    "RC = EchoStateNetwork(**nl_oscillator_hp_set, \n",
    "                       random_state = 209, \n",
    "                       feedback = False, \n",
    "                       id_ = 10,\n",
    "                       activation_f = torch.sin,\n",
    "                       act_f_prime = torch.cos,\n",
    "                       dtype = torch.float32, n_outputs = 2)\n",
    "\n",
    "train_args = {\"burn_in\" : int(BURN_IN), \n",
    "              \"ODE_order\" : 1,\n",
    "              \"force\" : force,\n",
    "              \"reparam_f\" : reparam,\n",
    "              \"init_conditions\" : [y0s, float(v0)],\n",
    "              \"ode_coefs\" :       [1, 1],\n",
    "              \"X\" :   xtrain.view(-1, 1),\n",
    "              \"eq_system\" : True,\n",
    "              #\"out_weights\" : out_weights\n",
    "              }\n",
    "#fit\n",
    "results = RC.fit(**train_args, \n",
    "                 SOLVE = True,\n",
    "                 train_score = True,\n",
    "                 backprop_f = optimize_last_layer, \n",
    "                 epochs = 10000,\n",
    "                 ODE_criterion = custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "specialized-mills",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-74c76ff1f75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNLosc_solution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m plot_data = plot_rmsr(RC,\n\u001b[1;32m      4\u001b[0m                       \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_force\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-9a1116c0db23>\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(RC, results, integrator_model, y0s, ax)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#plot the integrator prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         ax.plot(y_truth, p_truth, color = \"red\", linewidth =3, \n\u001b[0;32m---> 57\u001b[0;31m                 alpha = 1.0, label = labels[2])\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;31m#         ax.plot(X, p, color = \"red\", alpha = 1.0, linewidth =3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#                 label = labels[3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize = (14,4))\n",
    "plot_results(RC, results, NLosc_solution, y0s, ax = ax[0])\n",
    "plot_data = plot_rmsr(RC,\n",
    "                      results, \n",
    "                      force = no_force, \n",
    "                      log = True, \n",
    "                      ax = ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "antique-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notebook runtime: 19220.08 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
