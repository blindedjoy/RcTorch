{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "#from RcTorch import *\n",
    "from rctorchprivate import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#this method will ensure that the notebook can use multiprocessing (train multiple \n",
    "#RC's in parallel) on jupyterhub or any other linux based system.\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except:\n",
    "    pass\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accurate-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineW = 3\n",
    "lineBoxW=2\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-panic",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to use RcTorch to find optimal hyper-paramters for the differential equation $\\dot y + q(t) y = f(t) $.\n",
    "\n",
    "Simple population:  <font color='blue'>$\\dot y + y =0$  </font>\n",
    "* Analytical solution: <font color='green'>$y = y_0 e^{-t}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "constitutional-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a reparameterization function, empirically we find that g= 1-e^(-t) works well)\n",
    "def reparam(t, order = 1):\n",
    "    \n",
    "    exp_t = torch.exp(-t)\n",
    "    derivatives_of_g = []\n",
    "    \n",
    "    g = 1 - exp_t\n",
    "    g_dot = 1 - g\n",
    "    return g, g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "portable-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(RC, results, integrator_model, ax = None):\n",
    "    \"\"\"plots a RC prediction and integrator model prediction for comparison\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    integrator model: function\n",
    "        the model to be passed to odeint which is a gold standard integrator numerical method\n",
    "        for solving ODE's written in Fortran. You may find the documentation here:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    X = RC.X.cpu()\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (6,6))\n",
    "    for i, y in enumerate(results[\"ys\"]):\n",
    "        y = y.cpu()\n",
    "        if not i:\n",
    "            labels = [\"RC\", \"Integrator Solution\"]\n",
    "        else:\n",
    "            labels = [None, None]\n",
    "        ax.plot(X, y, color = \"dodgerblue\", label = labels[0], linewidth = lineW + 1, alpha = 0.9)\n",
    "\n",
    "        #calculate the integrator prediction:\n",
    "        int_sol = odeint(integrator_model, y0s[i], np.array(X.cpu().squeeze()))\n",
    "        int_sol = torch.tensor(int_sol)\n",
    "        \n",
    "        #plot the integrator prediction\n",
    "        ax.plot(X, int_sol, '--', color = \"red\", alpha = 0.9, label = labels[1],  linewidth = lineW)\n",
    "    \n",
    "    plt.ylabel(r'$y(t)$');\n",
    "    ax.legend();\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def covert_ode_coefs(t, ode_coefs):\n",
    "    \"\"\" converts coefficients from the string 't**n' or 't^n' where n is any float\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.tensor\n",
    "        input time tensor\n",
    "    ode_coefs: list\n",
    "        list of associated floats. List items can either be (int/floats) or ('t**n'/'t^n')\n",
    "    Returns\n",
    "    -------\n",
    "    ode_coefs\n",
    "    \"\"\"\n",
    "    type_t = type(t)\n",
    "    for i, coef in enumerate(ode_coefs):\n",
    "        if type(coef) == str:\n",
    "            if coef[0] == \"t\" and (coef[1] == \"*\" or (coef[1] == \"*\" and coef[2] == \"*\")):\n",
    "                pow_ = float(re.sub(\"[^0-9.-]+\", \"\", coef))\n",
    "                ode_coefs[i]  = t ** pow_\n",
    "                print(\"alterning ode_coefs\")\n",
    "        elif type(coef) in [float, int, type_t]:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"ode_coefs must be a list floats or strings of the form 't^pow', where pow is a real number.\"\n",
    "    return ode_coefs\n",
    "    \n",
    "\n",
    "def plot_rmsr(RC, results, force, ax = None):\n",
    "    \"\"\"plots the residuals of a RC prediction directly from the loss function\n",
    "    Parameters\n",
    "    ----------\n",
    "    RC: RcTorchPrivate.esn\n",
    "        the RcTorch echostate network to evaluate. This model should already have been fit.\n",
    "    results: dictionary\n",
    "        the dictionary of results returned by the RC after fitting\n",
    "    force: function\n",
    "        the force function describing the force term in the population equation\n",
    "    ax: matplotlib.axes._subplots.AxesSubplot\n",
    "        If provided, the function will plot on this subplot axes\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10, 4))\n",
    "    X = RC.X.cpu()\n",
    "    ys, ydots = results[\"ys\"], results[\"ydots\"]\n",
    "    \n",
    "    residuals = []\n",
    "    force_t = force(X)\n",
    "    for i, y in enumerate(ys):\n",
    "        ydot = ydots[i]\n",
    "        y = y.cpu()\n",
    "        ydot = ydot.cpu()\n",
    "        \n",
    "        ode_coefs = covert_ode_coefs(t = X, ode_coefs = RC.ode_coefs)\n",
    "        \n",
    "        resids = custom_loss(X, y, ydot, None, \n",
    "                             force_t = force_t, \n",
    "                             ode_coefs = RC.ode_coefs,\n",
    "                             mean = False)\n",
    "        if not i:\n",
    "            resids_tensor = resids\n",
    "            label = r'{Individual Trajectory RMSR}'\n",
    "        else:\n",
    "            resids_tensor = torch.cat((resids_tensor, resids), axis = 1)\n",
    "            label = None\n",
    "        resids_specific_rmsr = torch.sqrt(resids/1) \n",
    "            \n",
    "        ax.plot(X, resids_specific_rmsr, color = \"orangered\", alpha = 0.4, label = label, linewidth = lineW-1)\n",
    "        residuals.append(resids)\n",
    "    \n",
    "    mean_resid = torch.mean(resids_tensor, axis =1)\n",
    "    rmsr = torch.sqrt(mean_resid)\n",
    "    ax.plot(X, rmsr, \n",
    "               color = \"blue\", \n",
    "               alpha = 0.9, \n",
    "               label = r'{RMSR}',\n",
    "               linewidth = lineW-0.5)\n",
    "\n",
    "    ax.legend(prop={\"size\":16});\n",
    "    \n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(r'{RMSR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-vermont",
   "metadata": {},
   "source": [
    "## task 1: cross check burn in for all three experiments (burn in should be embedded into hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "academic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_force(X, A = 1):\n",
    "    \"\"\" a force function, specifically f(t) = sin(t)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, a torch.tensor of equal dimension to the input time tensor.\n",
    "    \"\"\"\n",
    "    return A*torch.sin(X)\n",
    "\n",
    "def no_force(X):\n",
    "    \"\"\" a force function (returns 0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        the input time tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the force, in this case 0.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "lam =1\n",
    "def custom_loss(X , y, ydot, out_weights, lam = lam, force_t = None, reg = False, \n",
    "               ode_coefs = None, init_conds = None, \n",
    "                enet_alpha = None, enet_strength =None, mean = True):\n",
    "    \"\"\" The loss function of the ODE (in this case the population equation loss)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor\n",
    "        The input (in the case of ODEs this is time t)\n",
    "    y: torch.tensor\n",
    "        The response variable\n",
    "    ydot: torch.tensor\n",
    "        The time derivative of the response variable\n",
    "    enet_strength: float\n",
    "        the magnitude of the elastic net regularization parameter. In this case there is no e-net regularization\n",
    "    enet_alpha: float\n",
    "        the proportion of the loss that is L2 regularization (ridge). 1-alpha is the L1 proportion (lasso).\n",
    "    ode_coefs: list\n",
    "        this list represents the ODE coefficients. They can be numbers or t**n where n is some real number.\n",
    "    force: function\n",
    "        this function needs to take the input time tensor and return a new tensor f(t)\n",
    "    reg: bool\n",
    "        if applicable (not in the case below) this will toggle the elastic net regularization on and off\n",
    "    reparam: function\n",
    "        a reparameterization function which needs to take in the time tensor and return g and gdot, which \n",
    "        is the reparameterized time function that satisfies the initial conditions.\n",
    "    init_conds: list\n",
    "        the initial conditions of the ODE.\n",
    "    mean: bool\n",
    "        if true return the cost (0 dimensional float tensor) else return the residuals (1 dimensional tensor)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    the residuals or the cost depending on the mean argument (see above)\n",
    "    \"\"\"\n",
    "    #with paramization\n",
    "    L =  ydot  + lam * y - force_t\n",
    "    \n",
    "#     if reg:\n",
    "#         #assert False\n",
    "#         weight_size_sq = torch.mean(torch.square(out_weights))\n",
    "#         weight_size_L1 = torch.mean(torch.abs(out_weights))\n",
    "#         L_reg = enet_strength*(enet_alpha * weight_size_sq + (1- enet_alpha) * weight_size_L1)\n",
    "#         L = L + 0.1 * L_reg \n",
    "    \n",
    "    L = torch.square(L)\n",
    "    if mean:\n",
    "        L = torch.mean(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "first-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1732674837112427"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(0.671015444528619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "laden-anxiety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#declare the initial conditions (each initial condition corresponds to a different curve)\n",
    "y0s = np.arange(-5.1, 5.1, 1)#2.1\n",
    "len(y0s)\n",
    "\n",
    "bounds_dict = {\"connectivity\" : (-2, -0.1), #log space\n",
    "               \"spectral_radius\" : (0.9, 1.0), #lin space\n",
    "               \"n_nodes\" : (50, 52.5), \n",
    "               \"regularization\" : (-3.5, 3.5), #log space\n",
    "               \"leaking_rate\" : (0.5, 0.95),    #linear space\n",
    "               \"input_connectivity\" : (0.1, 1.0),\n",
    "               \"dt\" : -2, #log space\n",
    "               #\"input_scaling\": (0,1),\n",
    "               \"bias\": (-0.75,0.75), #linear space\n",
    "#                \"mu\" : 0.0, #(-0.5, 0.5),\n",
    "#                \"sigma\" : (-3, 0.5)\n",
    "               }\n",
    "\n",
    "#set up data\n",
    "x0, xf = 0, 5\n",
    "nsteps = int(abs(xf - x0)/(10**bounds_dict[\"dt\"]))\n",
    "xtrain = torch.linspace(x0, xf, nsteps, requires_grad=False).view(-1,1)\n",
    "int(xtrain.shape[0] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convinced-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common cv arguments:\n",
    "cv_declaration_args = {\"interactive\" : False, \n",
    "                       \"n_jobs\" : 10, #batch size is parallel\n",
    "                       \"cv_samples\" : 1, #2 number of cv_samples, random start points\n",
    "                       \"initial_samples\" : 50, # 50 number of random samples before optimization starts\n",
    "                       \"validate_fraction\" : 0.01, #validation prop of tr+val sets\n",
    "                       \"log_score\" : True, #log-residuals\n",
    "                       \"random_seed\" : 209, # random seed\n",
    "                       \"ODE_order\" : 1, #order of eq\n",
    "                       \"subsequence_prop\" : 0.8,\n",
    "                       #\"solve_sample_prop\" : 0.8,\n",
    "                       \"n_outputs\" : 1,\n",
    "                       \"n_inputs\" : 1,\n",
    "                       \"length_min\" : 2 ** (-11),#2 **(-7), \n",
    "                       \"success_tolerance\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "discrete-charm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': -2.0,\n",
       " 'connectivity': -0.2842545509338379,\n",
       " 'spectral_radius': 1.2,\n",
       " 'n_nodes': 302.3799133300781,\n",
       " 'regularization': 0.9276695251464844,\n",
       " 'leaking_rate': 0.9,\n",
       " 'input_connectivity': 0.42385581135749817,\n",
       " 'bias': 0.32629919052124023}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_hps = {'dt': 0.01,\n",
    " 'connectivity': 0.5196913030864784,\n",
    " 'spectral_radius': 1.2,#0.9868528246879578,\n",
    " 'n_nodes': 302.3799133300781,\n",
    " 'regularization': 8.465829646562826,\n",
    " 'leaking_rate': 0.9, #0.5895532369613647,\n",
    " 'input_connectivity': 0.42385581135749817,\n",
    " 'bias': 0.32629919052124023}\n",
    "\n",
    "log_vars = ['connectivity', 'llambda', 'llambda2', 'enet_strength',\n",
    "                         'noise', 'regularization', 'dt', 'gamma_cyclic', 'sigma',\n",
    "                         #'input_connectivity', 'feedback_connectivity'\n",
    "                         ]\n",
    "tmp = {}\n",
    "for key, val in t2_hps.items():\n",
    "    if key in log_vars:\n",
    "        tmp[key] = np.log10(val)\n",
    "    else:\n",
    "        tmp[key] = val\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_dict = {\"connectivity\" : (-0.4, -0.1), #log space\n",
    "               \"spectral_radius\" : (1.1, 1.3), #lin space\n",
    "               \"n_nodes\" : (20, 22.5), \n",
    "               \"regularization\" : (-3, 3.0), #log space\n",
    "               \"leaking_rate\" : (0.85, 0.95),    #linear space\n",
    "               \"input_connectivity\" : (0.2, 0.8),\n",
    "               \"dt\" : -1, #log space\n",
    "               #\"input_scaling\": (0,1),\n",
    "               \"bias\": (-0.5, 0.5), #linear space\n",
    "#                \"mu\" : 0.0, #(-0.5, 0.5),\n",
    "#                \"sigma\" : (-3, 0.5)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK: None , device: None\n",
      "cpu\n",
      "Model initialization and exploration run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-11 02:11:23,054\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 500, #states to throw away before calculating output\n",
    "                            #combine len of tr + val sets\n",
    "                            **cv_declaration_args,\n",
    "                            reservoir_weight_dist = \"uniform\",\n",
    "                            turbo_batch_size = 1\n",
    "                            )\n",
    "#optimize the network:\n",
    "opt = True\n",
    "if opt:\n",
    "    t2_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                              reparam_f = reparam, \n",
    "                              ODE_criterion = custom_loss,\n",
    "                              init_conditions = [y0s], \n",
    "                              force = driven_force,\n",
    "                              n_trust_regions = 8,\n",
    "                              max_evals = 1500,\n",
    "                              tr_score_prop = 0.99,\n",
    "                              ode_coefs = [\"t^2\", 1],\n",
    "                              reg_type = \"driven_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_pop_hps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv.recover_hps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv.X_turbo.shape, esn_cv.Y_turbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv.recover_hps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(esn_cv.Y_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_pop_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-watch",
   "metadata": {},
   "source": [
    "### Simple population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ray.remote(num_gps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "hi = ray.remote\n",
    "\n",
    "class conditional_ray(object):\n",
    "    def __init__(self):\n",
    "        cuda_is_available = torch.cuda.is_available()\n",
    "        if cuda_is_available:\n",
    "            self.decorator = ray.remote(num_gps = 1)\n",
    "        else:\n",
    "            self.decorator = ray.remote\n",
    "    def __call__(self, func):\n",
    "        self.decorator(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common cv arguments:\n",
    "cv_declaration_args = {\"interactive\" : True, \n",
    "                       \"n_jobs\" :8, #batch size is parallel\n",
    "                       \"cv_samples\" : 1, #2 number of cv_samples, random start points\n",
    "                       \"initial_samples\" : 10, # 50 number of random samples before optimization starts\n",
    "                       \"validate_fraction\" : 0.3, #validation prop of tr+val sets\n",
    "                       \"log_score\" : True, #log-residuals\n",
    "                       \"random_seed\" : 209, # random seed\n",
    "                       \"ODE_order\" : 1, #order of eq\n",
    "                       \"subsequence_prop\" : 0.8,\n",
    "                       #see turbo ref:\n",
    "                       \"n_outputs\" : 1,\n",
    "                       \"n_inputs\" : 1,\n",
    "                       \"length_min\" : 2 ** (-7),#2 **(-7), \n",
    "                       \"success_tolerance\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "bounds_dict = {\"connectivity\" : (-2.2, -0.12), #log space\n",
    "               \"spectral_radius\" : (1, 10), #lin space\n",
    "               \"n_nodes\" : 250, \n",
    "               \"regularization\" : (-4, 4), #log space\n",
    "               \"leaking_rate\" : (0, 1),    #linear space\n",
    "               \"dt\" : -2.5, #log space\n",
    "               \"bias\": (-0.75,0.75), #linear space\n",
    "               \"mu\" : 0.0,#(-0.5, 0.5),\n",
    "               \"sigma\" : (-3, 0.5)\n",
    "               }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 500, #states to throw away before calculating output\n",
    "                            **cv_declaration_args,\n",
    "                            feedback = False,\n",
    "                            reservoir_weight_dist = \"normal\"\n",
    "                            )\n",
    "#optimize the network:\n",
    "opt = True\n",
    "if opt:\n",
    "    simple_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                              n_trust_regions = 4,\n",
    "                              max_evals = 200,\n",
    "                              reparam_f = reparam, \n",
    "                              ODE_criterion = custom_loss,\n",
    "                              init_conditions = [y0s], \n",
    "                              force = no_force,\n",
    "                              ode_coefs = [1, 1],\n",
    "                              #n_outputs = 1,\n",
    "                              reg_type = \"simple_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(esn_cv.X_turbo[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_hps(self, denorm = True):\n",
    "   \n",
    "    best_vals = self.X_turbo\n",
    "    scores = esn_cv.Y_turbo\n",
    "    \n",
    "    if denorm:\n",
    "        #denormed_ = self.denormalize_bounds(best_vals)\n",
    "        denormed_ = self.denormalize_bounds(best_vals)\n",
    "    else:\n",
    "        denormed_ = best_vals\n",
    "#         try:\n",
    "#             denormed_ = denormalize_bounds(best_vals)\n",
    "#         except:\n",
    "#             print(\"FAIL\")\n",
    "\n",
    "    #best_vals = X_turbo[torch.argmax(Y_turbo)]\n",
    "    all_hps =[]\n",
    "    \n",
    "    for i, row in enumerate(denormed_):\n",
    "        #####Bad temporary code to change it back into a dictionaryf\n",
    "        denormed_free_parameters = list(zip(self.free_parameters, row))\n",
    "        denormed_free_parameters = dict([ (item[0], item[1].item()) for item in denormed_free_parameters])\n",
    "\n",
    "        hps = denormed_free_parameters\n",
    "        for fixed_parameter in self.fixed_parameters:\n",
    "            hps = {fixed_parameter : self.bounds[fixed_parameter], **hps }\n",
    "\n",
    "        #log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt']\n",
    "        for var in self.log_vars:\n",
    "            if var in hps:\n",
    "                hps[var] = 10. ** hps[var] \n",
    "        hps[\"score\"] = float(scores[i])\n",
    "        all_hps.append(hps)\n",
    "\n",
    "\n",
    "    # Return best parameters\n",
    "    return pd.DataFrame(all_hps)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.scatter(df['connectivity'], df[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-database",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(esn_cv._errorz[0])\n",
    "#esn_cv.Y_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pop_hpss = {'dt': 0.0031622776601683794,\n",
    " 'n_nodes': 250,\n",
    " 'connectivity': 0.035335003384821,\n",
    " 'spectral_radius': 6.823965072631836,\n",
    " 'regularization': 0.0004151860381238963,\n",
    " 'leaking_rate': 0.22981758415699005,\n",
    " 'bias': 0.3198728561401367}\n",
    "\n",
    "feedback_hps = {'dt': 0.0031622776601683794,\n",
    " 'n_nodes': 250,\n",
    " 'connectivity': 0.042459767294240155,\n",
    " 'spectral_radius': 6.535794734954834,\n",
    " 'regularization': 0.002854726449745577,\n",
    " 'leaking_rate': 0.20386245846748352,\n",
    " 'bias': -0.5434672832489014}\n",
    "\n",
    "\n",
    "normal_reservoir_hps = {'mu': 0.0,\n",
    "                         'dt': 0.0031622776601683794,\n",
    "                         'n_nodes': 500,\n",
    "                         'connectivity': 0.5553696929611397,\n",
    "                         'spectral_radius': 6.276016712188721,\n",
    "                         'regularization': 6.4142668843564135,\n",
    "                         'leaking_rate': 0.8516905903816223,\n",
    "                         'bias': -0.11652106046676636,\n",
    "                         'sigma': 1.1307638250980523}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pop_RC = EchoStateNetwork(**normal_reservoir_hps,\n",
    "                          random_state = 209, \n",
    "                          dtype = torch.float32,\n",
    "                          reservoir_weight_dist = \"normal\",\n",
    "                          activation_function = \"sigmoid\",\n",
    "                          n_inputs = 1,\n",
    "                          n_outputs = 1)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 500, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : no_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1, 1]}\n",
    "\n",
    "\n",
    "pop_results = pop_RC.fit(init_conditions = [y0s,1],\n",
    "                        SOLVE = True,\n",
    "                        train_score = True, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                         n_outputs = 1,\n",
    "                        **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_pop(y, t, t_pow = 0, force_k = 0, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: show results outside BO range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some particularly good runs:\n",
    "\n",
    "# simple_pop_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.13615401772200952,\n",
    "#  'spectral_radius': 4.1387834548950195,\n",
    "#  'regularization': 0.00028325262824591835,\n",
    "#  'leaking_rate': 0.2962796092033386,\n",
    "#  'bias': -0.5639935731887817}\n",
    "\n",
    "# opt_hps = {'dt': 0.0031622776601683794,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.7170604557008349,\n",
    "#  'spectral_radius': 1.5755887031555176,\n",
    "#  'regularization': 0.00034441529823729916,\n",
    "#  'leaking_rate': 0.9272222518920898,\n",
    "#  'bias': 0.1780446171760559}\n",
    "\n",
    "# opt_hps = {'dt': 0.0017782794100389228,\n",
    "#  'n_nodes': 250,\n",
    "#  'connectivity': 0.11197846061157432,\n",
    "#  'spectral_radius': 1.7452095746994019,\n",
    "#  'regularization': 0.00012929296298723957,\n",
    "#  'leaking_rate': 0.7733328938484192,\n",
    "#  'bias': 0.1652531623840332}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = pop_RC, \n",
    "                       results = pop_results, \n",
    "                       integrator_model = simple_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(pop_RC, \n",
    "                      results = pop_results, \n",
    "                      force = no_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmin(pop_results[\"scores\"])\n",
    "plt.plot(pop_results['ydots'][best_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-quebec",
   "metadata": {},
   "source": [
    "### Driven population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "bounds_dict = {\"connectivity\" : (-2, -0.12), #log space\n",
    "               \"spectral_radius\" : (1, 10), #lin space\n",
    "               \"n_nodes\" : (250,253), \n",
    "               \"regularization\" : (-4, 4), #log space\n",
    "               \"leaking_rate\" : (0, 1),    #linear space\n",
    "               \"dt\" : -2.5, #log space\n",
    "               \"bias\": (-0.75,0.75), #linear space,\n",
    "               \"mu\" : 0.0, #(-0.5, 0.5),\n",
    "               \"sigma\" : (-3, 0.5)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            feedback = True,\n",
    "                            esn_burn_in = 500, #states to throw away before calculating output\n",
    "                            #combine len of tr + val sets\n",
    "                            **cv_declaration_args,\n",
    "                            activation_function = 'sigmoid',\n",
    "                            reservoir_weight_dist = \"normal\"\n",
    "                            )\n",
    "#optimize the network:\n",
    "opt = True\n",
    "if opt:\n",
    "    driven_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                              reparam_f = reparam, \n",
    "                              ODE_criterion = custom_loss,\n",
    "                              init_conditions = [y0s], \n",
    "                              force = driven_force,\n",
    "                              ode_coefs = [1, 1],\n",
    "                              max_evals = 200,\n",
    "                              n_trust_regions = 5,\n",
    "                              reg_type = \"driven_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y0s = np.arange(-10, 10.1, 1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "driven_RC = EchoStateNetwork(**driven_pop_hps,#driven_pop_hps,\n",
    "                             random_state = 209, \n",
    "                             dtype = torch.float32,\n",
    "                             reservoir_weight_dist = 'normal',\n",
    "                             activation_function = 'sigmoid',\n",
    "                             n_inputs = 1,\n",
    "                             n_outputs = 1)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 500, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [1, 1]}\n",
    "\n",
    "\n",
    "driven_results = driven_RC.fit(init_conditions = [y0s,1],\n",
    "                    SOLVE = True,\n",
    "                    train_score = True, \n",
    "                    ODE_criterion = custom_loss,\n",
    "                    n_outputs = 1,\n",
    "                    **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driven_pop(y, t, t_pow = 0, force_k = 1, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driven_pop_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = driven_RC, \n",
    "                       results = driven_results, \n",
    "                       integrator_model = driven_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(driven_RC, \n",
    "                      results = driven_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-colombia",
   "metadata": {},
   "source": [
    "#### Driven t^2 Population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the initial conditions (each initial condition corresponds to a different curve)\n",
    "#y0s = np.arange(-10, 10.1, 0.1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(torch.exp(torch.tensor(1, dtype = torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the bounds dict. We search for the variables within the specified bounds.\n",
    "# if a variable is declared as a float or integer like n_nodes or dt, these variables are fixed.\n",
    "\n",
    "t2_hps =  {'n_nodes': 50,\n",
    "           'connectivity': 0.09905712745750006,\n",
    "           'spectral_radius': 1.8904799222946167,\n",
    "           'regularization': 714.156090350679,\n",
    "           'leaking_rate': 0.031645022332668304,\n",
    "           'bias': -0.24167031049728394,\n",
    "           'dt' : 0.005}\n",
    "\n",
    "bounds_dict = {\"connectivity\" : (-1, -0.1), #log space\n",
    "               \"spectral_radius\" : (1.0, 3.0), #lin space\n",
    "               \"n_nodes\" : (250, 253), \n",
    "               \"regularization\" : (-3.5, 3.5), #log space\n",
    "               \"leaking_rate\" : (0.5, 0.95),    #linear space\n",
    "               \"dt\" : -2, #log space\n",
    "               \"input_scaling\": 0.0,\n",
    "               \"bias\": (-0.75,0.75), #linear space\n",
    "#                \"mu\" : 0.0, #(-0.5, 0.5),\n",
    "#                \"sigma\" : (-3, 0.5)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#declare the esn_cv optimizer: this class will run bayesian optimization to optimize the bounds dict.\n",
    "#for more information see the github.\n",
    "esn_cv = EchoStateNetworkCV(bounds = bounds_dict,\n",
    "                            esn_burn_in = 300, #states to throw away before calculating output\n",
    "                            #combine len of tr + val sets\n",
    "                            **cv_declaration_args,\n",
    "                            #reservoir_weight_dist = \"uniform\"\n",
    "                            )\n",
    "#optimize the network:\n",
    "opt = True\n",
    "if opt:\n",
    "    t2_pop_hps = esn_cv.optimize(x = xtrain,\n",
    "                              reparam_f = reparam, \n",
    "                              ODE_criterion = custom_loss,\n",
    "                              init_conditions = [y0s], \n",
    "                              force = driven_force,\n",
    "                              n_trust_regions = 4,\n",
    "                              max_evals = 450,\n",
    "                              \n",
    "                              ode_coefs = [\"t^2\", 1],\n",
    "                              reg_type = \"driven_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_cv.recover_hps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recover_hps(self, k):\n",
    "#     print(self.X_turbo[torch.argmax(self.Y_turbo)])\n",
    "#     print(self.Y_turbo.shape)\n",
    "    ys = self.Y_turbo.long() \n",
    "    topk = torch.topk(ys, k, dim = 0)\n",
    "    print(topk.indices)\n",
    "    topk = topk.indices\n",
    "    best_vals = self.X_turbo[topk, :]\n",
    "    \n",
    "    \n",
    "    best_Xs = []\n",
    "    for i in range(best_vals.shape[0]):\n",
    "        best_Xs.append(best_vals[i].view(-1,))\n",
    "    best_hps = []\n",
    "    for best_vals in best_Xs:\n",
    "        print(best_vals)\n",
    "        denormed_ = self.denormalize_bounds(best_vals)\n",
    "\n",
    "#         try:\n",
    "#             denormed_ = denormalize_bounds(best_vals)\n",
    "#         except:\n",
    "#             print(\"FAIL\")\n",
    "\n",
    "        #best_vals = X_turbo[torch.argmax(Y_turbo)]\n",
    "\n",
    "        #####Bad temporary code to change it back into a dictionaryf\n",
    "        denormed_free_parameters = list(zip(self.free_parameters, denormed_))\n",
    "        denormed_free_parameters = dict([ (item[0], item[1].item()) for item in denormed_free_parameters])\n",
    "\n",
    "        best_hyper_parameters = denormed_free_parameters\n",
    "        for fixed_parameter in self.fixed_parameters:\n",
    "            best_hyper_parameters = {fixed_parameter : self.bounds[fixed_parameter], **best_hyper_parameters }\n",
    "\n",
    "        #log_vars = ['connectivity', 'llambda', 'llambda2', 'noise', 'regularization', 'dt']\n",
    "        for var in self.log_vars:\n",
    "            if var in best_hyper_parameters:\n",
    "                best_hyper_parameters[var] = 10. ** best_hyper_parameters[var] \n",
    "        best_hps.append(dict(best_hyper_parameters))\n",
    "\n",
    "    # Return best parameters\n",
    "    return best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = recover_hps(esn_cv, 4)\n",
    "hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution run:\n",
    "# t2_hps =  {'n_nodes': 500,\n",
    "#            'connectivity': 0.09905712745750006,\n",
    "#            'spectral_radius': 1.8904799222946167,\n",
    "#            'regularization': 714.156090350679,\n",
    "#            'leaking_rate': 0.031645022332668304,\n",
    "#            'bias': -0.24167031049728394,\n",
    "#            'dt' : 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_pop(y, t, t_pow = 2, force_k = 1, k = 1):\n",
    "    dydt = -k * y *t**t_pow + force_k*np.sin(t)\n",
    "    return dydt\n",
    "\n",
    "t2_large_pop_hps = {'dt': 0.0031622776601683794,\n",
    "  'n_nodes': 5000,\n",
    "  'connectivity': 0.011375554517426858,\n",
    "  'spectral_radius': 1.001483678817749,\n",
    "  'regularization': 0.10551396568378141,\n",
    "  'leaking_rate': 0.6042274236679077,\n",
    "  'bias': -0.5456951856613159}\n",
    "\n",
    "t2_large_pop_hps = {'dt': 0.0031622776601683794,\n",
    "  'n_nodes': 5000,\n",
    "  'connectivity': 0.006769240463316872,\n",
    "  'spectral_radius': 1.02934992313385,\n",
    "  'regularization': 2.553968845569174,\n",
    "  'leaking_rate': 0.5708888173103333,\n",
    "  'bias': 0.11009591817855835}\n",
    "\n",
    "t2_hps =  {'n_nodes': 500,\n",
    "           'connectivity': 0.09905712745750006,\n",
    "           'spectral_radius': 1.8904799222946167,\n",
    "           'regularization': 714.156090350679,\n",
    "           'leaking_rate': 0.031645022332668304,\n",
    "           'bias': -0.24167031049728394,\n",
    "           'dt' : 0.005,\n",
    "          'mu' : None}\n",
    "\n",
    "t2_hps = {'dt': 0.01,\n",
    " 'connectivity': 0.01941342977956559,\n",
    " 'spectral_radius': 0.9240224361419678,\n",
    " 'n_nodes': 100.79619598388672,\n",
    " 'regularization': 119.62205010230673,\n",
    " 'leaking_rate': 0.5126264691352844,\n",
    " 'bias': -0.6684032678604126}\n",
    "\n",
    "t2_hps = {'dt': 0.01,\n",
    " 'connectivity': 0.011935769253512066,\n",
    " 'spectral_radius': 0.9255421757698059,\n",
    " 'n_nodes': 100.69910430908203,\n",
    " 'regularization': 0.0025961285365239143,\n",
    " 'leaking_rate': 0.5886231064796448,\n",
    " 'bias': -0.11111664772033691,\n",
    " }\n",
    "t2_hps = {'dt': 0.01,\n",
    " 'connectivity': 0.5196913030864784,\n",
    " 'spectral_radius': 1.2,#0.9868528246879578,\n",
    " 'n_nodes': 302.3799133300781,\n",
    " 'regularization': 8.465829646562826,\n",
    " 'leaking_rate': 0.9, #0.5895532369613647,\n",
    " 'input_connectivity': 0.42385581135749817,\n",
    " 'bias': 0.32629919052124023}\n",
    "\n",
    "# t2_normal_reservoir_hps = {'mu': 0.0,\n",
    "#  'dt': 0.0031622776601683794,\n",
    "#  'connectivity': 0.046269292530735924,\n",
    "#  'spectral_radius': 2.9632248878479004,\n",
    "#  'n_nodes': 252.12603759765625,\n",
    "#  'regularization': 1629.0326850836211,\n",
    "#  'leaking_rate': 0.03967997804284096,\n",
    "#  'bias': -0.017130792140960693,\n",
    "#  'sigma': 0.004813828205433559}\n",
    "y0s = np.arange(-5.1, 5.1, 1)\n",
    "len(y0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-venue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_RC = EchoStateNetwork(**t2_hps,\n",
    "                         #reservoir_weight_dist = 'normal',\n",
    "                         #activation_function = \"tanh\",\n",
    "                         random_state = 209, \n",
    "                         dtype = torch.float32,\n",
    "                         n_inputs = 1)\n",
    "\n",
    "train_args = {\"X\" : xtrain.view(-1,1),        \n",
    "              \"burn_in\" : 300, \n",
    "              \"ODE_order\" : 1,   \n",
    "              \"force\" : driven_force, \n",
    "              \"reparam_f\" : reparam,\n",
    "              \"ode_coefs\" : [\"t^2\", 1],\n",
    "              }\n",
    "\n",
    "t2_results = t2_RC.fit(init_conditions = [y0s,1],\n",
    "                        \n",
    "                        n_outputs = 1,\n",
    "                        SOLVE = True,\n",
    "                        train_score = True, \n",
    "                        ODE_criterion = custom_loss,\n",
    "                        **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-letter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9, 7)); gs1 = gridspec.GridSpec(3, 3);\n",
    "ax = plt.subplot(gs1[:-1, :])\n",
    "\n",
    "gts = plot_predictions(RC = t2_RC, \n",
    "                       results = t2_results, \n",
    "                       integrator_model = t2_pop, \n",
    "                       ax = ax)\n",
    "\n",
    "ax = plt.subplot(gs1[-1, :])\n",
    "plot_data = plot_rmsr(t2_RC, \n",
    "                      results = t2_results, \n",
    "                      force = driven_force, \n",
    "                      ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total notebook runtime: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-clock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-inventory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
