
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>RcTorch API &#8212; RcTorch 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RcTorch Tutorial: Forced Pedulum Example" href="tutorials/forced_pendulum.html" />
    <link rel="prev" title="Welcome to RcTorch’s documentation!" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="rctorch-api">
<span id="api"></span><h1>RcTorch API<a class="headerlink" href="#rctorch-api" title="Permalink to this headline">¶</a></h1>
<section id="rcnetwork-class">
<h2>RcNetwork Class<a class="headerlink" href="#rcnetwork-class" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rctorchprivate.rc.</span></span><span class="sig-name descname"><span class="pre">RcNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Class with all functionality to train Reservoir Computers (RCs).
Builds and trains RC networks with the specified parameters.
In training (fitting), testing and predicting, X is a matrix consisting of column-wise time series features.
Y is a zero-dimensional target vector or a matrix consisting of a matrix of column-wise time series vectors.</p>
<p>The evolution of the RC is governed by the following formula:
<span class="math notranslate nohighlight">\(\bf{h}_k = \left(1-\alpha \right)\bf{h}_{k-1} + \alpha \phi \left( \bf{W}_\text{res} \cdot \bf{h}_{k-1}+\bf{W}_\text{in}\cdot \bf{u} + \bf {b}  \right)\)</span>
where <span class="math notranslate nohighlight">\(\bf{h}_k\)</span> is the k<sup>th</sup> hidden state, <span class="math notranslate nohighlight">\(\alpha\)</span> is the leaking rate,
<span class="math notranslate nohighlight">\(\phi\)</span> is the activation function, <span class="math notranslate nohighlight">\(\bf{W}_\text{res}\)</span> is the matrix of reservoir weights (the adjacency matrix which determines the structure of the reservoir),
<span class="math notranslate nohighlight">\(\bf{W}_\text{in}\)</span> is the set of input weights, <span class="math notranslate nohighlight">\(\bf{u}\)</span> is the input and <span class="math notranslate nohighlight">\(\bf{b}\)</span> is the bias.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">RcBayes</span></code> class trains many individual <a class="reference internal" href="#rctorchprivate.rc.RcNetwork" title="rctorchprivate.rc.RcNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">RcNetwork</span></code></a> instances.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The most important methods are the <a class="reference internal" href="#rctorchprivate.rc.RcNetwork.fit" title="rctorchprivate.rc.RcNetwork.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>, <a class="reference internal" href="#rctorchprivate.rc.RcNetwork.predict" title="rctorchprivate.rc.RcNetwork.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>, and <a class="reference internal" href="#rctorchprivate.rc.RcNetwork.test" title="rctorchprivate.rc.RcNetwork.test"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></a>.</p>
</div>
<p>To see the hidden states check out the <code class="xref py py-attr docutils literal notranslate"><span class="pre">state</span></code> or run the <a class="reference internal" href="#rctorchprivate.rc.RcNetwork.plot_states" title="rctorchprivate.rc.RcNetwork.plot_states"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_states()</span></code></a> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_nodes</strong> (<em>int</em>) – Number of nodes that together make up the reservoir</p></li>
<li><p><strong>input_scaling</strong> (<em>float</em>) – The scaling of input values into the network</p></li>
<li><p><strong>feedback_scaling</strong> (<em>float</em>) – The scaling of feedback values back into the reservoir</p></li>
<li><p><strong>spectral_radius</strong> (<em>float</em>) – Sets the magnitude of the largest eigenvalue of the transition matrix (weight matrix)</p></li>
<li><p><strong>leaking_rate</strong> (<em>float</em>) – Specifies how much of the state update ‘leaks’ into the new state</p></li>
<li><p><strong>connectivity</strong> (<em>float</em>) – The probability that two nodes will be connected</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – The L2-regularization parameter used in Ridge regression for model inference</p></li>
<li><p><strong>feedback</strong> (<em>bool</em>) – Sets feedback of the last value back into the network on or off</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed used to initialize RandomState in reservoir generation and weight initialization</p></li>
<li><p><strong>backprop</strong> (<em>bool</em>) – if true the network initiates backpropogation.</p></li>
<li><p><strong>classification</strong> (<em>bool</em>) – if true the network assumes a categorical response, initiates backprop. Not yet working.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Loss function</em>) – loss function for backprogation training</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs to train the network for.</p></li>
<li><p><strong>l2_prop</strong> (<em>float</em><em> (</em><em>between 0 and 1</em><em>)</em>) – this is the proportion of the l2 norm. if 1, ridge regression. if 0, lasso. in between it’s elastic net regularization.
<strong>Please note that a significant slowdown will occur with values other than 0</strong></p></li>
<li><p><strong>enet_alpha</strong> (<em>float</em><em> (</em><em>between 0 and 1</em><em>)</em>) – to be used in the context of solving ODEs (unsupervised). Represents the proportion of the
elastic net loss that is L2. Specifically the <code class="xref py py-func docutils literal notranslate"><span class="pre">rctorchprivate.defs.elastic_loss()</span></code> criterion uses the hyper-parameter in the following way:
<code class="docutils literal notranslate"><span class="pre">L_reg</span> <span class="pre">=</span> <span class="pre">enet_strength*(enet_alpha</span> <span class="pre">*</span> <span class="pre">weight_size_sq</span> <span class="pre">+</span> <span class="pre">(1-</span> <span class="pre">enet_alpha)</span> <span class="pre">*</span> <span class="pre">weight_size_L1)</span></code></p></li>
<li><p><strong>enet_strength</strong> – to be used in the context of solving ODEs (unsupervised). Represents the strength of the
elastic net regularization. Specifically the <code class="xref py py-func docutils literal notranslate"><span class="pre">rctorchprivate.defs.elastic_loss()</span></code> criterion uses the hyper-parameter in the following way:
<code class="docutils literal notranslate"><span class="pre">L_reg</span> <span class="pre">=</span> <span class="pre">enet_strength*(enet_alpha</span> <span class="pre">*</span> <span class="pre">weight_size_sq</span> <span class="pre">+</span> <span class="pre">(1-</span> <span class="pre">enet_alpha)</span> <span class="pre">*</span> <span class="pre">weight_size_L1)</span></code></p></li>
<li><p><strong>n_inputs</strong> (<em>int</em>) – the number of observers (input time-series) that are being input to the model.</p></li>
<li><p><strong>n_outputs</strong> (<em>int</em>) – the number of time series that the model will try to fit.</p></li>
<li><p><strong>input_weight_dist</strong> (<em>str</em>) – The probability distribution from which the input weights are drawn.
Valid values include <cite>“uniform”</cite>, and <cite>“discrete”</cite></p></li>
<li><p><strong>input_weight_dist</strong> – The probability distribution from which the reservoir weights are drawn.
Valid values include <cite>“uniform”</cite>, <cite>“discrete”</cite>, and <cite>“normal”</cite>.</p></li>
<li><p><strong>output_activation</strong> (<em>str</em>) – the output activation function. Valid values include <cite>“identity”</cite> (the default), <cite>“tanh”</cite>, and <cite>“sin”</cite>.
Currently only <cite>“identity”</cite> and <cite>“tanh”</cite> are recommended. Specifically if it is known that the output is bounded,
generally in a similar range to the training set, then <cite>“tanh”</cite> is recommended otherwise use the <cite>“identity”</cite>.</p></li>
<li><p><strong>gamma_cyclic</strong> (<em>float</em>) – gamma hyper-parameter to be passed to torch.optim.lr_scheduler.CyclicLR, only used in certain
unsupervised loss functions. Check out the defs.py file where this HP is currently in use in
the <code class="xref py py-func docutils literal notranslate"><span class="pre">rctorchprivate.defs.optimize_last_layer()</span></code> function.</p></li>
<li><p><strong>input_connectivity</strong> (<em>float</em>) – connectivity = (1- sparcity) of the input weights (number of non null weights)</p></li>
<li><p><strong>feedback_connectivity</strong> (<em>float</em>) – connectivity = (1 - sparcity) of the feedback weights (number of non null weights)</p></li>
<li><p><strong>noise</strong> (<em>float</em>) – random normal noise will be added with the following shape
torch.normal(0, 1, size = (self.n_nodes, t)) * self.noise
it will be added as <span class="math notranslate nohighlight">\(\epsilon\)</span> in the equation:
<span class="math notranslate nohighlight">\(\bf{h}_k = \left(1-\alpha \right)\bf{h}_{k-1} + \alpha f \left( \bf{W}_\text{res} \cdot \bf{h}_{k-1}+\bf{W}_\text{in}\cdot \bf{u} + \bf {b} + \epsilon \right)\)</span></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.combined_plot">
<span class="sig-name descname"><span class="pre">combined_plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_tr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_te</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_tr_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_te_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis_label_fontsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">29</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lw_vert</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tight_layout_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'h_pad':</span> <span class="pre">0.1,</span> <span class="pre">'pad':</span> <span class="pre">0.01,</span> <span class="pre">'w_pad':</span> <span class="pre">0.0}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel_pred</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tick_fontsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">27</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel_resid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'$MSE$'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_spec_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resid_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.combined_plot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.combined_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots both residuals and the prediction.</p>
<p>Extended description of function.</p>
<dl class="simple">
<dt>tight_layout_args: must be a dictionary,</dt><dd><p>for example: {‘pad’=0.4, ‘w_pad’=0.5, ‘h_pad’=1.0}
#https://matplotlib.org/stable/tutorials/intermediate/tight_layout_guide.html</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis_label_fontsize</strong> (<em>int</em>) – fontsize for axis labels</p></li>
<li><p><strong>fig</strong> (<em>matplotlib.figure.Figure</em>) – Figure to use to plot. If None, a Figure will be generated.
matplotlib.figure.Figure: The top level container for all the plot elements.</p></li>
<li><p><strong>grid_spec_x</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>gt_tr_override</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>gt_te_override</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>labelsize</strong> (<em>int</em>) – font size for labels</p></li>
<li><p><strong>lw_vert</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>resid_blocks</strong> (<em>int</em>) – Desc</p></li>
<li><p><strong>tick_fontsize</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>tight_layout_args</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>t_tr</strong> (<em>dtype</em>) – Description of arg1</p></li>
<li><p><strong>t_te</strong> (<em>dtype</em>) – Description of arg2</p></li>
<li><p><strong>ylabel_pred</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>ylabel_resid</strong> (<em>dtype</em>) – Desc</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.display_in_weights">
<span class="sig-name descname"><span class="pre">display_in_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.display_in_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.display_in_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a heatmap of the input weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.display_out_weights">
<span class="sig-name descname"><span class="pre">display_out_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.display_out_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.display_out_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a heatmap of the output weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.display_res_weights">
<span class="sig-name descname"><span class="pre">display_res_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.display_res_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.display_res_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a heatmap of the reservoir weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.error">
<span class="sig-name descname"><span class="pre">error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predicted</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nmse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.error" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the error between predictions and target values.</p>
<p>Suggested values of alpha (see the parameter description below for an explanation):</p>
<table class="colwidths-given docutils align-default" id="id1">
<caption><span class="caption-text">n vs alpha values</span><a class="headerlink" href="#id1" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>n</p></th>
<th class="head"><p>alpha</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>1.6</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>2.8</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>4.0</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>5.2</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>6.4</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>7.6</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>predicted</strong> (<em>array</em>) – Predicted value</p></li>
<li><p><strong>target</strong> (<em>array</em>) – Target values</p></li>
<li><p><strong>method</strong> (<em>{'mse'</em><em>, </em><em>'tanh'</em><em>, </em><em>'rmse'</em><em>, </em><em>'nmse'</em><em>, </em><em>'nrmse'</em><em>, </em><em>'tanh-nmse'</em><em>, </em><em>'log-tanh'</em><em>, </em><em>'log'}</em>) – Evaluation metric. ‘tanh’ takes the hyperbolic tangent of mse to bound its domain to [0, 1] to ensure
continuity for unstable models. ‘log’ takes the logged mse, and ‘log-tanh’ takes the log of the squeezed
normalized mse. The log ensures that any variance in the GP stays within bounds as errors go toward 0.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha coefficient to scale the tanh error transformation: <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">*</span> <span class="pre">tanh{(1</span> <span class="pre">/</span> <span class="pre">alpha)</span> <span class="pre">*</span> <span class="pre">error}</span></code>.
This squeezes errors onto the interval [0, alpha].
Default is 1. Suggestions for squeezing errors &gt; n * stddev of the original series
(for tanh-nrmse, this is the point after which difference with y = x is larger than 50%,
and squeezing kicks in). suggested n, alpha value pairs:</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>error</strong> – The error as evaluated with the metric chosen above</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">burn_in</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.nn.MSELoss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_states</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ODE_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">SOLVE</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reparam_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ode_coefs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ODE_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eq_system</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backprop_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nl</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_sampling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_timepoints</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the network by fitting the hidden states and then solving for the output weights.</p>
<p>Extended description of function.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To see the hidden states check out the <code class="xref py py-attr docutils literal notranslate"><span class="pre">extended_states</span></code> attribute!</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you enter ODE_order &gt;=1  then the RC will perform unsupervised differential equation solving.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>pytorch.tensor</em><em> or </em><em>numpy.array</em>) – Target</p></li>
<li><p><strong>X</strong> (<em>pytorch.tensor</em><em> or </em><em>numpy.array</em>) – Observers</p></li>
<li><p><strong>burn_in</strong> (<em>int</em>) – number of initial steps to throw away, similar to role in Markov Chain Monte Carlo simulations</p></li>
<li><p><strong>criterion</strong> (<em>dtype</em>) – loss function</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs to train</p></li>
<li><p><strong>return_states</strong> (<em>bool</em>) – if True return the hidden states</p></li>
<li><p><strong>nl</strong> (<em>bool</em>) – If True then the network tries to solve the Bernoulli differential eq family</p></li>
<li><p><strong>eq_system</strong> (<em>bool</em>) – If True then the network tries to solve a system of differential equations</p></li>
<li><p><strong>n_inputs</strong> (<em>int</em>) – the number of input timeseries, if None then the network will use teacher forcing with a pure prediction</p></li>
<li><p><strong>n_outputs</strong> (<em>int</em>) – the number of output timeseries</p></li>
<li><p><strong>backprop_f</strong> (<em>function</em>) – the backpropagation loss function</p></li>
<li><p><strong>ODE_order</strong> (<em>int</em>) – the order of the differential equation that the network will solve.
The default value is None. If left as None then the network will not perform unsupervised training and
will instead default to supervised training.</p></li>
<li><p><strong>q</strong> (<em>float</em>) – a hyper-parameter related to solving the Bernoulli family of differential equations.</p></li>
<li><p><strong>train_score</strong> (<em>bool</em>) – if True the network will return the train_score as well. This is for use in unsupervised
equations.</p></li>
<li><p><strong>epochs</strong> – number of epochs to train (for use with unsupervised non-linear diffeqs)</p></li>
<li><p><strong>ode_coefs</strong> (<em>list</em>) – list of ODE coefficients</p></li>
<li><p><strong>random_sampling</strong> (<em>bool</em>) – if True then the network will perform random sampling, instead of uniform sampling, of time points.
This makes the network considerably more powerful when solving diffeqs.</p></li>
<li><p><strong>sample_timepoints</strong> (<em>int</em>) – if the <code class="xref py py-attr docutils literal notranslate"><span class="pre">random_sampling</span></code> argument is True then the network will sample this many timepoints.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Description of return value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.plot_prediction">
<span class="sig-name descname"><span class="pre">plot_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis_label_fontsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_tr_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_te_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lw_vert</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tick_fontsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.plot_prediction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.plot_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>plots the RC predictions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gt_tr_override</strong> (<em>if you want to calculate residuals from a non-noisy real training set</em><em>,</em>) – residuals will be calculated from it not say noisy inputs</p></li>
<li><p><strong>gt_te_override</strong> (<em>if you want to calculate residuals from a non-noisy real validation set</em><em>,</em>) – residuals will be calculated from it not say noisy inputs</p></li>
<li><p><strong>fig</strong> (<em>a matplotlib figure to plot on.</em>) – </p></li>
<li><p><strong>ylabel</strong> (<em>the users desired ylabel</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.plot_residuals">
<span class="sig-name descname"><span class="pre">plot_residuals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis_label_fontsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_tr_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_te_override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lw_vert</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tick_fontsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.plot_residuals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.plot_residuals" title="Permalink to this definition">¶</a></dt>
<dd><p>Residuals plot</p>
<p>Extended description of function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis_label_fontsize</strong> (<em>int</em>) – fontsize for axis labels</p></li>
<li><p><strong>fig</strong> (<em>matplotlib.figure.Figure</em>) – Figure to use to plot. If None, a Figure will be generated.
matplotlib.figure.Figure: The top level container for all the plot elements.</p></li>
<li><p><strong>gt_tr_override</strong> (<em>dtype</em>) – Description of arg3</p></li>
<li><p><strong>gt_te_override</strong> (<em>dtype</em>) – Description of arg4</p></li>
<li><p><strong>lw_vert</strong> (<em>dtype</em>) – Desc</p></li>
<li><p><strong>prep</strong> (<em>bool</em>) – Desc</p></li>
<li><p><strong>tick_fontsize</strong> (<em>int</em>) – Desc</p></li>
<li><p><strong>ylabel</strong> (<em>dtype</em>) – Desc</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.plot_states">
<span class="sig-name descname"><span class="pre">plot_states</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.plot_states"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.plot_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots up to n hidden states.</p>
<dl class="simple">
<dt>:: note::</dt><dd><p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">state</span></code> is being plotted.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<em>int</em>) – Number of hidden states to plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continue_force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts n values in advance.</p>
<p>Prediction starts from the last state generated in training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_steps</strong> (<em>int</em>) – The number of steps to predict into the future (internally done in one step increments)</p></li>
<li><p><strong>x</strong> (<em>numpy array</em><em> or </em><em>None</em>) – If prediciton requires inputs, provide them here</p></li>
<li><p><strong>y_start</strong> (<em>float</em><em> or </em><em>None</em>) – Starting value from which to start prediction. If None, last stored value dfrom training will be used</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y_predicted</strong> – Array of n_step predictions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc.RcNetwork.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps_ahead</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nmse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reparam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ODE_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc.html#RcNetwork.test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc.RcNetwork.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests and scores against known output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>array</em>) – Column vector of known outputs</p></li>
<li><p><strong>x</strong> (<em>array</em><em> or </em><em>None</em>) – Any inputs if required</p></li>
<li><p><strong>y_start</strong> (<em>float</em><em> or </em><em>None</em>) – Starting value from which to start testing. If None, last stored value from trainging will be used</p></li>
<li><p><strong>steps_ahead</strong> (<em>int</em><em> or </em><em>None</em>) – Computes average error on n steps ahead prediction. If <cite>None</cite> all steps in y will be used.</p></li>
<li><p><strong>scoring_method</strong> (<em>{'mse'</em><em>, </em><em>'rmse'</em><em>, </em><em>'nrmse'</em><em>, </em><em>'tanh'}</em>) – Evaluation metric used to calculate error</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha coefficient to scale the tanh error transformation: alpha * tanh{(1 / alpha) * error}</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>error</strong> – Error between prediction and knwon outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="rcbayesopt-class">
<h2>RcBayesOpt Class<a class="headerlink" href="#rcbayesopt-class" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rctorchprivate.rc_bayes.RcBayesOpt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rctorchprivate.rc_bayes.</span></span><span class="sig-name descname"><span class="pre">RcBayesOpt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsequence_prop=0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model=&lt;class</span> <span class="pre">'rctorchprivate.rc.RcNetwork'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_samples=50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_fraction=0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps_ahead=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">turbo_batch_size=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_samples=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_method='nrmse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">esn_burn_in=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feedback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type='random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function='sigmoid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_activation='identity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_weight_type='uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interactive=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate_reservoir=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length_min=0.001953125</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">success_tolerance=3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=torch.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">windowsOS=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">track_in_grad=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience=400</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ODE_order=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_score=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_f_prime=&lt;function</span> <span class="pre">sech2&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_inputs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_outputs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_weight_dist='uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feedback_weight_dist='uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_weight_dist='uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solve_sample_prop=1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc_bayes.html#RcBayesOpt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc_bayes.RcBayesOpt" title="Permalink to this definition">¶</a></dt>
<dd><p>A cross-validation object that automatically optimizes ESN hyperparameters using Bayesian optimization with
Gaussian Process priors.</p>
<p>Searches optimal solution within the provided bounds.</p>
<p>The most important argument is the <code class="xref py py-attr docutils literal notranslate"><span class="pre">bounds</span></code> argument which defines the search space for the various
hyper-parameters. An example of this argument is :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bounds_dict</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;connectivity&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;spectral_radius&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="s2">&quot;n_nodes&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">353.1</span><span class="p">),</span>
    <span class="s2">&quot;log_regularization&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="s2">&quot;leaking_rate&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;input_connectivity&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;feedback_connectivity&quot;</span> <span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can search in log-space for any hyper-parameter by including ‘<a href="#id2"><span class="problematic" id="id3">log_</span></a>’ in the string. For example,
if we instead wanted to search for the connectivity between 0.01 and 0.1 we could modify the connectivity argument in the bounds dict above
to ‘log_connectivity : (-2, -1)’.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The only acquisition function which is currently implimented is Thompson Sampling.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> (<em>dict</em>) – A dictionary specifying the bounds for optimization. The key is the parameter name and the value
is a tuple with minimum value and maximum value of that parameter. E.g. {‘n_nodes’: (100, 200), …}</p></li>
<li><p><strong>model</strong> (<em>class: {RcNetwork}</em>) – Model class to optimize</p></li>
<li><p><strong>subsequence_length</strong> (<em>int</em>) – Number of samples in one cross-validation sample</p></li>
<li><p><strong>initial_samples</strong> (<em>int</em>) – The number of random samples to explore the  before starting optimization</p></li>
<li><p><strong>validate_fraction</strong> (<em>float</em>) – The fraction of the data that may be used as a validation set</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size of samples used by BoTorch</p></li>
<li><p><strong>cv_samples</strong> (<em>int</em>) – Number of samples of the objective function to evaluate for a given parametrization of the ESN</p></li>
<li><p><strong>scoring_method</strong> (<em>{'mse'</em><em>, </em><em>'rmse'</em><em>, </em><em>'tanh'</em><em>, </em><em>'nmse'</em><em>, </em><em>'nrmse'</em><em>, </em><em>'log'</em><em>, </em><em>'log-tanh'</em><em>, </em><em>'tanh-nrmse'}</em>) – Evaluation metric that is used to guide optimization</p></li>
<li><p><strong>esn_burn_in</strong> (<em>int</em>) – Number of time steps to discard upon training a single Echo State Network</p></li>
<li><p><strong>esn_feedback</strong> (<em>bool</em><em> or </em><em>None</em>) – Build ESNs with feedback (‘teacher forcing’) if available</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Verbosity on or off</p></li>
<li><p><strong>device</strong> (<em>string</em><em> or </em><em>torch device                                 #TODO flexible implimentation</em>) – Torch device (either ‘cpu’ or ‘cuda’)</p></li>
<li><p><strong>interactive</strong> (<em>bool</em>) – if true, make interactive python plots. Useful in a jupyter notebook.</p></li>
<li><p><strong>reservoir</strong> (<em>approximate</em>) – if true, builds approximate sparse reservoirs and (ie approximate connectivity not precise).
It likely slightly reduces the final result’s score but greatly speeds up the algorithm. #SPARCITY NOT IMPLIMENTED IN RCTORCH</p></li>
<li><p><strong>input_weight_type</strong> (<em>string</em>) – {“uniform”} is currently implimented.
#TODO: exponential and normal weights.</p></li>
<li><p><strong>function</strong> (<em>activation</em>) – The activation function used in the reservoir</p></li>
<li><p><strong>model_type</strong> (<em>str</em>) – #TODO
right now it is unclear whether this means reservoir type or model type.
likely that is unclear because I haven’t implimented cyclic or exponential here. #TODO impliment uniform and expo weights</p></li>
<li><p><strong>tolerance</strong> (<em>failure</em>) – the number of times that the model can fail to improve before length is in increased in turbo algo.</p></li>
<li><p><strong>success_tolerance</strong> (<em>int</em>) – like the explanation above this needs work.</p></li>
<li><p><strong>length_min</strong> (<em>int</em>) – The stopping condition. If the turbo_state’s length falls below length_min then the algorithm will terminate.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – if backprop is True, then the RC will train with gradient descent. In this case this is that learning rate.</p></li>
<li><p><strong>success_tolerance</strong> – #TODO description</p></li>
<li><p><strong>failure_tolerance</strong> – #TOD description</p></li>
<li><p><strong>steps_ahead</strong> (<em>int</em><em> or </em><em>None</em>) – Number of steps to use in n-step ahead prediction for cross validation. <cite>None</cite> indicates prediction
of all values in the validation array.</p></li>
<li><p><strong>max_iterations</strong> (<em>int</em>) – Maximim number of iterations in optimization</p></li>
<li><p><strong>log_space</strong> (<em>bool</em>) – Optimize in log space or not (take the logarithm of the objective or not before modeling it in the GP)
####### NOT IMPLIMENTED IN TORCH</p></li>
<li><p><strong>tanh_alpha</strong> (<em>float</em>) – Alpha coefficient used to scale the tanh error function: alpha * tanh{(1 / alpha) * mse}</p></li>
<li><p><strong>max_time</strong> (<em>float</em>) – Maximum number of seconds before quitting optimization</p></li>
<li><p><strong>acquisition_type</strong> (<em>{'MPI'</em><em>, </em><em>'EI'</em><em>, </em><em>'LCB'}</em>) – The type of acquisition function to use in Bayesian Optimization</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – The number specifying the maximum amount of change in parameters before considering convergence</p></li>
<li><p><strong>plot</strong> (<em>bool</em>) – Show convergence plot at end of optimization</p></li>
<li><p><strong>target_score</strong> (<em>float</em>) – Quit when reaching this target score</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em>) – Maximum number of concurrent jobs</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc_bayes.RcBayesOpt.optimize">
<span class="sig-name descname"><span class="pre">optimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_trust_regions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.nn.MSELoss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reparam_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ODE_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backprop_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backprop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ode_coefs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solve</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tr_score_prop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eq_system</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_ode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nl_ham'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solve_sample_prop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc_bayes.html#RcBayesOpt.optimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc_bayes.RcBayesOpt.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs optimization (with cross-validation).</p>
<p>Uses Bayesian Optimization with Gaussian Process priors to optimize ESN hyperparameters.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>the <code class="xref py py-attr docutils literal notranslate"><span class="pre">epochs</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">backprop_f</span></code>, and <code class="xref py py-attr docutils literal notranslate"><span class="pre">learning_rate</span></code> arguments only currently only works with unsupervised training.
This is the part of RcTorch which fits ODEs, and should only be used for non-linear equations.</p>
</div>
<div class="admonition-and-by-the-way admonition">
<p class="admonition-title">And, by the way…</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">ODE_criterion</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">init_conditions</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">force</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">reg_type</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">eq_system</span></code>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">q</span></code>,  <code class="xref py py-attr docutils literal notranslate"><span class="pre">nonlinear_ode</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">reparam_f</span></code> are also unsupervised arguments which should only be used
for solving (unsupervised) differential equations.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>numpy array</em>) – Column vector with target values (y-values)</p></li>
<li><p><strong>x</strong> (<em>numpy array</em><em> or </em><em>None</em>) – Optional array with input values (x-values)</p></li>
<li><p><strong>store_path</strong> (<em>str</em><em> or </em><em>None</em>) – Optional path where to store best found parameters to disk (in JSON)</p></li>
<li><p><strong>max_evals</strong> (<em>int</em>) – the maximum number of RcNetworks to train</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – backprop training epochs</p></li>
<li><p><strong>tr_score_prop</strong> (<em>float</em>) – if the network is running unsupervised, this argument will allow the network to score the training set as well.
for unsupervised (data based runs) this parameter has no effect.</p></li>
<li><p><strong>n_trust_regions</strong> (<em>int</em>) – This argument determines the n number of BO runs to run simultaeneoulsy.
RcTorch uses the Turbo-1 and Turbo-m algorithms, see <a class="reference external" href="https://arxiv.org/abs/1910.01739">this paper</a> by Uber AI.
n total BO arms are run in parallel, and each performs local bayesian optimization which is faster and more robust
than standard global bayesian optimization.</p></li>
<li><p><strong>q</strong> (<em>float</em>) – a diffeq hp</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>best_arguments</strong> – The best parameters found during optimization</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rctorchprivate.rc_bayes.RcBayesOpt.recover_hps">
<span class="sig-name descname"><span class="pre">recover_hps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alternative_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rctorchprivate/rc_bayes.html#RcBayesOpt.recover_hps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rctorchprivate.rc_bayes.RcBayesOpt.recover_hps" title="Permalink to this definition">¶</a></dt>
<dd><p>Recover best hyper-parameters from RcBayesOpt object.</p>
<p>This is useful if your run crashed, or you put a large number of iterations and
are training the object in a jupyter notebook and you want to stop the run.</p>
<p>This method will then recover the best hyper-parameters by extracting them from the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">X_turbo</span></code> (list of hp values) and <code class="xref py py-attr docutils literal notranslate"><span class="pre">y_turbo</span></code> (the respective scores), along with
converting those HPs back to their original scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alternative__index</strong> (<em>int</em>) – the alternative_index will give you the i/ :sup:th best hyper-parameters (as opposed to the HPs with the highest score)
this method allows you to extract them.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>best_hyper_parameters</strong> – a dictionary with the optimized hyper-parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">RcTorch</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">RcTorch API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#rcnetwork-class">RcNetwork Class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rcbayesopt-class">RcBayesOpt Class</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/forced_pendulum.html">RcTorch Tutorial: Forced Pedulum Example</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">Welcome to RcTorch’s documentation!</a></li>
      <li>Next: <a href="tutorials/forced_pendulum.html" title="next chapter">RcTorch Tutorial: Forced Pedulum Example</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Hayden Joy.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/Pages/api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>